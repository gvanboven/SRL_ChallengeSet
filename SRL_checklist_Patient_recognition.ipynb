{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SRL Patient recognition experiments\n",
    "\n",
    "In this notebook I carry out experiments to test whether two Semantic Role Labelling (SRL) systems can correctly identify patients in sentences with varying structures. This code was based on code provided by Pia Sommerauer.\n",
    "\n",
    "In this code I load two models, namely the AllenNLP SRL model and the AllenNLP SRL BERT model. I create a variety of tets cases, for wich I evaluate the performance of the two models. All the test sentences are stored in a json file specified through the `test_sents_path` variable. The SRL predictions are stored in the json file specified through `srl_pred_path`, and similarly the SRL BERT predictions are stored at the path `bert_pred_path`.\n",
    "\n",
    "### Patient recognition\n",
    "I carry out two sets of tests: in the first test I only use names as patients, in the second test I add titles to the agent and patient, namely 'Doctor' and 'nurse'. In both sets I test 3 sentence structures and names from 3 cultures: English, Iranian and Dutch. The sentence structures are as follows:\n",
    "* Active: '`name1` kissed `name2` yesterday'\n",
    "* Passive : '`name1` is the one that was kissed by `name2` yesterday'\n",
    "* 'It was .. who' + passive : 'It was `name1` that who was kissed by `name2` yesterday'\n",
    "\n",
    "For the doctor/nurse titles, I test them both in a stereotypical context, where the Doctor has a male name and the nurse a female name, and in a non-stereotypical context, where the gender of the Doctor and the nurse are reversed. This is done to test whether the model has some gender bias: if this is the case we expect better results in the stereotypical context.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp_models.pretrained import load_predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import checklist\n",
    "from checklist.editor import Editor\n",
    "from checklist.perturb import Perturb\n",
    "from checklist.test_types import MFT, INV, DIR\n",
    "from checklist.expect import Expect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from checklist.pred_wrapper import PredictorWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-01 16:10:04,021 - INFO - allennlp.common.plugins - Plugin allennlp_models available\n",
      "2022-04-01 16:10:04,198 - INFO - allennlp.common.plugins - Plugin allennlp_semparse available\n",
      "2022-04-01 16:10:04,405 - INFO - allennlp.common.plugins - Plugin allennlp_server available\n",
      "2022-04-01 16:10:04,465 - INFO - allennlp.common.params - id = pair-classification-esim\n",
      "2022-04-01 16:10:04,466 - INFO - allennlp.common.params - registered_model_name = esim\n",
      "2022-04-01 16:10:04,467 - INFO - allennlp.common.params - model_class = None\n",
      "2022-04-01 16:10:04,468 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-04-01 16:10:04,469 - INFO - allennlp.common.params - display_name = Enhanced LSTM for Natural Language Inference\n",
      "2022-04-01 16:10:04,471 - INFO - allennlp.common.params - task_id = textual_entailment\n",
      "2022-04-01 16:10:04,472 - INFO - allennlp.common.params - model_usage.archive_file = esim-elmo-2020.11.11.tar.gz\n",
      "2022-04-01 16:10:04,473 - INFO - allennlp.common.params - model_usage.training_config = esim.jsonnet\n",
      "2022-04-01 16:10:04,474 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==1.0.0 allennlp-models==1.0.0\n",
      "2022-04-01 16:10:04,475 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-04-01 16:10:04,477 - INFO - allennlp.common.params - model_details.description = This `Model` implements the ESIM model, which is a sequential neural inference model based on chain LSTMs.\n",
      "2022-04-01 16:10:04,478 - INFO - allennlp.common.params - model_details.short_description = Enhanced LSTM trained on SNLI.\n",
      "2022-04-01 16:10:04,479 - INFO - allennlp.common.params - model_details.developed_by = Chen et al\n",
      "2022-04-01 16:10:04,480 - INFO - allennlp.common.params - model_details.contributed_by = Dirk Groeneveld\n",
      "2022-04-01 16:10:04,481 - INFO - allennlp.common.params - model_details.date = 2020-04-09\n",
      "2022-04-01 16:10:04,482 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-04-01 16:10:04,483 - INFO - allennlp.common.params - model_details.model_type = LSTM\n",
      "2022-04-01 16:10:04,484 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@inproceedings{Chen2017EnhancedLF,\n",
      "title={Enhanced LSTM for Natural Language Inference},\n",
      "author={Qian Chen and Xiao-Dan Zhu and Z. Ling and Si Wei and Hui Jiang and Diana Inkpen},\n",
      "booktitle={ACL},\n",
      "year={2017}}\n",
      "\n",
      "2022-04-01 16:10:04,485 - INFO - allennlp.common.params - model_details.paper.title = Enhanced LSTM for Natural Language Inference\n",
      "2022-04-01 16:10:04,485 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:34032948\n",
      "2022-04-01 16:10:04,486 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-04-01 16:10:04,487 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-04-01 16:10:04,489 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-04-01 16:10:04,490 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-04-01 16:10:04,492 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-04-01 16:10:04,495 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-04-01 16:10:04,498 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-04-01 16:10:04,501 - INFO - allennlp.common.params - metrics.model_performance_measures = Accuracy\n",
      "2022-04-01 16:10:04,503 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-04-01 16:10:04,506 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-04-01 16:10:04,509 - INFO - allennlp.common.params - evaluation_data.dataset.name = Stanford Natural Language Inference (SNLI) dev set\n",
      "2022-04-01 16:10:04,511 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = https://allennlp.s3.amazonaws.com/datasets/snli/snli_1.0_test.jsonl\n",
      "2022-04-01 16:10:04,512 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://nlp.stanford.edu/projects/snli/\n",
      "2022-04-01 16:10:04,514 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-04-01 16:10:04,515 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-04-01 16:10:04,518 - INFO - allennlp.common.params - training_data.dataset.name = Stanford Natural Language Inference (SNLI) train set\n",
      "2022-04-01 16:10:04,519 - INFO - allennlp.common.params - training_data.dataset.processed_url = https://allennlp.s3.amazonaws.com/datasets/snli/snli_1.0_train.jsonl\n",
      "2022-04-01 16:10:04,519 - INFO - allennlp.common.params - training_data.dataset.url = https://nlp.stanford.edu/projects/snli/\n",
      "2022-04-01 16:10:04,520 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-04-01 16:10:04,521 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-04-01 16:10:04,523 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = None\n",
      "2022-04-01 16:10:04,524 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-04-01 16:10:04,526 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-04-01 16:10:04,529 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-04-01 16:10:04,606 - INFO - allennlp.common.params - id = rc-nmn\n",
      "2022-04-01 16:10:04,608 - INFO - allennlp.common.params - registered_model_name = None\n",
      "2022-04-01 16:10:04,610 - INFO - allennlp.common.params - model_class = None\n",
      "2022-04-01 16:10:04,611 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-04-01 16:10:04,613 - INFO - allennlp.common.params - display_name = Neural Module Network (NMN)\n",
      "2022-04-01 16:10:04,615 - INFO - allennlp.common.params - task_id = rc\n",
      "2022-04-01 16:10:04,617 - INFO - allennlp.common.params - model_usage.archive_file = drop-nmn-2020.04.04.tar.gz\n",
      "2022-04-01 16:10:04,619 - INFO - allennlp.common.params - model_usage.training_config = None\n",
      "2022-04-01 16:10:04,620 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==1.0.0 allennlp-models==1.0.0\n",
      "2022-04-01 16:10:04,621 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-04-01 16:10:04,623 - INFO - allennlp.common.params - model_details.description = A neural module network trained on DROP.\n",
      "2022-04-01 16:10:04,624 - INFO - allennlp.common.params - model_details.short_description = A neural module network trained on DROP.\n",
      "2022-04-01 16:10:04,625 - INFO - allennlp.common.params - model_details.developed_by = Andreas et al\n",
      "2022-04-01 16:10:04,626 - INFO - allennlp.common.params - model_details.contributed_by = None\n",
      "2022-04-01 16:10:04,628 - INFO - allennlp.common.params - model_details.date = 2020-04-04\n",
      "2022-04-01 16:10:04,629 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-04-01 16:10:04,630 - INFO - allennlp.common.params - model_details.model_type = Neural Module Network\n",
      "2022-04-01 16:10:04,631 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@article{Andreas2016NeuralMN,\n",
      "title={Neural Module Networks},\n",
      "author={Jacob Andreas and Marcus Rohrbach and Trevor Darrell and D. Klein},\n",
      "journal={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},\n",
      "year={2016},\n",
      "pages={39-48}}\n",
      "\n",
      "2022-04-01 16:10:04,633 - INFO - allennlp.common.params - model_details.paper.title = Neural Module Networks\n",
      "2022-04-01 16:10:04,634 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:5276660\n",
      "2022-04-01 16:10:04,635 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-04-01 16:10:04,636 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-04-01 16:10:04,638 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-04-01 16:10:04,639 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-04-01 16:10:04,640 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-04-01 16:10:04,642 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-04-01 16:10:04,643 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-04-01 16:10:04,645 - INFO - allennlp.common.params - metrics.model_performance_measures = None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-01 16:10:04,646 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-04-01 16:10:04,647 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-04-01 16:10:04,649 - INFO - allennlp.common.params - evaluation_data.dataset = None\n",
      "2022-04-01 16:10:04,650 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-04-01 16:10:04,652 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-04-01 16:10:04,659 - INFO - allennlp.common.params - training_data.dataset.name = DROP\n",
      "2022-04-01 16:10:04,661 - INFO - allennlp.common.params - training_data.dataset.url = https://allennlp.org/drop\n",
      "2022-04-01 16:10:04,663 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-04-01 16:10:04,664 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-04-01 16:10:04,667 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = None\n",
      "2022-04-01 16:10:04,668 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-04-01 16:10:04,670 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-04-01 16:10:04,672 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-04-01 16:10:04,745 - INFO - allennlp.common.params - id = roberta-sst\n",
      "2022-04-01 16:10:04,746 - INFO - allennlp.common.params - registered_model_name = None\n",
      "2022-04-01 16:10:04,747 - INFO - allennlp.common.params - model_class = None\n",
      "2022-04-01 16:10:04,749 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-04-01 16:10:04,751 - INFO - allennlp.common.params - display_name = RoBERTa large\n",
      "2022-04-01 16:10:04,752 - INFO - allennlp.common.params - task_id = sentiment-analysis\n",
      "2022-04-01 16:10:04,754 - INFO - allennlp.common.params - model_usage.archive_file = stanford-sentiment-treebank-roberta.2021-03-11.tar.gz\n",
      "2022-04-01 16:10:04,755 - INFO - allennlp.common.params - model_usage.training_config = classification/stanford_sentiment_treebank_roberta.jsonnet\n",
      "2022-04-01 16:10:04,755 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.4.0 allennlp-models==2.4.0\n",
      "2022-04-01 16:10:04,756 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-04-01 16:10:04,758 - INFO - allennlp.common.params - model_details.description = This model is trained on RoBERTa large with the binary classification setting of the Stanford Sentiment Treebank. It achieves 95.11% accuracy on the test set.\n",
      "2022-04-01 16:10:04,760 - INFO - allennlp.common.params - model_details.short_description = RoBERTa-based binary classifier for Stanford Sentiment Treebank\n",
      "2022-04-01 16:10:04,762 - INFO - allennlp.common.params - model_details.developed_by = Devlin et al\n",
      "2022-04-01 16:10:04,763 - INFO - allennlp.common.params - model_details.contributed_by = Zhaofeng Wu\n",
      "2022-04-01 16:10:04,764 - INFO - allennlp.common.params - model_details.date = 2020-06-08\n",
      "2022-04-01 16:10:04,765 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-04-01 16:10:04,766 - INFO - allennlp.common.params - model_details.model_type = RoBERTa large\n",
      "2022-04-01 16:10:04,768 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@article{Liu2019RoBERTaAR,\n",
      "title={RoBERTa: A Robustly Optimized BERT Pretraining Approach},\n",
      "author={Y. Liu and Myle Ott and Naman Goyal and Jingfei Du and Mandar Joshi and Danqi Chen and Omer Levy and M. Lewis and Luke Zettlemoyer and Veselin Stoyanov},\n",
      "journal={ArXiv},\n",
      "year={2019},\n",
      "volume={abs/1907.11692}}\n",
      "\n",
      "2022-04-01 16:10:04,769 - INFO - allennlp.common.params - model_details.paper.title = RoBERTa: A Robustly Optimized BERT Pretraining Approach (Liu et al)\n",
      "2022-04-01 16:10:04,770 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:198953378\n",
      "2022-04-01 16:10:04,771 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-04-01 16:10:04,772 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-04-01 16:10:04,773 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-04-01 16:10:04,775 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-04-01 16:10:04,775 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-04-01 16:10:04,777 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-04-01 16:10:04,778 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-04-01 16:10:04,780 - INFO - allennlp.common.params - metrics.model_performance_measures = Accuracy\n",
      "2022-04-01 16:10:04,781 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-04-01 16:10:04,783 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-04-01 16:10:04,785 - INFO - allennlp.common.params - evaluation_data.dataset.name = Stanford Sentiment Treebank\n",
      "2022-04-01 16:10:04,786 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = https://allennlp.s3.amazonaws.com/datasets/sst/test.txt\n",
      "2022-04-01 16:10:04,786 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://nlp.stanford.edu/sentiment/treebank.html\n",
      "2022-04-01 16:10:04,787 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-04-01 16:10:04,788 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-04-01 16:10:04,790 - INFO - allennlp.common.params - training_data.dataset.name = Stanford Sentiment Treebank\n",
      "2022-04-01 16:10:04,791 - INFO - allennlp.common.params - training_data.dataset.processed_url = https://allennlp.s3.amazonaws.com/datasets/sst/train.txt\n",
      "2022-04-01 16:10:04,791 - INFO - allennlp.common.params - training_data.dataset.url = https://nlp.stanford.edu/sentiment/treebank.html\n",
      "2022-04-01 16:10:04,792 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-04-01 16:10:04,794 - INFO - allennlp.common.params - training_data.preprocessing = Binary classification setting\n",
      "2022-04-01 16:10:04,796 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = Accuracy: 95.11% on SST test set.\n",
      "2022-04-01 16:10:04,798 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-04-01 16:10:04,800 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-04-01 16:10:04,803 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-04-01 16:10:04,883 - INFO - allennlp.common.params - id = mc-roberta-commonsenseqa\n",
      "2022-04-01 16:10:04,884 - INFO - allennlp.common.params - registered_model_name = transformer_mc\n",
      "2022-04-01 16:10:04,886 - INFO - allennlp.common.params - model_class = None\n",
      "2022-04-01 16:10:04,887 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-04-01 16:10:04,888 - INFO - allennlp.common.params - display_name = RoBERTa Common Sense QA\n",
      "2022-04-01 16:10:04,889 - INFO - allennlp.common.params - task_id = mc\n",
      "2022-04-01 16:10:04,890 - INFO - allennlp.common.params - model_usage.archive_file = commonsenseqa.2020-07-08.tar.gz\n",
      "2022-04-01 16:10:04,890 - INFO - allennlp.common.params - model_usage.training_config = mc/commonsenseqa.jsonnet\n",
      "2022-04-01 16:10:04,891 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==1.0.0 allennlp-models==1.0.0\n",
      "2022-04-01 16:10:04,891 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-04-01 16:10:04,892 - INFO - allennlp.common.params - model_details.description = This is a multiple choice model patterned after the BERT architecture. It calculates a score for each sequence on top of the CLS token, and then chooses the alternative with the highest score.\n",
      "2022-04-01 16:10:04,894 - INFO - allennlp.common.params - model_details.short_description = RoBERTa-based multiple choice model for CommonSenseQA.\n",
      "2022-04-01 16:10:04,895 - INFO - allennlp.common.params - model_details.developed_by = Liu et al\n",
      "2022-04-01 16:10:04,896 - INFO - allennlp.common.params - model_details.contributed_by = Dirk Groeneveld\n",
      "2022-04-01 16:10:04,898 - INFO - allennlp.common.params - model_details.date = 2020-07-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-01 16:10:04,899 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-04-01 16:10:04,901 - INFO - allennlp.common.params - model_details.model_type = RoBERTa large\n",
      "2022-04-01 16:10:04,902 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@article{Liu2019RoBERTaAR,\n",
      "title={RoBERTa: A Robustly Optimized BERT Pretraining Approach},\n",
      "author={Y. Liu and Myle Ott and Naman Goyal and Jingfei Du and Mandar Joshi and Danqi Chen and Omer Levy and M. Lewis and Luke Zettlemoyer and Veselin Stoyanov},\n",
      "journal={ArXiv},\n",
      "year={2019},\n",
      "volume={abs/1907.11692}}\n",
      "\n",
      "2022-04-01 16:10:04,904 - INFO - allennlp.common.params - model_details.paper.title = RoBERTa: A Robustly Optimized BERT Pretraining Approach (Liu et al)\n",
      "2022-04-01 16:10:04,906 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:198953378\n",
      "2022-04-01 16:10:04,906 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-04-01 16:10:04,907 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-04-01 16:10:04,909 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-04-01 16:10:04,910 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-04-01 16:10:04,911 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-04-01 16:10:04,918 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-04-01 16:10:04,919 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-04-01 16:10:04,922 - INFO - allennlp.common.params - metrics.model_performance_measures = The chosen metric is accuracy, since it is a multiple choice model.\n",
      "2022-04-01 16:10:04,923 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-04-01 16:10:04,924 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-04-01 16:10:04,926 - INFO - allennlp.common.params - evaluation_data.dataset.name = CommonSenseQA (validation set)\n",
      "2022-04-01 16:10:04,927 - INFO - allennlp.common.params - evaluation_data.dataset.notes = Please download the data from the url provided.\n",
      "2022-04-01 16:10:04,928 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://github.com/jonathanherzig/commonsenseqa\n",
      "2022-04-01 16:10:04,929 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-04-01 16:10:04,930 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-04-01 16:10:04,932 - INFO - allennlp.common.params - training_data.dataset.name = CommonSenseQA (train set)\n",
      "2022-04-01 16:10:04,934 - INFO - allennlp.common.params - training_data.dataset.notes = Please download the data from the url provided.\n",
      "2022-04-01 16:10:04,935 - INFO - allennlp.common.params - training_data.dataset.url = https://github.com/jonathanherzig/commonsenseqa\n",
      "2022-04-01 16:10:04,936 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-04-01 16:10:04,939 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-04-01 16:10:04,941 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = None\n",
      "2022-04-01 16:10:04,942 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-04-01 16:10:04,944 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-04-01 16:10:04,946 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-04-01 16:10:05,022 - INFO - allennlp.common.params - id = glove-sst\n",
      "2022-04-01 16:10:05,023 - INFO - allennlp.common.params - registered_model_name = None\n",
      "2022-04-01 16:10:05,024 - INFO - allennlp.common.params - model_class = None\n",
      "2022-04-01 16:10:05,026 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-04-01 16:10:05,027 - INFO - allennlp.common.params - display_name = GLoVe-LSTM\n",
      "2022-04-01 16:10:05,027 - INFO - allennlp.common.params - task_id = sentiment-analysis\n",
      "2022-04-01 16:10:05,029 - INFO - allennlp.common.params - model_usage.archive_file = basic_stanford_sentiment_treebank-2020.06.09.tar.gz\n",
      "2022-04-01 16:10:05,030 - INFO - allennlp.common.params - model_usage.training_config = classification/basic_stanford_sentiment_treebank.jsonnet\n",
      "2022-04-01 16:10:05,032 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
      "2022-04-01 16:10:05,033 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-04-01 16:10:05,037 - INFO - allennlp.common.params - model_details.description = This model uses GloVe embeddings and is trained on the binary classification setting of the Stanford Sentiment Treebank. It achieves about 87% on the test set.\n",
      "2022-04-01 16:10:05,039 - INFO - allennlp.common.params - model_details.short_description = LSTM binary classifier with GloVe embeddings.\n",
      "2022-04-01 16:10:05,039 - INFO - allennlp.common.params - model_details.developed_by = None\n",
      "2022-04-01 16:10:05,040 - INFO - allennlp.common.params - model_details.contributed_by = None\n",
      "2022-04-01 16:10:05,041 - INFO - allennlp.common.params - model_details.date = 2020-06-09\n",
      "2022-04-01 16:10:05,042 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-04-01 16:10:05,043 - INFO - allennlp.common.params - model_details.model_type = LSTM\n",
      "2022-04-01 16:10:05,043 - INFO - allennlp.common.params - model_details.paper = None\n",
      "2022-04-01 16:10:05,045 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-04-01 16:10:05,046 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-04-01 16:10:05,048 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-04-01 16:10:05,049 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-04-01 16:10:05,050 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-04-01 16:10:05,053 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-04-01 16:10:05,057 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-04-01 16:10:05,059 - INFO - allennlp.common.params - metrics.model_performance_measures = Accuracy\n",
      "2022-04-01 16:10:05,061 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-04-01 16:10:05,063 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-04-01 16:10:05,065 - INFO - allennlp.common.params - evaluation_data.dataset.name = Stanford Sentiment Treebank\n",
      "2022-04-01 16:10:05,066 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = https://allennlp.s3.amazonaws.com/datasets/sst/test.txt\n",
      "2022-04-01 16:10:05,067 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://nlp.stanford.edu/sentiment/treebank.html\n",
      "2022-04-01 16:10:05,068 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-04-01 16:10:05,069 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-04-01 16:10:05,071 - INFO - allennlp.common.params - training_data.dataset.name = Stanford Sentiment Treebank\n",
      "2022-04-01 16:10:05,072 - INFO - allennlp.common.params - training_data.dataset.processed_url = https://allennlp.s3.amazonaws.com/datasets/sst/train.txt\n",
      "2022-04-01 16:10:05,073 - INFO - allennlp.common.params - training_data.dataset.url = https://nlp.stanford.edu/sentiment/treebank.html\n",
      "2022-04-01 16:10:05,073 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-04-01 16:10:05,074 - INFO - allennlp.common.params - training_data.preprocessing = Binary classification setting\n",
      "2022-04-01 16:10:05,076 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = Accuracy: 87% on SST test set.\n",
      "2022-04-01 16:10:05,077 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-04-01 16:10:05,079 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-04-01 16:10:05,081 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-04-01 16:10:05,151 - INFO - allennlp.common.params - id = coref-spanbert\n",
      "2022-04-01 16:10:05,152 - INFO - allennlp.common.params - registered_model_name = coref\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-01 16:10:05,153 - INFO - allennlp.common.params - model_class = None\n",
      "2022-04-01 16:10:05,154 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-04-01 16:10:05,155 - INFO - allennlp.common.params - display_name = Coreference Resolution\n",
      "2022-04-01 16:10:05,156 - INFO - allennlp.common.params - task_id = coref\n",
      "2022-04-01 16:10:05,158 - INFO - allennlp.common.params - model_usage.archive_file = coref-spanbert-large-2021.03.10.tar.gz\n",
      "2022-04-01 16:10:05,159 - INFO - allennlp.common.params - model_usage.training_config = coref/coref_spanbert_large.jsonnet\n",
      "2022-04-01 16:10:05,160 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
      "2022-04-01 16:10:05,161 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-04-01 16:10:05,163 - INFO - allennlp.common.params - model_details.description = The basic outline of this model is to get an embedded representation of each span in the document. These span representations are scored  and used to prune away spans that are unlikely to occur in a coreference  cluster. For the remaining spans, the model decides which antecedent span (if any) they are coreferent with. The resulting coreference links, after applying transitivity, imply a clustering of the spans in the document. The GloVe embeddings in the original paper have been substituted with SpanBERT embeddings.\n",
      "2022-04-01 16:10:05,165 - INFO - allennlp.common.params - model_details.short_description = Higher-order coref with coarse-to-fine inference (with SpanBERT embeddings).\n",
      "2022-04-01 16:10:05,169 - INFO - allennlp.common.params - model_details.developed_by = Lee et al\n",
      "2022-04-01 16:10:05,171 - INFO - allennlp.common.params - model_details.contributed_by = Zhaofeng Wu\n",
      "2022-04-01 16:10:05,172 - INFO - allennlp.common.params - model_details.date = 2020-02-27\n",
      "2022-04-01 16:10:05,173 - INFO - allennlp.common.params - model_details.version = 2\n",
      "2022-04-01 16:10:05,174 - INFO - allennlp.common.params - model_details.model_type = SpanBERT\n",
      "2022-04-01 16:10:05,175 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@inproceedings{Lee2018HigherorderCR,\n",
      "title={Higher-order Coreference Resolution with Coarse-to-fine Inference},\n",
      "author={Kenton Lee and Luheng He and L. Zettlemoyer},\n",
      "booktitle={NAACL-HLT},\n",
      "year={2018}}\n",
      "\n",
      "2022-04-01 16:10:05,176 - INFO - allennlp.common.params - model_details.paper.title = Higher-order Coreference Resolution with Coarse-to-fine Inference\n",
      "2022-04-01 16:10:05,178 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:4891749\n",
      "2022-04-01 16:10:05,180 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-04-01 16:10:05,181 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-04-01 16:10:05,184 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-04-01 16:10:05,186 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-04-01 16:10:05,188 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-04-01 16:10:05,190 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-04-01 16:10:05,191 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-04-01 16:10:05,192 - INFO - allennlp.common.params - metrics.model_performance_measures = CoNLL coref scores and Mention Recall\n",
      "2022-04-01 16:10:05,193 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-04-01 16:10:05,195 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-04-01 16:10:05,197 - INFO - allennlp.common.params - evaluation_data.dataset.name = Ontonotes 5.0\n",
      "2022-04-01 16:10:05,198 - INFO - allennlp.common.params - evaluation_data.dataset.notes = The Coreference model was evaluated on the CoNLL 2012 dataset. Unfortunately we cannot release this data due to licensing restrictions by the LDC. To compile the data in the right format for evaluating the Coreference model, please see scripts/compile_coref_data.sh. This script requires the Ontonotes 5.0 dataset, available on the LDC website.\n",
      "2022-04-01 16:10:05,201 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = /path/to/dataset\n",
      "2022-04-01 16:10:05,202 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://catalog.ldc.upenn.edu/LDC2013T19\n",
      "2022-04-01 16:10:05,203 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-04-01 16:10:05,205 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-04-01 16:10:05,207 - INFO - allennlp.common.params - training_data.dataset.name = Ontonotes 5.0\n",
      "2022-04-01 16:10:05,208 - INFO - allennlp.common.params - training_data.dataset.notes = The Coreference model was evaluated on the CoNLL 2012 dataset. Unfortunately we cannot release this data due to licensing restrictions by the LDC. To compile the data in the right format for evaluating the Coreference model, please see scripts/compile_coref_data.sh. This script requires the Ontonotes 5.0 dataset, available on the LDC website.\n",
      "2022-04-01 16:10:05,209 - INFO - allennlp.common.params - training_data.dataset.processed_url = /path/to/dataset\n",
      "2022-04-01 16:10:05,210 - INFO - allennlp.common.params - training_data.dataset.url = https://catalog.ldc.upenn.edu/LDC2013T19\n",
      "2022-04-01 16:10:05,211 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-04-01 16:10:05,211 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-04-01 16:10:05,213 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = None\n",
      "2022-04-01 16:10:05,214 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-04-01 16:10:05,215 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-04-01 16:10:05,215 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-04-01 16:10:05,275 - INFO - allennlp.common.params - id = nlvr2-vilbert\n",
      "2022-04-01 16:10:05,275 - INFO - allennlp.common.params - registered_model_name = nlvr2\n",
      "2022-04-01 16:10:05,276 - INFO - allennlp.common.params - model_class = None\n",
      "2022-04-01 16:10:05,278 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-04-01 16:10:05,279 - INFO - allennlp.common.params - display_name = Visual Entailment - NLVR2\n",
      "2022-04-01 16:10:05,281 - INFO - allennlp.common.params - task_id = nlvr2\n",
      "2022-04-01 16:10:05,282 - INFO - allennlp.common.params - model_usage.archive_file = vilbert-nlvr2-head-2021.06.01.tar.gz\n",
      "2022-04-01 16:10:05,283 - INFO - allennlp.common.params - model_usage.training_config = vilbert_nlvr2_pretrained.jsonnet\n",
      "2022-04-01 16:10:05,284 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp>=2.5.1 allennlp-models>=2.5.1\n",
      "2022-04-01 16:10:05,285 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-04-01 16:10:05,287 - INFO - allennlp.common.params - model_details.description = This model uses a VilBERT-based backbone with an NLVR2-specific model head. The image features are obtained using the ResNet backbone and Faster RCNN (region detection).\n",
      "2022-04-01 16:10:05,288 - INFO - allennlp.common.params - model_details.short_description = ViLBERT-based model for Visual Entailment.\n",
      "2022-04-01 16:10:05,289 - INFO - allennlp.common.params - model_details.developed_by = Lu et al\n",
      "2022-04-01 16:10:05,289 - INFO - allennlp.common.params - model_details.contributed_by = Jacob Morrison\n",
      "2022-04-01 16:10:05,290 - INFO - allennlp.common.params - model_details.date = 2021-05-27\n",
      "2022-04-01 16:10:05,291 - INFO - allennlp.common.params - model_details.version = 2\n",
      "2022-04-01 16:10:05,292 - INFO - allennlp.common.params - model_details.model_type = ViLBERT based on BERT large\n",
      "2022-04-01 16:10:05,293 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@inproceedings{Lu2019ViLBERTPT,\n",
      "title={ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks},\n",
      "author={Jiasen Lu and Dhruv Batra and D. Parikh and Stefan Lee},\n",
      "booktitle={NeurIPS},\n",
      "year={2019}\n",
      "2022-04-01 16:10:05,295 - INFO - allennlp.common.params - model_details.paper.title = ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-01 16:10:05,296 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:199453025\n",
      "2022-04-01 16:10:05,297 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-04-01 16:10:05,299 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-04-01 16:10:05,300 - INFO - allennlp.common.params - intended_use.primary_uses = This model is developed for the AllenNLP demo.\n",
      "2022-04-01 16:10:05,301 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-04-01 16:10:05,302 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-04-01 16:10:05,303 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-04-01 16:10:05,304 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-04-01 16:10:05,305 - INFO - allennlp.common.params - metrics.model_performance_measures = Accuracy and F1-score\n",
      "2022-04-01 16:10:05,307 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-04-01 16:10:05,308 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-04-01 16:10:05,309 - INFO - allennlp.common.params - evaluation_data.dataset.name = Natural Language for Visual Reasoning For Real dev set\n",
      "2022-04-01 16:10:05,315 - INFO - allennlp.common.params - evaluation_data.dataset.notes = Evaluation requires a large amount of images to be accessible locally, so we cannot provide a command you can easily copy and paste.\n",
      "2022-04-01 16:10:05,315 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://github.com/lil-lab/nlvr/tree/master/nlvr2\n",
      "2022-04-01 16:10:05,317 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-04-01 16:10:05,318 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-04-01 16:10:05,319 - INFO - allennlp.common.params - training_data.dataset.name = Natural Language for Visual Reasoning For Real train set\n",
      "2022-04-01 16:10:05,320 - INFO - allennlp.common.params - training_data.dataset.url = https://github.com/lil-lab/nlvr/tree/master/nlvr2\n",
      "2022-04-01 16:10:05,321 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-04-01 16:10:05,322 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-04-01 16:10:05,324 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = On the validation set:\n",
      "F1: 33.7%\n",
      "Accuracy: 50.8%.\n",
      "These scores do not match the performance in the 12-in-1 paper because this was trained as a standalone task, not as part of a multitask setup. Please contact us if you want to match those scores!\n",
      "2022-04-01 16:10:05,325 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-04-01 16:10:05,327 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-04-01 16:10:05,328 - INFO - allennlp.common.params - model_caveats_and_recommendations = None\n",
      "2022-04-01 16:10:05,379 - INFO - allennlp.common.params - id = tagging-elmo-crf-tagger\n",
      "2022-04-01 16:10:05,380 - INFO - allennlp.common.params - registered_model_name = crf_tagger\n",
      "2022-04-01 16:10:05,381 - INFO - allennlp.common.params - model_class = None\n",
      "2022-04-01 16:10:05,382 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-04-01 16:10:05,382 - INFO - allennlp.common.params - display_name = ELMo-based Named Entity Recognition\n",
      "2022-04-01 16:10:05,383 - INFO - allennlp.common.params - task_id = ner\n",
      "2022-04-01 16:10:05,385 - INFO - allennlp.common.params - model_usage.archive_file = ner-elmo.2021-02-12.tar.gz\n",
      "2022-04-01 16:10:05,386 - INFO - allennlp.common.params - model_usage.training_config = tagging/ner_elmo.jsonnet\n",
      "2022-04-01 16:10:05,387 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
      "2022-04-01 16:10:05,388 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-04-01 16:10:05,389 - INFO - allennlp.common.params - model_details.description = This model is the baseline model described in [Semi-supervised sequence tagging with bidirectional language models](https://api.semanticscholar.org/CorpusID:7197241). It uses a Gated Recurrent Unit (GRU) character encoder as well as a GRU phrase encoder, and it starts with pretrained GloVe vectors for its token embeddings. It was trained on the CoNLL-2003 NER dataset.\n",
      "2022-04-01 16:10:05,390 - INFO - allennlp.common.params - model_details.short_description = NER tagger using a Gated Recurrent Unit (GRU) character encoder as well as a GRU phrase encoder, with GloVe embeddings.\n",
      "2022-04-01 16:10:05,391 - INFO - allennlp.common.params - model_details.developed_by = Peters et al\n",
      "2022-04-01 16:10:05,392 - INFO - allennlp.common.params - model_details.contributed_by = None\n",
      "2022-04-01 16:10:05,393 - INFO - allennlp.common.params - model_details.date = 2020-02-10\n",
      "2022-04-01 16:10:05,394 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-04-01 16:10:05,395 - INFO - allennlp.common.params - model_details.model_type = Gated Recurrent Unit (GRU)\n",
      "2022-04-01 16:10:05,399 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@inproceedings{Peters2017SemisupervisedST,\n",
      "title={Semi-supervised sequence tagging with bidirectional language models},\n",
      "author={Matthew E. Peters and Waleed Ammar and Chandra Bhagavatula and R. Power},\n",
      "booktitle={ACL},\n",
      "year={2017}}\n",
      "\n",
      "2022-04-01 16:10:05,400 - INFO - allennlp.common.params - model_details.paper.title = Semi-supervised sequence tagging with bidirectional language models\n",
      "2022-04-01 16:10:05,401 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:7197241\n",
      "2022-04-01 16:10:05,402 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-04-01 16:10:05,403 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-04-01 16:10:05,405 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-04-01 16:10:05,407 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-04-01 16:10:05,407 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-04-01 16:10:05,409 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-04-01 16:10:05,410 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-04-01 16:10:05,411 - INFO - allennlp.common.params - metrics.model_performance_measures = Accuracy and Span-based F1 metric\n",
      "2022-04-01 16:10:05,412 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-04-01 16:10:05,413 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-04-01 16:10:05,415 - INFO - allennlp.common.params - evaluation_data.dataset.name = CoNLL-2003 NER dataset\n",
      "2022-04-01 16:10:05,416 - INFO - allennlp.common.params - evaluation_data.dataset.notes = The NER model was evaluated on the CoNLL-2003 NER dataset. Unfortunately we cannot release this data due to licensing restrictions.\n",
      "2022-04-01 16:10:05,417 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = path/to/dataset\n",
      "2022-04-01 16:10:05,418 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://www.clips.uantwerpen.be/conll2003/ner/\n",
      "2022-04-01 16:10:05,419 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-04-01 16:10:05,420 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-04-01 16:10:05,421 - INFO - allennlp.common.params - training_data.dataset.name = CoNLL-2003 NER dataset\n",
      "2022-04-01 16:10:05,422 - INFO - allennlp.common.params - training_data.dataset.notes = The NER model was trained on the CoNLL-2003 NER dataset. Unfortunately we cannot release this data due to licensing restrictions.\n",
      "2022-04-01 16:10:05,423 - INFO - allennlp.common.params - training_data.dataset.processed_url = /path/to/dataset\n",
      "2022-04-01 16:10:05,424 - INFO - allennlp.common.params - training_data.dataset.url = https://www.clips.uantwerpen.be/conll2003/ner/\n",
      "2022-04-01 16:10:05,425 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-04-01 16:10:05,426 - INFO - allennlp.common.params - training_data.preprocessing = None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-01 16:10:05,427 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = Achieves 99% accuracy and 96% F1 on the CoNLL-2003 validation set.\n",
      "2022-04-01 16:10:05,429 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-04-01 16:10:05,431 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-04-01 16:10:05,432 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = This model is based on ELMo. ELMo is not deterministic, meaning that you will see slight differences every time you run it. Also, ELMo likes to be warmed up, so we recommend processing dummy input before processing real workloads with it.\n",
      "2022-04-01 16:10:05,485 - INFO - allennlp.common.params - id = semparse-text-to-sql\n",
      "2022-04-01 16:10:05,486 - INFO - allennlp.common.params - registered_model_name = None\n",
      "2022-04-01 16:10:05,487 - INFO - allennlp.common.params - model_class = None\n",
      "2022-04-01 16:10:05,487 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-04-01 16:10:05,488 - INFO - allennlp.common.params - display_name = Text to SQL (ATIS)\n",
      "2022-04-01 16:10:05,489 - INFO - allennlp.common.params - task_id = semparse-text-to-sql\n",
      "2022-04-01 16:10:05,490 - INFO - allennlp.common.params - model_usage.archive_file = https://allennlp.s3.amazonaws.com/models/atis-parser-2020.02.10.tar.gz\n",
      "2022-04-01 16:10:05,491 - INFO - allennlp.common.params - model_usage.training_config = None\n",
      "2022-04-01 16:10:05,491 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==1.0.0 allennlp-models==1.0.0\n",
      "2022-04-01 16:10:05,492 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-04-01 16:10:05,493 - INFO - allennlp.common.params - model_details.description = This model is an implementation of an encoder-decoder architecture with LSTMs and constrained type decoding trained on the ATIS dataset. This model is still a proof-of-concept of what you can do with semantic parsing in AllenNLP and its performance is not state-of-the-art (this naive model gets around 40% exact denotation accuracy on the contextual ATIS dataset).\n",
      "2022-04-01 16:10:05,494 - INFO - allennlp.common.params - model_details.short_description = This model is an implementation of an encoder-decoder architecture with LSTMs and constrained type decoding trained on the ATIS dataset.\n",
      "2022-04-01 16:10:05,495 - INFO - allennlp.common.params - model_details.developed_by = Dasigi et al\n",
      "2022-04-01 16:10:05,496 - INFO - allennlp.common.params - model_details.contributed_by = None\n",
      "2022-04-01 16:10:05,498 - INFO - allennlp.common.params - model_details.date = 2020-02-10\n",
      "2022-04-01 16:10:05,500 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-04-01 16:10:05,503 - INFO - allennlp.common.params - model_details.model_type = None\n",
      "2022-04-01 16:10:05,504 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@inproceedings{Dasigi2019IterativeSF,\n",
      "title={Iterative Search for Weakly Supervised Semantic Parsing},\n",
      "author={Pradeep Dasigi and Matt Gardner and Shikhar Murty and Luke Zettlemoyer and E. Hovy},\n",
      "booktitle={NAACL-HLT},\n",
      "year={2019}}\n",
      "\n",
      "2022-04-01 16:10:05,504 - INFO - allennlp.common.params - model_details.paper.title = Iterative Search for Weakly Supervised Semantic Parsing\n",
      "2022-04-01 16:10:05,505 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:174799945\n",
      "2022-04-01 16:10:05,506 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-04-01 16:10:05,506 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-04-01 16:10:05,508 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-04-01 16:10:05,508 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-04-01 16:10:05,509 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-04-01 16:10:05,510 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-04-01 16:10:05,511 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-04-01 16:10:05,512 - INFO - allennlp.common.params - metrics.model_performance_measures = 1. `exact_match`; the percentage of the time that our best output action sequence matches the SQL query exactly.\n",
      "2. `denotation_acc`; the percentage of examples where we get the correct denotation.\n",
      "3. `valid_sql_query`; the percentage of time that decoding actually produces avalid SQL query.\n",
      "4. `action_similarity`; how similar the action sequence predicted is to the actual action sequence.\n",
      "2022-04-01 16:10:05,514 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-04-01 16:10:05,515 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-04-01 16:10:05,516 - INFO - allennlp.common.params - evaluation_data.dataset.name = ATIS\n",
      "2022-04-01 16:10:05,519 - INFO - allennlp.common.params - evaluation_data.dataset.notes = Please download the data from the url provided.\n",
      "2022-04-01 16:10:05,519 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://api.semanticscholar.org/CorpusID:1094063\n",
      "2022-04-01 16:10:05,520 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-04-01 16:10:05,521 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-04-01 16:10:05,522 - INFO - allennlp.common.params - training_data.dataset.name = ATIS\n",
      "2022-04-01 16:10:05,523 - INFO - allennlp.common.params - training_data.dataset.notes = Please download the data from the url provided.\n",
      "2022-04-01 16:10:05,525 - INFO - allennlp.common.params - training_data.dataset.url = https://api.semanticscholar.org/CorpusID:1094063\n",
      "2022-04-01 16:10:05,526 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-04-01 16:10:05,527 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-04-01 16:10:05,528 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = None\n",
      "2022-04-01 16:10:05,529 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-04-01 16:10:05,531 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-04-01 16:10:05,533 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-04-01 16:10:05,595 - INFO - allennlp.common.params - id = tagging-fine-grained-transformer-crf-tagger\n",
      "2022-04-01 16:10:05,597 - INFO - allennlp.common.params - registered_model_name = crf_tagger\n",
      "2022-04-01 16:10:05,599 - INFO - allennlp.common.params - model_class = None\n",
      "2022-04-01 16:10:05,599 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-04-01 16:10:05,600 - INFO - allennlp.common.params - display_name = Fine Grained Named Entity Recognition with Transformer\n",
      "2022-04-01 16:10:05,602 - INFO - allennlp.common.params - task_id = ner\n",
      "2022-04-01 16:10:05,603 - INFO - allennlp.common.params - model_usage.archive_file = fgner-transformer.2021-02-11.tar.gz\n",
      "2022-04-01 16:10:05,605 - INFO - allennlp.common.params - model_usage.training_config = tagging/fgner_transformer.jsonnet\n",
      "2022-04-01 16:10:05,606 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
      "2022-04-01 16:10:05,607 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-04-01 16:10:05,608 - INFO - allennlp.common.params - model_details.description = Fine-grained NER model\n",
      "2022-04-01 16:10:05,609 - INFO - allennlp.common.params - model_details.short_description = Fine-grained NER model\n",
      "2022-04-01 16:10:05,610 - INFO - allennlp.common.params - model_details.developed_by = None\n",
      "2022-04-01 16:10:05,610 - INFO - allennlp.common.params - model_details.contributed_by = None\n",
      "2022-04-01 16:10:05,611 - INFO - allennlp.common.params - model_details.date = 2020-07-14\n",
      "2022-04-01 16:10:05,611 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-04-01 16:10:05,612 - INFO - allennlp.common.params - model_details.model_type = Transformer\n",
      "2022-04-01 16:10:05,614 - INFO - allennlp.common.params - model_details.paper = None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-01 16:10:05,615 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-04-01 16:10:05,615 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-04-01 16:10:05,617 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-04-01 16:10:05,619 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-04-01 16:10:05,619 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-04-01 16:10:05,621 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-04-01 16:10:05,622 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-04-01 16:10:05,623 - INFO - allennlp.common.params - metrics.model_performance_measures = Accuracy and Span-based F1 metric\n",
      "2022-04-01 16:10:05,624 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-04-01 16:10:05,625 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-04-01 16:10:05,626 - INFO - allennlp.common.params - evaluation_data.dataset.name = Ontonotes 5.0\n",
      "2022-04-01 16:10:05,627 - INFO - allennlp.common.params - evaluation_data.dataset.notes = Unfortunately we cannot release this data due to licensing restrictions.\n",
      "2022-04-01 16:10:05,628 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://catalog.ldc.upenn.edu/LDC2013T19\n",
      "2022-04-01 16:10:05,629 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-04-01 16:10:05,634 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-04-01 16:10:05,637 - INFO - allennlp.common.params - training_data.dataset.name = Ontonotes 5.0\n",
      "2022-04-01 16:10:05,638 - INFO - allennlp.common.params - training_data.dataset.notes = Unfortunately we cannot release this data due to licensing restrictions.\n",
      "2022-04-01 16:10:05,639 - INFO - allennlp.common.params - training_data.dataset.url = https://catalog.ldc.upenn.edu/LDC2013T19\n",
      "2022-04-01 16:10:05,640 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-04-01 16:10:05,641 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-04-01 16:10:05,642 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = On the validation set:\n",
      "Accuracy: 98%\n",
      "F1: 88%\n",
      "2022-04-01 16:10:05,643 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-04-01 16:10:05,645 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-04-01 16:10:05,647 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-04-01 16:10:05,703 - INFO - allennlp.common.params - id = nlvr2-vilbert\n",
      "2022-04-01 16:10:05,704 - INFO - allennlp.common.params - registered_model_name = nlvr2\n",
      "2022-04-01 16:10:05,705 - INFO - allennlp.common.params - model_class = None\n",
      "2022-04-01 16:10:05,706 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-04-01 16:10:05,707 - INFO - allennlp.common.params - display_name = Visual Entailment - NLVR2\n",
      "2022-04-01 16:10:05,708 - INFO - allennlp.common.params - task_id = nlvr2\n",
      "2022-04-01 16:10:05,709 - INFO - allennlp.common.params - model_usage.archive_file = vilbert-nlvr2-2021.06.01.tar.gz\n",
      "2022-04-01 16:10:05,711 - INFO - allennlp.common.params - model_usage.training_config = vilbert_nlvr2_pretrained.jsonnet\n",
      "2022-04-01 16:10:05,712 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp>=2.5.1 allennlp-models>=2.5.1\n",
      "2022-04-01 16:10:05,714 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-04-01 16:10:05,715 - INFO - allennlp.common.params - model_details.description = This model is based on the ViLBERT multitask architecture. The image features are obtained using the ResNet backbone and Faster RCNN (region detection).\n",
      "2022-04-01 16:10:05,716 - INFO - allennlp.common.params - model_details.short_description = ViLBERT-based model for Visual Entailment.\n",
      "2022-04-01 16:10:05,717 - INFO - allennlp.common.params - model_details.developed_by = Lu et al\n",
      "2022-04-01 16:10:05,719 - INFO - allennlp.common.params - model_details.contributed_by = Jacob Morrison\n",
      "2022-04-01 16:10:05,719 - INFO - allennlp.common.params - model_details.date = 2021-05-27\n",
      "2022-04-01 16:10:05,720 - INFO - allennlp.common.params - model_details.version = 2\n",
      "2022-04-01 16:10:05,721 - INFO - allennlp.common.params - model_details.model_type = ViLBERT based on BERT large\n",
      "2022-04-01 16:10:05,722 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@inproceedings{Lu2019ViLBERTPT,\n",
      "title={ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks},\n",
      "author={Jiasen Lu and Dhruv Batra and D. Parikh and Stefan Lee},\n",
      "booktitle={NeurIPS},\n",
      "year={2019}\n",
      "2022-04-01 16:10:05,723 - INFO - allennlp.common.params - model_details.paper.title = ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks\n",
      "2022-04-01 16:10:05,723 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:199453025\n",
      "2022-04-01 16:10:05,724 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-04-01 16:10:05,725 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-04-01 16:10:05,726 - INFO - allennlp.common.params - intended_use.primary_uses = This model is developed for the AllenNLP demo.\n",
      "2022-04-01 16:10:05,727 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-04-01 16:10:05,728 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-04-01 16:10:05,730 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-04-01 16:10:05,735 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-04-01 16:10:05,736 - INFO - allennlp.common.params - metrics.model_performance_measures = Accuracy and F1-score\n",
      "2022-04-01 16:10:05,737 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-04-01 16:10:05,737 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-04-01 16:10:05,739 - INFO - allennlp.common.params - evaluation_data.dataset.name = Natural Language for Visual Reasoning For Real dev set\n",
      "2022-04-01 16:10:05,740 - INFO - allennlp.common.params - evaluation_data.dataset.notes = Evaluation requires a large amount of images to be accessible locally, so we cannot provide a command you can easily copy and paste.\n",
      "2022-04-01 16:10:05,740 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://github.com/lil-lab/nlvr/tree/master/nlvr2\n",
      "2022-04-01 16:10:05,741 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-04-01 16:10:05,742 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-04-01 16:10:05,743 - INFO - allennlp.common.params - training_data.dataset.name = Natural Language for Visual Reasoning For Real train set\n",
      "2022-04-01 16:10:05,744 - INFO - allennlp.common.params - training_data.dataset.url = https://github.com/lil-lab/nlvr/tree/master/nlvr2\n",
      "2022-04-01 16:10:05,745 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-04-01 16:10:05,746 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-04-01 16:10:05,748 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = On the validation set:\n",
      "F1: 33.7%\n",
      "Accuracy: 50.8%.\n",
      "These scores do not match the performance in the 12-in-1 paper because this was trained as a standalone task, not as part of a multitask setup. Please contact us if you want to match those scores!\n",
      "2022-04-01 16:10:05,749 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-04-01 16:10:05,751 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-04-01 16:10:05,752 - INFO - allennlp.common.params - model_caveats_and_recommendations = None\n",
      "2022-04-01 16:10:05,805 - INFO - allennlp.common.params - id = pair-classification-roberta-snli\n",
      "2022-04-01 16:10:05,806 - INFO - allennlp.common.params - registered_model_name = basic_classifier\n",
      "2022-04-01 16:10:05,807 - INFO - allennlp.common.params - model_class = None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-01 16:10:05,808 - INFO - allennlp.common.params - registered_predictor_name = textual_entailment\n",
      "2022-04-01 16:10:05,810 - INFO - allennlp.common.params - display_name = RoBERTa SNLI\n",
      "2022-04-01 16:10:05,811 - INFO - allennlp.common.params - task_id = textual_entailment\n",
      "2022-04-01 16:10:05,813 - INFO - allennlp.common.params - model_usage.archive_file = snli-roberta.2021-03-11.tar.gz\n",
      "2022-04-01 16:10:05,815 - INFO - allennlp.common.params - model_usage.training_config = pair_classification/snli_roberta.jsonnet\n",
      "2022-04-01 16:10:05,816 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
      "2022-04-01 16:10:05,817 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-04-01 16:10:05,820 - INFO - allennlp.common.params - model_details.description = This `Model` implements a basic text classifier. The text is embedded into a text field using a RoBERTa-large model. The resulting sequence is pooled using a cls_pooler `Seq2VecEncoder` and then passed to a linear classification layer, which projects into the label space.\n",
      "2022-04-01 16:10:05,821 - INFO - allennlp.common.params - model_details.short_description = RoBERTa finetuned on SNLI.\n",
      "2022-04-01 16:10:05,822 - INFO - allennlp.common.params - model_details.developed_by = Liu et al\n",
      "2022-04-01 16:10:05,822 - INFO - allennlp.common.params - model_details.contributed_by = Dirk Groeneveld\n",
      "2022-04-01 16:10:05,823 - INFO - allennlp.common.params - model_details.date = 2020-07-29\n",
      "2022-04-01 16:10:05,824 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-04-01 16:10:05,825 - INFO - allennlp.common.params - model_details.model_type = RoBERTa\n",
      "2022-04-01 16:10:05,826 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@article{Liu2019RoBERTaAR,\n",
      "title={RoBERTa: A Robustly Optimized BERT Pretraining Approach},\n",
      "author={Y. Liu and Myle Ott and Naman Goyal and Jingfei Du and Mandar Joshi and Danqi Chen and Omer Levy and M. Lewis and Luke Zettlemoyer and Veselin Stoyanov},\n",
      "journal={ArXiv},\n",
      "year={2019},\n",
      "volume={abs/1907.11692}}\n",
      "\n",
      "2022-04-01 16:10:05,826 - INFO - allennlp.common.params - model_details.paper.title = RoBERTa: A Robustly Optimized BERT Pretraining Approach (Liu et al)\n",
      "2022-04-01 16:10:05,827 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:198953378\n",
      "2022-04-01 16:10:05,829 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-04-01 16:10:05,831 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-04-01 16:10:05,832 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-04-01 16:10:05,834 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-04-01 16:10:05,835 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-04-01 16:10:05,836 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-04-01 16:10:05,837 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-04-01 16:10:05,838 - INFO - allennlp.common.params - metrics.model_performance_measures = Accuracy\n",
      "2022-04-01 16:10:05,839 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-04-01 16:10:05,839 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-04-01 16:10:05,841 - INFO - allennlp.common.params - evaluation_data.dataset.name = Stanford Natural Language Inference (SNLI) dev set\n",
      "2022-04-01 16:10:05,843 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = https://allennlp.s3.amazonaws.com/datasets/snli/snli_1.0_test.jsonl\n",
      "2022-04-01 16:10:05,844 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://nlp.stanford.edu/projects/snli/\n",
      "2022-04-01 16:10:05,845 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-04-01 16:10:05,845 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-04-01 16:10:05,848 - INFO - allennlp.common.params - training_data.dataset.name = Stanford Natural Language Inference (SNLI) train set\n",
      "2022-04-01 16:10:05,848 - INFO - allennlp.common.params - training_data.dataset.processed_url = https://allennlp.s3.amazonaws.com/datasets/snli/snli_1.0_train.jsonl\n",
      "2022-04-01 16:10:05,849 - INFO - allennlp.common.params - training_data.dataset.url = https://nlp.stanford.edu/projects/snli/\n",
      "2022-04-01 16:10:05,850 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-04-01 16:10:05,851 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-04-01 16:10:05,852 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = Net Neutral: 0.49562665820121765, Fraction Neutral: 0.5068705677986145, Threshold:0.5: 0.47600528597831726, Threshold:0.7: 0.3036800026893616\n",
      "2022-04-01 16:10:05,853 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-04-01 16:10:05,854 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-04-01 16:10:05,855 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-04-01 16:10:05,908 - INFO - allennlp.common.params - id = semparse-wikitables\n",
      "2022-04-01 16:10:05,909 - INFO - allennlp.common.params - registered_model_name = None\n",
      "2022-04-01 16:10:05,910 - INFO - allennlp.common.params - model_class = None\n",
      "2022-04-01 16:10:05,911 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-04-01 16:10:05,912 - INFO - allennlp.common.params - display_name = WikiTables Semantic Parsing\n",
      "2022-04-01 16:10:05,913 - INFO - allennlp.common.params - task_id = semparse-tabular\n",
      "2022-04-01 16:10:05,915 - INFO - allennlp.common.params - model_usage.archive_file = wikitables-model-2020.02.10.tar.gz\n",
      "2022-04-01 16:10:05,916 - INFO - allennlp.common.params - model_usage.training_config = None\n",
      "2022-04-01 16:10:05,916 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==1.0.0 allennlp-models==1.0.0\n",
      "2022-04-01 16:10:05,917 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-04-01 16:10:05,919 - INFO - allennlp.common.params - model_details.description = The model is a semantic parser trained on WikiTableQuestions.\n",
      "2022-04-01 16:10:05,919 - INFO - allennlp.common.params - model_details.short_description = The model is a semantic parser trained on WikiTableQuestions.\n",
      "2022-04-01 16:10:05,920 - INFO - allennlp.common.params - model_details.developed_by = Dasigi et al\n",
      "2022-04-01 16:10:05,921 - INFO - allennlp.common.params - model_details.contributed_by = None\n",
      "2022-04-01 16:10:05,922 - INFO - allennlp.common.params - model_details.date = 2020-02-10\n",
      "2022-04-01 16:10:05,922 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-04-01 16:10:05,923 - INFO - allennlp.common.params - model_details.model_type = None\n",
      "2022-04-01 16:10:05,924 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@inproceedings{Dasigi2019IterativeSF,\n",
      "title={Iterative Search for Weakly Supervised Semantic Parsing},\n",
      "author={Pradeep Dasigi and Matt Gardner and Shikhar Murty and Luke Zettlemoyer and E. Hovy},\n",
      "booktitle={NAACL-HLT},\n",
      "year={2019}}\n",
      "\n",
      "2022-04-01 16:10:05,925 - INFO - allennlp.common.params - model_details.paper.title = Iterative Search for Weakly Supervised Semantic Parsing\n",
      "2022-04-01 16:10:05,926 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:174799945\n",
      "2022-04-01 16:10:05,926 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-04-01 16:10:05,927 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-04-01 16:10:05,928 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-04-01 16:10:05,929 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-04-01 16:10:05,930 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-04-01 16:10:05,933 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-04-01 16:10:05,934 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-04-01 16:10:05,935 - INFO - allennlp.common.params - metrics.model_performance_measures = 1. `lf_retrieval_acc`; the percentage of the time that our best output action sequence is in the set of action sequences provided by offline search.\n",
      "2. `denotation_acc`; the percentage of examples where we get the correct denotation.\n",
      "3. `lf_percent`; the percentage of time that decoding actually produces a finished logical form\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-01 16:10:05,936 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-04-01 16:10:05,937 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-04-01 16:10:05,938 - INFO - allennlp.common.params - evaluation_data.dataset.name = WikiTableQuestions\n",
      "2022-04-01 16:10:05,939 - INFO - allennlp.common.params - evaluation_data.dataset.notes = Please download the data from the url provided.\n",
      "2022-04-01 16:10:05,939 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://ppasupat.github.io/WikiTableQuestions/\n",
      "2022-04-01 16:10:05,940 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-04-01 16:10:05,941 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-04-01 16:10:05,942 - INFO - allennlp.common.params - training_data.dataset.name = WikiTableQuestions\n",
      "2022-04-01 16:10:05,943 - INFO - allennlp.common.params - training_data.dataset.notes = Please download the data from the url provided.\n",
      "2022-04-01 16:10:05,944 - INFO - allennlp.common.params - training_data.dataset.url = https://ppasupat.github.io/WikiTableQuestions/\n",
      "2022-04-01 16:10:05,945 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-04-01 16:10:05,945 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-04-01 16:10:05,947 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = None\n",
      "2022-04-01 16:10:05,948 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-04-01 16:10:05,949 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-04-01 16:10:05,955 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-04-01 16:10:06,005 - INFO - allennlp.common.params - id = structured-prediction-srl-bert\n",
      "2022-04-01 16:10:06,006 - INFO - allennlp.common.params - registered_model_name = srl_bert\n",
      "2022-04-01 16:10:06,007 - INFO - allennlp.common.params - model_class = None\n",
      "2022-04-01 16:10:06,007 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-04-01 16:10:06,008 - INFO - allennlp.common.params - display_name = SRL BERT\n",
      "2022-04-01 16:10:06,009 - INFO - allennlp.common.params - task_id = srl\n",
      "2022-04-01 16:10:06,009 - INFO - allennlp.common.params - model_usage.archive_file = structured-prediction-srl-bert.2020.12.15.tar.gz\n",
      "2022-04-01 16:10:06,010 - INFO - allennlp.common.params - model_usage.training_config = structured_prediction/bert_base_srl.jsonnet\n",
      "2022-04-01 16:10:06,011 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
      "2022-04-01 16:10:06,013 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-04-01 16:10:06,014 - INFO - allennlp.common.params - model_details.description = An implementation of a BERT based model (Shi et al, 2019) with some modifications (no additional parameters apart from a linear classification layer), which is currently the state of the art single model for English PropBank SRL (Newswire sentences). It achieves 86.49 test F1 on the Ontonotes 5.0 dataset.\n",
      "2022-04-01 16:10:06,015 - INFO - allennlp.common.params - model_details.short_description = A BERT based model (Shi et al, 2019) with some modifications (no additional parameters apart from a linear classification layer)\n",
      "2022-04-01 16:10:06,016 - INFO - allennlp.common.params - model_details.developed_by = Shi et al\n",
      "2022-04-01 16:10:06,018 - INFO - allennlp.common.params - model_details.contributed_by = None\n",
      "2022-04-01 16:10:06,019 - INFO - allennlp.common.params - model_details.date = 2020-09-03\n",
      "2022-04-01 16:10:06,019 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-04-01 16:10:06,020 - INFO - allennlp.common.params - model_details.model_type = BERT\n",
      "2022-04-01 16:10:06,021 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@article{Shi2019SimpleBM,\n",
      "title={Simple BERT Models for Relation Extraction and Semantic Role Labeling},\n",
      "author={Peng Shi and Jimmy Lin},\n",
      "journal={ArXiv},\n",
      "year={2019},\n",
      "volume={abs/1904.05255}}\n",
      "\n",
      "2022-04-01 16:10:06,022 - INFO - allennlp.common.params - model_details.paper.title = Simple BERT Models for Relation Extraction and Semantic Role Labeling\n",
      "2022-04-01 16:10:06,022 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:131773936\n",
      "2022-04-01 16:10:06,023 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-04-01 16:10:06,024 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-04-01 16:10:06,025 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-04-01 16:10:06,026 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-04-01 16:10:06,027 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-04-01 16:10:06,028 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-04-01 16:10:06,029 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-04-01 16:10:06,031 - INFO - allennlp.common.params - metrics.model_performance_measures = Precision, recall and F1-score\n",
      "2022-04-01 16:10:06,032 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-04-01 16:10:06,032 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-04-01 16:10:06,034 - INFO - allennlp.common.params - evaluation_data.dataset.name = Ontonotes 5.0\n",
      "2022-04-01 16:10:06,035 - INFO - allennlp.common.params - evaluation_data.dataset.notes = We cannot release this data due to licensing restrictions.\n",
      "2022-04-01 16:10:06,036 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://catalog.ldc.upenn.edu/LDC2013T19\n",
      "2022-04-01 16:10:06,037 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-04-01 16:10:06,038 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-04-01 16:10:06,041 - INFO - allennlp.common.params - training_data.dataset.name = Ontonotes 5.0\n",
      "2022-04-01 16:10:06,041 - INFO - allennlp.common.params - training_data.dataset.notes = We cannot release this data due to licensing restrictions.\n",
      "2022-04-01 16:10:06,042 - INFO - allennlp.common.params - training_data.dataset.url = https://catalog.ldc.upenn.edu/LDC2013T19\n",
      "2022-04-01 16:10:06,043 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-04-01 16:10:06,044 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-04-01 16:10:06,045 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = 86.49 test F1 on the Ontonotes 5.0 dataset\n",
      "2022-04-01 16:10:06,046 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-04-01 16:10:06,048 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-04-01 16:10:06,049 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-04-01 16:10:06,108 - INFO - allennlp.common.params - id = structured-prediction-srl\n",
      "2022-04-01 16:10:06,109 - INFO - allennlp.common.params - registered_model_name = srl\n",
      "2022-04-01 16:10:06,110 - INFO - allennlp.common.params - model_class = None\n",
      "2022-04-01 16:10:06,110 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-04-01 16:10:06,111 - INFO - allennlp.common.params - display_name = Open Information Extraction\n",
      "2022-04-01 16:10:06,112 - INFO - allennlp.common.params - task_id = srl\n",
      "2022-04-01 16:10:06,115 - INFO - allennlp.common.params - model_usage.archive_file = openie-model.2020.03.26.tar.gz\n",
      "2022-04-01 16:10:06,116 - INFO - allennlp.common.params - model_usage.training_config = structured-prediction/srl.jsonnet\n",
      "2022-04-01 16:10:06,117 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
      "2022-04-01 16:10:06,119 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-04-01 16:10:06,120 - INFO - allennlp.common.params - model_details.description = A reimplementation of a deep BiLSTM sequence prediction model (Stanovsky et al., 2018).\n",
      "2022-04-01 16:10:06,122 - INFO - allennlp.common.params - model_details.short_description = A reimplementation of a deep BiLSTM sequence prediction model (Stanovsky et al., 2018)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-01 16:10:06,123 - INFO - allennlp.common.params - model_details.developed_by = Stanovsky et al\n",
      "2022-04-01 16:10:06,125 - INFO - allennlp.common.params - model_details.contributed_by = None\n",
      "2022-04-01 16:10:06,126 - INFO - allennlp.common.params - model_details.date = 2020-03-26\n",
      "2022-04-01 16:10:06,127 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-04-01 16:10:06,129 - INFO - allennlp.common.params - model_details.model_type = BiLSTM\n",
      "2022-04-01 16:10:06,130 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@inproceedings{Stanovsky2018SupervisedOI,\n",
      "title={Supervised Open Information Extraction},\n",
      "author={Gabriel Stanovsky and Julian Michael and Luke Zettlemoyer and I. Dagan},\n",
      "booktitle={NAACL-HLT},\n",
      "year={2018}}\n",
      "\n",
      "2022-04-01 16:10:06,131 - INFO - allennlp.common.params - model_details.paper.title = Supervised Open Information Extraction\n",
      "2022-04-01 16:10:06,132 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:44145304\n",
      "2022-04-01 16:10:06,133 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-04-01 16:10:06,134 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-04-01 16:10:06,135 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-04-01 16:10:06,136 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-04-01 16:10:06,137 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-04-01 16:10:06,138 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-04-01 16:10:06,139 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-04-01 16:10:06,141 - INFO - allennlp.common.params - metrics.model_performance_measures = CoNLL SRL metrics\n",
      "2022-04-01 16:10:06,142 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-04-01 16:10:06,143 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-04-01 16:10:06,145 - INFO - allennlp.common.params - evaluation_data.dataset.name = OIE2016, WEB and NYT, PENN\n",
      "2022-04-01 16:10:06,146 - INFO - allennlp.common.params - evaluation_data.dataset.notes = The Open Information extractor was evaluated on the OIE2016 corpus. Unfortunately we cannot release this data due to licensing restrictions by the LDC. You can get the data on the corpus homepage.\n",
      "2022-04-01 16:10:06,148 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://github.com/gabrielStanovsky/oie-benchmark\n",
      "2022-04-01 16:10:06,149 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-04-01 16:10:06,151 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-04-01 16:10:06,153 - INFO - allennlp.common.params - training_data.dataset.name = All Words Open IE\n",
      "2022-04-01 16:10:06,156 - INFO - allennlp.common.params - training_data.dataset.url = https://github.com/gabrielStanovsky/supervised-oie/tree/master/data\n",
      "2022-04-01 16:10:06,157 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-04-01 16:10:06,158 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-04-01 16:10:06,159 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = None\n",
      "2022-04-01 16:10:06,160 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-04-01 16:10:06,162 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-04-01 16:10:06,164 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-04-01 16:10:06,217 - INFO - allennlp.common.params - id = ve-vilbert\n",
      "2022-04-01 16:10:06,219 - INFO - allennlp.common.params - registered_model_name = ve_vilbert\n",
      "2022-04-01 16:10:06,220 - INFO - allennlp.common.params - model_class = None\n",
      "2022-04-01 16:10:06,221 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-04-01 16:10:06,222 - INFO - allennlp.common.params - display_name = Visual Entailment\n",
      "2022-04-01 16:10:06,224 - INFO - allennlp.common.params - task_id = ve\n",
      "2022-04-01 16:10:06,225 - INFO - allennlp.common.params - model_usage.archive_file = visual-entailment-torchvision-2021.03.04.tar.gz\n",
      "2022-04-01 16:10:06,227 - INFO - allennlp.common.params - model_usage.training_config = vilbert_ve_pretrained.jsonnet\n",
      "2022-04-01 16:10:06,228 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==1.0.0 allennlp-models==1.0.0\n",
      "2022-04-01 16:10:06,229 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-04-01 16:10:06,231 - INFO - allennlp.common.params - model_details.description = This model is based on the ViLBERT architecture. The image features are obtained using the ResNet backbone and Faster RCNN (region detection).\n",
      "2022-04-01 16:10:06,232 - INFO - allennlp.common.params - model_details.short_description = ViLBERT-based model for Visual Entailment.\n",
      "2022-04-01 16:10:06,233 - INFO - allennlp.common.params - model_details.developed_by = Lu et al\n",
      "2022-04-01 16:10:06,234 - INFO - allennlp.common.params - model_details.contributed_by = Akshita Bhagia\n",
      "2022-04-01 16:10:06,235 - INFO - allennlp.common.params - model_details.date = 2021-03-04\n",
      "2022-04-01 16:10:06,236 - INFO - allennlp.common.params - model_details.version = 2\n",
      "2022-04-01 16:10:06,237 - INFO - allennlp.common.params - model_details.model_type = ViLBERT based on BERT large\n",
      "2022-04-01 16:10:06,238 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@inproceedings{Lu2019ViLBERTPT,\n",
      "title={ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks},\n",
      "author={Jiasen Lu and Dhruv Batra and D. Parikh and Stefan Lee},\n",
      "booktitle={NeurIPS},\n",
      "year={2019}\n",
      "2022-04-01 16:10:06,239 - INFO - allennlp.common.params - model_details.paper.title = ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks\n",
      "2022-04-01 16:10:06,239 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:199453025\n",
      "2022-04-01 16:10:06,240 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-04-01 16:10:06,241 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-04-01 16:10:06,242 - INFO - allennlp.common.params - intended_use.primary_uses = This model is developed for the AllenNLP demo.\n",
      "2022-04-01 16:10:06,242 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-04-01 16:10:06,243 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-04-01 16:10:06,244 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-04-01 16:10:06,245 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-04-01 16:10:06,246 - INFO - allennlp.common.params - metrics.model_performance_measures = Accuracy and F1-score\n",
      "2022-04-01 16:10:06,247 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-04-01 16:10:06,248 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-04-01 16:10:06,250 - INFO - allennlp.common.params - evaluation_data.dataset.name = Stanford Natural Language Inference - Visual Entailment(SNLI-VE) dev set\n",
      "2022-04-01 16:10:06,251 - INFO - allennlp.common.params - evaluation_data.dataset.notes = Evaluation requires a large amount of images to be accessible locally, so we cannot provide a command you can easily copy and paste.\n",
      "2022-04-01 16:10:06,251 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://github.com/necla-ml/SNLI-VE\n",
      "2022-04-01 16:10:06,252 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-04-01 16:10:06,253 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-04-01 16:10:06,254 - INFO - allennlp.common.params - training_data.dataset.name = Stanford Natural Language Inference - Visual Entailment(SNLI-VE) train set\n",
      "2022-04-01 16:10:06,255 - INFO - allennlp.common.params - training_data.dataset.url = https://github.com/necla-ml/SNLI-VE\n",
      "2022-04-01 16:10:06,256 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-04-01 16:10:06,256 - INFO - allennlp.common.params - training_data.preprocessing = None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-01 16:10:06,258 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = None\n",
      "2022-04-01 16:10:06,258 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-04-01 16:10:06,259 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-04-01 16:10:06,261 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = This model is trained on the original SNLI-VE dataset. [Subsequent work](https://api.semanticscholar.org/CorpusID:215415945) has found that an estimated 31% of `neutral` labels in the dataset are incorrect. The `e-SNLI-VE-2.0` dataset contains the re-annotated validation and test sets.\n",
      "2022-04-01 16:10:06,317 - INFO - allennlp.common.params - id = vgqa-vilbert\n",
      "2022-04-01 16:10:06,318 - INFO - allennlp.common.params - registered_model_name = vqa_vilbert_from_huggingface\n",
      "2022-04-01 16:10:06,319 - INFO - allennlp.common.params - model_class = None\n",
      "2022-04-01 16:10:06,320 - INFO - allennlp.common.params - registered_predictor_name = vgqa_vilbert\n",
      "2022-04-01 16:10:06,320 - INFO - allennlp.common.params - display_name = ViLBERT - Visual Genome Question Answering\n",
      "2022-04-01 16:10:06,321 - INFO - allennlp.common.params - task_id = vgqa\n",
      "2022-04-01 16:10:06,322 - INFO - allennlp.common.params - model_usage.archive_file = vilbert-vgqa-pretrained.2021-05-10.tar.gz\n",
      "2022-04-01 16:10:06,323 - INFO - allennlp.common.params - model_usage.training_config = vision/vilbert_vgqa_pretrained.jsonnet\n",
      "2022-04-01 16:10:06,324 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.5.0 allennlp-models==2.5.0\n",
      "2022-04-01 16:10:06,325 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-04-01 16:10:06,326 - INFO - allennlp.common.params - model_details.description = ViLBERT (short for Vision-and-Language BERT), is a model for learning task-agnostic joint representations of image content and natural language.\n",
      "2022-04-01 16:10:06,327 - INFO - allennlp.common.params - model_details.short_description = ViLBERT (short for Vision-and-Language BERT), is a model for learning task-agnostic joint representations of image content and natural language.\n",
      "2022-04-01 16:10:06,328 - INFO - allennlp.common.params - model_details.developed_by = Lu et al\n",
      "2022-04-01 16:10:06,329 - INFO - allennlp.common.params - model_details.contributed_by = Jacob Morrison\n",
      "2022-04-01 16:10:06,330 - INFO - allennlp.common.params - model_details.date = 2021-05-07\n",
      "2022-04-01 16:10:06,331 - INFO - allennlp.common.params - model_details.version = 2\n",
      "2022-04-01 16:10:06,331 - INFO - allennlp.common.params - model_details.model_type = ViLBERT based on BERT large\n",
      "2022-04-01 16:10:06,332 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@inproceedings{Lu2019ViLBERTPT,\n",
      "title={ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks},\n",
      "author={Jiasen Lu and Dhruv Batra and D. Parikh and Stefan Lee},\n",
      "booktitle={NeurIPS},\n",
      "year={2019}\n",
      "}\n",
      "2022-04-01 16:10:06,333 - INFO - allennlp.common.params - model_details.paper.title = ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks\n",
      "2022-04-01 16:10:06,333 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:199453025\n",
      "2022-04-01 16:10:06,334 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-04-01 16:10:06,335 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-04-01 16:10:06,337 - INFO - allennlp.common.params - intended_use.primary_uses = This model is developed for the AllenNLP demo.\n",
      "2022-04-01 16:10:06,338 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-04-01 16:10:06,339 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-04-01 16:10:06,340 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-04-01 16:10:06,341 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-04-01 16:10:06,342 - INFO - allennlp.common.params - metrics.model_performance_measures = F1-metric and VQA score\n",
      "2022-04-01 16:10:06,343 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-04-01 16:10:06,344 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-04-01 16:10:06,346 - INFO - allennlp.common.params - evaluation_data.dataset.name = VGQA dataset\n",
      "2022-04-01 16:10:06,350 - INFO - allennlp.common.params - evaluation_data.dataset.notes = Evaluation requires a large amount of images to be accessible locally, so we cannot provide a command you can easily copy and paste. The first time you run it, you will get an error message that tells you how to get the rest of the data.\n",
      "2022-04-01 16:10:06,352 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = https://visualgenome.org/static/data/dataset/question_answers.json.zip!question_answers.json[:5000]\n",
      "2022-04-01 16:10:06,352 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://visualgenome.org/\n",
      "2022-04-01 16:10:06,353 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-04-01 16:10:06,354 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-04-01 16:10:06,355 - INFO - allennlp.common.params - training_data.dataset.name = VGQA dataset\n",
      "2022-04-01 16:10:06,356 - INFO - allennlp.common.params - training_data.dataset.notes = Training requires a large amount of images to be accessible locally, so we cannot provide a command you can easily copy and paste. The first time you run it, you will get an error message that tells you how to get the rest of the data.\n",
      "2022-04-01 16:10:06,357 - INFO - allennlp.common.params - training_data.dataset.processed_url = https://visualgenome.org/static/data/dataset/question_answers.json.zip!question_answers.json[5000:]\n",
      "2022-04-01 16:10:06,358 - INFO - allennlp.common.params - training_data.dataset.url = https://visualgenome.org/\n",
      "2022-04-01 16:10:06,358 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-04-01 16:10:06,359 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-04-01 16:10:06,360 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = On the validation set:\n",
      "F1: 29.6%\n",
      "VQA: 26.5%.\n",
      "These scores do not match the performance in the VilBERT paper. Please contact us if you want to match those scores!\n",
      "2022-04-01 16:10:06,363 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-04-01 16:10:06,365 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-04-01 16:10:06,366 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-04-01 16:10:06,417 - INFO - allennlp.common.params - id = pair-classification-binary-gender-bias-mitigated-roberta-snli\n",
      "2022-04-01 16:10:06,419 - INFO - allennlp.common.params - registered_model_name = bias_mitigator_applicator\n",
      "2022-04-01 16:10:06,419 - INFO - allennlp.common.params - model_class = None\n",
      "2022-04-01 16:10:06,420 - INFO - allennlp.common.params - registered_predictor_name = textual_entailment\n",
      "2022-04-01 16:10:06,421 - INFO - allennlp.common.params - display_name = Binary Gender Bias-Mitigated RoBERTa SNLI\n",
      "2022-04-01 16:10:06,422 - INFO - allennlp.common.params - task_id = textual_entailment\n",
      "2022-04-01 16:10:06,423 - INFO - allennlp.common.params - model_usage.archive_file = binary-gender-bias-mitigated-snli-roberta.2021-05-20.tar.gz\n",
      "2022-04-01 16:10:06,424 - INFO - allennlp.common.params - model_usage.training_config = pair_classification/binary_gender_bias_mitigated_snli_roberta.jsonnet\n",
      "2022-04-01 16:10:06,425 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.5.0 allennlp-models==2.5.0\n",
      "2022-04-01 16:10:06,425 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-04-01 16:10:06,428 - INFO - allennlp.common.params - model_details.description = This `Model` implements a basic text classifier with a bias mitigator applicator wrapper. The text is embedded into a text field using a RoBERTa-large model. Following the static embedding layer, the embeddings are projected onto the subspace orthogonal to the binary gender bias subspace. The resulting sequence is pooled using a cls_pooler `Seq2VecEncoder` and then passed to a linear classification layer, which projects into the label space.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-01 16:10:06,429 - INFO - allennlp.common.params - model_details.short_description = RoBERTa finetuned on SNLI with binary gender bias mitigation.\n",
      "2022-04-01 16:10:06,431 - INFO - allennlp.common.params - model_details.developed_by = Dev at al\n",
      "2022-04-01 16:10:06,431 - INFO - allennlp.common.params - model_details.contributed_by = Arjun Subramonian\n",
      "2022-04-01 16:10:06,432 - INFO - allennlp.common.params - model_details.date = 2021-05-20\n",
      "2022-04-01 16:10:06,433 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-04-01 16:10:06,434 - INFO - allennlp.common.params - model_details.model_type = RoBERTa\n",
      "2022-04-01 16:10:06,435 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@article{Dev2020OnMA,\n",
      "title={On Measuring and Mitigating Biased Inferences of Word Embeddings},\n",
      "author={Sunipa Dev and Tao Li and J. M. Phillips and Vivek Srikumar},\n",
      "journal={Proceedings of the AAAI Conference on Artificial Intelligence},\n",
      "year={2020},\n",
      "volume={34},\n",
      "number={05},\n",
      "pages={7659-7666},\n",
      "DOI={10.1609/aaai.v34i05.6267}\n",
      "\n",
      "2022-04-01 16:10:06,436 - INFO - allennlp.common.params - model_details.paper.title = On Measuring and Mitigating Biased Inferences of Word Embeddings\n",
      "2022-04-01 16:10:06,437 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:201670701\n",
      "2022-04-01 16:10:06,437 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-04-01 16:10:06,438 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-04-01 16:10:06,439 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-04-01 16:10:06,440 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-04-01 16:10:06,441 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-04-01 16:10:06,442 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-04-01 16:10:06,443 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-04-01 16:10:06,444 - INFO - allennlp.common.params - metrics.model_performance_measures = Accuracy, Net Neutral, Fraction Neutral, Threshold:tau\n",
      "2022-04-01 16:10:06,445 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-04-01 16:10:06,446 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-04-01 16:10:06,448 - INFO - allennlp.common.params - evaluation_data.dataset.name = On Measuring and Mitigating Biased Gender-Occupation Inferences SNLI Dataset\n",
      "2022-04-01 16:10:06,449 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = https://storage.googleapis.com/allennlp-public-models/binary-gender-bias-mitigated-snli-dataset.jsonl\n",
      "2022-04-01 16:10:06,450 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://github.com/sunipa/On-Measuring-and-Mitigating-Biased-Inferences-of-Word-Embeddings\n",
      "2022-04-01 16:10:06,450 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-04-01 16:10:06,452 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-04-01 16:10:06,454 - INFO - allennlp.common.params - training_data.dataset.name = Stanford Natural Language Inference (SNLI) train set\n",
      "2022-04-01 16:10:06,454 - INFO - allennlp.common.params - training_data.dataset.processed_url = https://allennlp.s3.amazonaws.com/datasets/snli/snli_1.0_train.jsonl\n",
      "2022-04-01 16:10:06,455 - INFO - allennlp.common.params - training_data.dataset.url = https://nlp.stanford.edu/projects/snli/\n",
      "2022-04-01 16:10:06,456 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-04-01 16:10:06,457 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-04-01 16:10:06,458 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = Net Neutral: 0.6417539715766907, Fraction Neutral: 0.7002295255661011, Threshold:0.5: 0.6902161836624146, Threshold:0.7: 0.49243637919425964\n",
      "2022-04-01 16:10:06,458 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-04-01 16:10:06,459 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = Binary gender bias mitigation has been applied to this model. Nonetheless, the model will contain residual biases and bias mitigation does not guarantee entirely bias-free inferences.\n",
      "2022-04-01 16:10:06,461 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-04-01 16:10:06,517 - INFO - allennlp.common.params - id = vqa-vilbert\n",
      "2022-04-01 16:10:06,517 - INFO - allennlp.common.params - registered_model_name = vqa_vilbert\n",
      "2022-04-01 16:10:06,519 - INFO - allennlp.common.params - model_class = None\n",
      "2022-04-01 16:10:06,520 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-04-01 16:10:06,520 - INFO - allennlp.common.params - display_name = ViLBERT - Visual Question Answering\n",
      "2022-04-01 16:10:06,521 - INFO - allennlp.common.params - task_id = vqa\n",
      "2022-04-01 16:10:06,522 - INFO - allennlp.common.params - model_usage.archive_file = vilbert-vqa-pretrained.2021-03-15.tar.gz\n",
      "2022-04-01 16:10:06,523 - INFO - allennlp.common.params - model_usage.training_config = vision/vilbert_vqa_pretrained.jsonnet\n",
      "2022-04-01 16:10:06,523 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
      "2022-04-01 16:10:06,524 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-04-01 16:10:06,525 - INFO - allennlp.common.params - model_details.description = ViLBERT (short for Vision-and-Language BERT), is a model for learning task-agnostic joint representations of image content and natural language.\n",
      "2022-04-01 16:10:06,528 - INFO - allennlp.common.params - model_details.short_description = ViLBERT (short for Vision-and-Language BERT), is a model for learning task-agnostic joint representations of image content and natural language.\n",
      "2022-04-01 16:10:06,529 - INFO - allennlp.common.params - model_details.developed_by = Lu et al\n",
      "2022-04-01 16:10:06,530 - INFO - allennlp.common.params - model_details.contributed_by = Dirk Groeneveld\n",
      "2022-04-01 16:10:06,530 - INFO - allennlp.common.params - model_details.date = 2021-03-15\n",
      "2022-04-01 16:10:06,530 - INFO - allennlp.common.params - model_details.version = 2\n",
      "2022-04-01 16:10:06,531 - INFO - allennlp.common.params - model_details.model_type = ViLBERT based on BERT large\n",
      "2022-04-01 16:10:06,531 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@inproceedings{Lu2019ViLBERTPT,\n",
      "title={ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks},\n",
      "author={Jiasen Lu and Dhruv Batra and D. Parikh and Stefan Lee},\n",
      "booktitle={NeurIPS},\n",
      "year={2019}\n",
      "}\n",
      "2022-04-01 16:10:06,532 - INFO - allennlp.common.params - model_details.paper.title = ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks\n",
      "2022-04-01 16:10:06,533 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:199453025\n",
      "2022-04-01 16:10:06,533 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-04-01 16:10:06,534 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-04-01 16:10:06,535 - INFO - allennlp.common.params - intended_use.primary_uses = This model is developed for the AllenNLP demo.\n",
      "2022-04-01 16:10:06,535 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-04-01 16:10:06,536 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-04-01 16:10:06,538 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-04-01 16:10:06,539 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-04-01 16:10:06,540 - INFO - allennlp.common.params - metrics.model_performance_measures = F1-metric and VQA score\n",
      "2022-04-01 16:10:06,543 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-04-01 16:10:06,544 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-04-01 16:10:06,545 - INFO - allennlp.common.params - evaluation_data.dataset.name = VQA dataset\n",
      "2022-04-01 16:10:06,546 - INFO - allennlp.common.params - evaluation_data.dataset.notes = Evaluation requires a large amount of images to be accessible locally, so we cannot provide a command you can easily copy and paste. The first time you run it, you will get an error message that tells you how to get the rest of the data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-01 16:10:06,547 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = balanced_real_val\n",
      "2022-04-01 16:10:06,549 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://visualqa.org/\n",
      "2022-04-01 16:10:06,551 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-04-01 16:10:06,552 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-04-01 16:10:06,553 - INFO - allennlp.common.params - training_data.dataset.name = VQA dataset\n",
      "2022-04-01 16:10:06,554 - INFO - allennlp.common.params - training_data.dataset.notes = Training requires a large amount of images to be accessible locally, so we cannot provide a command you can easily copy and paste. The first time you run it, you will get an error message that tells you how to get the rest of the data.\n",
      "2022-04-01 16:10:06,554 - INFO - allennlp.common.params - training_data.dataset.processed_url = balanced_real_train\n",
      "2022-04-01 16:10:06,555 - INFO - allennlp.common.params - training_data.dataset.url = https://visualqa.org/\n",
      "2022-04-01 16:10:06,555 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-04-01 16:10:06,556 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-04-01 16:10:06,557 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = On the validation set:\n",
      "F1: 40%\n",
      "VQA: 54%.\n",
      "These scores do not match the performance in the VilBERT paper. Please contact us if you want to match those scores!\n",
      "2022-04-01 16:10:06,558 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-04-01 16:10:06,558 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-04-01 16:10:06,559 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-04-01 16:10:06,611 - INFO - allennlp.common.params - id = rc-naqanet\n",
      "2022-04-01 16:10:06,612 - INFO - allennlp.common.params - registered_model_name = naqanet\n",
      "2022-04-01 16:10:06,614 - INFO - allennlp.common.params - model_class = None\n",
      "2022-04-01 16:10:06,615 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-04-01 16:10:06,616 - INFO - allennlp.common.params - display_name = Numerically Augmented QA Net\n",
      "2022-04-01 16:10:06,618 - INFO - allennlp.common.params - task_id = rc\n",
      "2022-04-01 16:10:06,619 - INFO - allennlp.common.params - model_usage.archive_file = naqanet-2021.02.26.tar.gz\n",
      "2022-04-01 16:10:06,620 - INFO - allennlp.common.params - model_usage.training_config = rc/naqanet.jsonnet\n",
      "2022-04-01 16:10:06,621 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
      "2022-04-01 16:10:06,622 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-04-01 16:10:06,623 - INFO - allennlp.common.params - model_details.description = An augmented version of QANet model with some rudimentary numerical reasoning abilities. The main idea here is that instead of just predicting a passage span after doing all of the QANet modeling stuff, we add several different 'answer abilities': predicting a span from the question, predicting a count, or predicting an arithmetic expression.  Near the end of the QANet model, we have a variable that predicts what kind of answer type we need, and each branch has separate modeling logic to predict that answer type.  We then marginalize over all possible ways of getting to the right answer through each of these answer types.\n",
      "2022-04-01 16:10:06,624 - INFO - allennlp.common.params - model_details.short_description = An augmented version of QANet that adds rudimentary numerical reasoning ability, trained on DROP (Dua et al., 2019), as published in the original DROP paper.\n",
      "2022-04-01 16:10:06,626 - INFO - allennlp.common.params - model_details.developed_by = Dua et al\n",
      "2022-04-01 16:10:06,627 - INFO - allennlp.common.params - model_details.contributed_by = None\n",
      "2022-04-01 16:10:06,628 - INFO - allennlp.common.params - model_details.date = 2020-02-19\n",
      "2022-04-01 16:10:06,629 - INFO - allennlp.common.params - model_details.version = 2\n",
      "2022-04-01 16:10:06,630 - INFO - allennlp.common.params - model_details.model_type = QANet\n",
      "2022-04-01 16:10:06,631 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@inproceedings{Dua2019DROPAR,\n",
      "title={DROP: A Reading Comprehension Benchmark Requiring Discrete Reasoning Over Paragraphs},\n",
      "author={Dheeru Dua and Yizhong Wang and Pradeep Dasigi and Gabriel Stanovsky and Sameer Singh and Matt Gardner},\n",
      "booktitle={NAACL-HLT},\n",
      "year={2019}}\n",
      "\n",
      "2022-04-01 16:10:06,632 - INFO - allennlp.common.params - model_details.paper.title = DROP: A Reading Comprehension Benchmark Requiring Discrete Reasoning Over Paragraphs\n",
      "2022-04-01 16:10:06,633 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:67855846\n",
      "2022-04-01 16:10:06,635 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-04-01 16:10:06,636 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-04-01 16:10:06,639 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-04-01 16:10:06,639 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-04-01 16:10:06,640 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-04-01 16:10:06,642 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-04-01 16:10:06,642 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-04-01 16:10:06,644 - INFO - allennlp.common.params - metrics.model_performance_measures = Exact Match and F1-score\n",
      "2022-04-01 16:10:06,646 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-04-01 16:10:06,647 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-04-01 16:10:06,650 - INFO - allennlp.common.params - evaluation_data.dataset.name = DROP\n",
      "2022-04-01 16:10:06,651 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = https://s3-us-west-2.amazonaws.com/allennlp/datasets/drop/drop_dataset.zip!drop_dataset/drop_dataset_dev.json\n",
      "2022-04-01 16:10:06,652 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://allennlp.org/drop\n",
      "2022-04-01 16:10:06,653 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-04-01 16:10:06,654 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-04-01 16:10:06,657 - INFO - allennlp.common.params - training_data.dataset.name = DROP\n",
      "2022-04-01 16:10:06,657 - INFO - allennlp.common.params - training_data.dataset.processed_url = https://s3-us-west-2.amazonaws.com/allennlp/datasets/drop/drop_dataset.zip!drop_dataset/drop_dataset_train.json\n",
      "2022-04-01 16:10:06,658 - INFO - allennlp.common.params - training_data.dataset.url = https://allennlp.org/drop\n",
      "2022-04-01 16:10:06,659 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-04-01 16:10:06,660 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-04-01 16:10:06,661 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = Validation F1-score: 0.509, Exact Match: 0.473\n",
      "2022-04-01 16:10:06,662 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-04-01 16:10:06,666 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-04-01 16:10:06,668 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-04-01 16:10:06,723 - INFO - allennlp.common.params - id = structured-prediction-constituency-parser\n",
      "2022-04-01 16:10:06,724 - INFO - allennlp.common.params - registered_model_name = constituency_parser\n",
      "2022-04-01 16:10:06,725 - INFO - allennlp.common.params - model_class = None\n",
      "2022-04-01 16:10:06,726 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-04-01 16:10:06,727 - INFO - allennlp.common.params - display_name = Constituency Parser with ELMo embeddings\n",
      "2022-04-01 16:10:06,727 - INFO - allennlp.common.params - task_id = constituency-parsing\n",
      "2022-04-01 16:10:06,729 - INFO - allennlp.common.params - model_usage.archive_file = elmo-constituency-parser-2020.02.10.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-01 16:10:06,730 - INFO - allennlp.common.params - model_usage.training_config = structured-prediction/constituency_parser_elmo.jsonnet\n",
      "2022-04-01 16:10:06,731 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
      "2022-04-01 16:10:06,732 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-04-01 16:10:06,734 - INFO - allennlp.common.params - model_details.description = This is an implementation of a minimal neural model for constituency parsing based on an independent scoring of labels and spans. This `SpanConstituencyParser` simply encodes a sequence of text with a stacked `Seq2SeqEncoder`, extracts span representations using a `SpanExtractor`, and then predicts a label for each span in the sequence. These labels are non-terminal nodes in a constituency parse tree, which we then greedily reconstruct. The model uses ELMo embeddings, which are completely character-based and improves single model performance from 92.6 F1 to 94.11 F1 on the Penn Treebank, a 20% relative error reduction.\n",
      "2022-04-01 16:10:06,738 - INFO - allennlp.common.params - model_details.short_description = Constituency parser with character-based ELMo embeddings\n",
      "2022-04-01 16:10:06,738 - INFO - allennlp.common.params - model_details.developed_by = Joshi et al\n",
      "2022-04-01 16:10:06,739 - INFO - allennlp.common.params - model_details.contributed_by = None\n",
      "2022-04-01 16:10:06,739 - INFO - allennlp.common.params - model_details.date = 2020-02-10\n",
      "2022-04-01 16:10:06,740 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-04-01 16:10:06,741 - INFO - allennlp.common.params - model_details.model_type = Seq2SeqEncoder\n",
      "2022-04-01 16:10:06,742 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@inproceedings{Joshi2018ExtendingAP,\n",
      "title={Extending a Parser to Distant Domains Using a Few Dozen Partially Annotated Examples},\n",
      "author={V. Joshi and Matthew E. Peters and Mark Hopkins},\n",
      "booktitle={ACL},\n",
      "year={2018}}\n",
      "\n",
      "2022-04-01 16:10:06,743 - INFO - allennlp.common.params - model_details.paper.title = Extending a Parser to Distant Domains Using a Few Dozen Partially Annotated Examples\n",
      "2022-04-01 16:10:06,744 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:21712653\n",
      "2022-04-01 16:10:06,744 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-04-01 16:10:06,745 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-04-01 16:10:06,747 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-04-01 16:10:06,748 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-04-01 16:10:06,749 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-04-01 16:10:06,750 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-04-01 16:10:06,751 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-04-01 16:10:06,753 - INFO - allennlp.common.params - metrics.model_performance_measures = Precision, Recall and F1-score for parse trees (EVALB_bracketing_scorer)\n",
      "2022-04-01 16:10:06,753 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-04-01 16:10:06,754 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-04-01 16:10:06,756 - INFO - allennlp.common.params - evaluation_data.dataset.name = PTB 3.0\n",
      "2022-04-01 16:10:06,757 - INFO - allennlp.common.params - evaluation_data.dataset.notes = Please download the data from the url provided.\n",
      "2022-04-01 16:10:06,758 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = /path/do/dataset\n",
      "2022-04-01 16:10:06,758 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://catalog.ldc.upenn.edu/LDC99T42\n",
      "2022-04-01 16:10:06,759 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-04-01 16:10:06,761 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-04-01 16:10:06,765 - INFO - allennlp.common.params - training_data.dataset.name = PTB 3.0\n",
      "2022-04-01 16:10:06,766 - INFO - allennlp.common.params - training_data.dataset.notes = Please download the data from the url provided.\n",
      "2022-04-01 16:10:06,767 - INFO - allennlp.common.params - training_data.dataset.processed_url = /path/do/dataset\n",
      "2022-04-01 16:10:06,767 - INFO - allennlp.common.params - training_data.dataset.url = https://catalog.ldc.upenn.edu/LDC99T42\n",
      "2022-04-01 16:10:06,769 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-04-01 16:10:06,769 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-04-01 16:10:06,771 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = 94.11 F1 score\n",
      "2022-04-01 16:10:06,772 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-04-01 16:10:06,774 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-04-01 16:10:06,775 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-04-01 16:10:06,835 - INFO - allennlp.common.params - id = pair-classification-roberta-rte\n",
      "2022-04-01 16:10:06,836 - INFO - allennlp.common.params - registered_model_name = basic_classifier\n",
      "2022-04-01 16:10:06,838 - INFO - allennlp.common.params - model_class = None\n",
      "2022-04-01 16:10:06,839 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-04-01 16:10:06,841 - INFO - allennlp.common.params - display_name = RoBERTa RTE\n",
      "2022-04-01 16:10:06,842 - INFO - allennlp.common.params - task_id = pair_classification\n",
      "2022-04-01 16:10:06,844 - INFO - allennlp.common.params - model_usage.archive_file = superglue-rte-roberta.2021-04-09.tar.gz\n",
      "2022-04-01 16:10:06,846 - INFO - allennlp.common.params - model_usage.training_config = pair-classification/superglue_rte_roberta.jsonnet\n",
      "2022-04-01 16:10:06,847 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.3.1 allennlp-models==2.3.1\n",
      "2022-04-01 16:10:06,847 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-04-01 16:10:06,849 - INFO - allennlp.common.params - model_details.description = The model implements a pair classification model patterned after the proposed model in [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding (Devlin et al, 2018)](https://api.semanticscholar.org/CorpusID:52967399), fine-tuned on the MultiNLI corpus. It predicts labels with a linear layer on top of word piece embeddings.\n",
      "2022-04-01 16:10:06,850 - INFO - allennlp.common.params - model_details.short_description = A pair classification model patterned after the proposed model in Devlin et al, fine-tuned on the SuperGLUE RTE corpus\n",
      "2022-04-01 16:10:06,851 - INFO - allennlp.common.params - model_details.developed_by = Devlin et al\n",
      "2022-04-01 16:10:06,852 - INFO - allennlp.common.params - model_details.contributed_by = Jacob Morrison\n",
      "2022-04-01 16:10:06,852 - INFO - allennlp.common.params - model_details.date = 2021-04-09\n",
      "2022-04-01 16:10:06,853 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-04-01 16:10:06,853 - INFO - allennlp.common.params - model_details.model_type = RoBERTa\n",
      "2022-04-01 16:10:06,854 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@article{Liu2019RoBERTaAR,\n",
      "title={RoBERTa: A Robustly Optimized BERT Pretraining Approach},\n",
      "author={Y. Liu and Myle Ott and Naman Goyal and Jingfei Du and Mandar Joshi and Danqi Chen and Omer Levy and M. Lewis and L. Zettlemoyer and V. Stoyanov},\n",
      "journal={ArXiv},\n",
      "year={2019},\n",
      "volume={abs/1907.11692}}\n",
      "\n",
      "2022-04-01 16:10:06,854 - INFO - allennlp.common.params - model_details.paper.title = RoBERTa: A Robustly Optimized BERT Pretraining Approach\n",
      "2022-04-01 16:10:06,854 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:198953378\n",
      "2022-04-01 16:10:06,855 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-04-01 16:10:06,856 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-04-01 16:10:06,857 - INFO - allennlp.common.params - intended_use.primary_uses = None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-01 16:10:06,859 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-04-01 16:10:06,861 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-04-01 16:10:06,861 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-04-01 16:10:06,862 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-04-01 16:10:06,863 - INFO - allennlp.common.params - metrics.model_performance_measures = Accuracy\n",
      "2022-04-01 16:10:06,865 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-04-01 16:10:06,865 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-04-01 16:10:06,867 - INFO - allennlp.common.params - evaluation_data.dataset.name = SuperGLUE Recognizing Textual Entailment validation set\n",
      "2022-04-01 16:10:06,868 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = https://dl.fbaipublicfiles.com/glue/superglue/data/v2/RTE.zip!RTE/val.jsonl\n",
      "2022-04-01 16:10:06,869 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://super.gluebenchmark.com/tasks\n",
      "2022-04-01 16:10:06,869 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-04-01 16:10:06,871 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-04-01 16:10:06,874 - INFO - allennlp.common.params - training_data.dataset.name = SuperGLUE Recognizing Textual Entailment training set\n",
      "2022-04-01 16:10:06,875 - INFO - allennlp.common.params - training_data.dataset.processed_url = https://dl.fbaipublicfiles.com/glue/superglue/data/v2/RTE.zip!RTE/train.jsonl\n",
      "2022-04-01 16:10:06,876 - INFO - allennlp.common.params - training_data.dataset.url = https://super.gluebenchmark.com/tasks\n",
      "2022-04-01 16:10:06,877 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-04-01 16:10:06,877 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-04-01 16:10:06,878 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = Accuracy: 89.9% on the SuperGLUE RTE validation dataset.\n",
      "2022-04-01 16:10:06,879 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-04-01 16:10:06,881 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-04-01 16:10:06,882 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-04-01 16:10:06,955 - INFO - allennlp.common.params - id = lm-masked-language-model\n",
      "2022-04-01 16:10:06,957 - INFO - allennlp.common.params - registered_model_name = masked_language_model\n",
      "2022-04-01 16:10:06,959 - INFO - allennlp.common.params - model_class = None\n",
      "2022-04-01 16:10:06,960 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-04-01 16:10:06,961 - INFO - allennlp.common.params - display_name = BERT-based Masked Language Model\n",
      "2022-04-01 16:10:06,962 - INFO - allennlp.common.params - task_id = masked-language-modeling\n",
      "2022-04-01 16:10:06,965 - INFO - allennlp.common.params - model_usage.archive_file = bert-masked-lm-2020-10-07.tar.gz\n",
      "2022-04-01 16:10:06,966 - INFO - allennlp.common.params - model_usage.training_config = lm/bidirectional_language_model.jsonnet\n",
      "2022-04-01 16:10:06,967 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
      "2022-04-01 16:10:06,968 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-04-01 16:10:06,970 - INFO - allennlp.common.params - model_details.description = The `MaskedLanguageModel` embeds some input tokens (including some which are masked), contextualizes them, then predicts targets for the masked tokens, computing a loss against known targets.\n",
      "2022-04-01 16:10:06,971 - INFO - allennlp.common.params - model_details.short_description = BERT-based masked language model\n",
      "2022-04-01 16:10:06,973 - INFO - allennlp.common.params - model_details.developed_by = Devlin et al\n",
      "2022-04-01 16:10:06,975 - INFO - allennlp.common.params - model_details.contributed_by = None\n",
      "2022-04-01 16:10:06,976 - INFO - allennlp.common.params - model_details.date = 2020-10-07\n",
      "2022-04-01 16:10:06,977 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-04-01 16:10:06,977 - INFO - allennlp.common.params - model_details.model_type = BERT\n",
      "2022-04-01 16:10:06,979 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@inproceedings{Devlin2019BERTPO,\n",
      "title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},\n",
      "author={J. Devlin and Ming-Wei Chang and Kenton Lee and Kristina Toutanova},\n",
      "booktitle={NAACL-HLT},\n",
      "year={2019}}\n",
      "\n",
      "2022-04-01 16:10:06,980 - INFO - allennlp.common.params - model_details.paper.title = BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\n",
      "2022-04-01 16:10:06,981 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:52967399\n",
      "2022-04-01 16:10:06,981 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-04-01 16:10:06,982 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-04-01 16:10:06,983 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-04-01 16:10:06,984 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-04-01 16:10:06,986 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-04-01 16:10:06,990 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-04-01 16:10:06,992 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-04-01 16:10:06,993 - INFO - allennlp.common.params - metrics.model_performance_measures = Perplexity\n",
      "2022-04-01 16:10:06,994 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-04-01 16:10:06,995 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-04-01 16:10:06,997 - INFO - allennlp.common.params - evaluation_data.dataset = BooksCorpus (800M words) and English Wikipedia (2,500M words).\n",
      "2022-04-01 16:10:06,998 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-04-01 16:10:06,999 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-04-01 16:10:07,001 - INFO - allennlp.common.params - training_data.dataset = BooksCorpus (800M words) and English Wikipedia (2,500M words).\n",
      "2022-04-01 16:10:07,002 - INFO - allennlp.common.params - training_data.motivation = Document-level corpus is used rather than shuffled sentence-level corpus, to extract long contiguous sequences.\n",
      "2022-04-01 16:10:07,005 - INFO - allennlp.common.params - training_data.preprocessing = For Wikipedia, text passages are extracted and lists, tables, and headers are ignored.\n",
      "2022-04-01 16:10:07,006 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = None\n",
      "2022-04-01 16:10:07,008 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-04-01 16:10:07,010 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = BERT demonstrates gender bias in that it thinks the doctor is more likely a man ('his') than a woman ('her'). An important issue in NLP is how to understand and address such biases in our linguistic models.\n",
      "2022-04-01 16:10:07,011 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = NOTE: This was developed for use in a demo, not for training.  It's possible that it will still work for training a masked LM, but it is very likely that some other code would be much more efficient for that.  This `does` compute correct gradients of the loss, because we use that in our demo, so in principle it should be able to train a model, we just don't necessarily endorse that use.\n",
      "2022-04-01 16:10:07,079 - INFO - allennlp.common.params - id = rc-transformer-qa\n",
      "2022-04-01 16:10:07,080 - INFO - allennlp.common.params - registered_model_name = transformer_qa\n",
      "2022-04-01 16:10:07,082 - INFO - allennlp.common.params - model_class = None\n",
      "2022-04-01 16:10:07,083 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-04-01 16:10:07,083 - INFO - allennlp.common.params - display_name = Transformer QA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-01 16:10:07,084 - INFO - allennlp.common.params - task_id = rc\n",
      "2022-04-01 16:10:07,086 - INFO - allennlp.common.params - model_usage.archive_file = transformer-qa.2021-02-11.tar.gz\n",
      "2022-04-01 16:10:07,087 - INFO - allennlp.common.params - model_usage.training_config = rc/transformer_qa.jsonnet\n",
      "2022-04-01 16:10:07,088 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
      "2022-04-01 16:10:07,089 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-04-01 16:10:07,091 - INFO - allennlp.common.params - model_details.description = The model implements a reading comprehension model patterned after the proposed model in [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding (Devlin et al, 2018)](https://api.semanticscholar.org/CorpusID:52967399), with improvements borrowed from the SQuAD model in the transformers project. It predicts start tokens and end tokens with a linear layer on top of word piece embeddings.\n",
      "2022-04-01 16:10:07,092 - INFO - allennlp.common.params - model_details.short_description = A reading comprehension model patterned after the proposed model in Devlin et al, with improvements borrowed from the SQuAD model in the transformers project\n",
      "2022-04-01 16:10:07,093 - INFO - allennlp.common.params - model_details.developed_by = Devlin et al\n",
      "2022-04-01 16:10:07,093 - INFO - allennlp.common.params - model_details.contributed_by = Dirk Groeneveld and Evan Pete Walsh\n",
      "2022-04-01 16:10:07,094 - INFO - allennlp.common.params - model_details.date = 2020-10-03\n",
      "2022-04-01 16:10:07,095 - INFO - allennlp.common.params - model_details.version = 2\n",
      "2022-04-01 16:10:07,096 - INFO - allennlp.common.params - model_details.model_type = RoBERTa\n",
      "2022-04-01 16:10:07,097 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@article{Liu2019RoBERTaAR,\n",
      "title={RoBERTa: A Robustly Optimized BERT Pretraining Approach},\n",
      "author={Y. Liu and Myle Ott and Naman Goyal and Jingfei Du and Mandar Joshi and Danqi Chen and Omer Levy and M. Lewis and L. Zettlemoyer and V. Stoyanov},\n",
      "journal={ArXiv},\n",
      "year={2019},\n",
      "volume={abs/1907.11692}}\n",
      "\n",
      "2022-04-01 16:10:07,099 - INFO - allennlp.common.params - model_details.paper.title = RoBERTa: A Robustly Optimized BERT Pretraining Approach\n",
      "2022-04-01 16:10:07,099 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:198953378\n",
      "2022-04-01 16:10:07,100 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-04-01 16:10:07,101 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-04-01 16:10:07,102 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-04-01 16:10:07,106 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-04-01 16:10:07,107 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-04-01 16:10:07,108 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-04-01 16:10:07,109 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-04-01 16:10:07,111 - INFO - allennlp.common.params - metrics.model_performance_measures = F1-score, Span Accuracy, Exact Match\n",
      "2022-04-01 16:10:07,112 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-04-01 16:10:07,113 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-04-01 16:10:07,115 - INFO - allennlp.common.params - evaluation_data.dataset.name = SQuAD dev set\n",
      "2022-04-01 16:10:07,116 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = https://s3-us-west-2.amazonaws.com/allennlp/datasets/squad/squad-dev-v2.0.json\n",
      "2022-04-01 16:10:07,117 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://rajpurkar.github.io/SQuAD-explorer/explore/2.0/dev/\n",
      "2022-04-01 16:10:07,118 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-04-01 16:10:07,119 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-04-01 16:10:07,122 - INFO - allennlp.common.params - training_data.dataset.name = SQuAD training set\n",
      "2022-04-01 16:10:07,123 - INFO - allennlp.common.params - training_data.dataset.processed_url = https://s3-us-west-2.amazonaws.com/allennlp/datasets/squad/squad-train-v2.0.json\n",
      "2022-04-01 16:10:07,123 - INFO - allennlp.common.params - training_data.dataset.url = https://rajpurkar.github.io/SQuAD-explorer/explore/2.0/dev/\n",
      "2022-04-01 16:10:07,124 - INFO - allennlp.common.params - training_data.motivation = For the pretrained RoBERTa model, document-level corpora were used rather than a shuffled sentence-level corpus such as the Billion Word Benchmark (Chelba et al., 2013) in order to extract long contiguous sequences\n",
      "2022-04-01 16:10:07,125 - INFO - allennlp.common.params - training_data.preprocessing = For the pretrained RoBERTa model, only the text passages were extracted from English Wikipedia; lists, tables, and headers were ignored.\n",
      "2022-04-01 16:10:07,126 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = On the validation set:\n",
      "F1: 88%\n",
      "Exact match: 84%\n",
      "These are metrics using the official evaluation. Note that the metrics that the model produces while training are calculated on a per-instance basis only. Since there could be more than one instance per question, these metrics are not the official numbers on the SQuAD task. To get official numbers, run the evaluation script at allennlp_models/rc/tools/transformer_qa_eval.py.\n",
      "2022-04-01 16:10:07,127 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-04-01 16:10:07,128 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-04-01 16:10:07,130 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-04-01 16:10:07,196 - INFO - allennlp.common.params - id = mc-roberta-swag\n",
      "2022-04-01 16:10:07,198 - INFO - allennlp.common.params - registered_model_name = transformer_mc\n",
      "2022-04-01 16:10:07,200 - INFO - allennlp.common.params - model_class = None\n",
      "2022-04-01 16:10:07,201 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-04-01 16:10:07,203 - INFO - allennlp.common.params - display_name = RoBERTa SWAG\n",
      "2022-04-01 16:10:07,205 - INFO - allennlp.common.params - task_id = mc\n",
      "2022-04-01 16:10:07,207 - INFO - allennlp.common.params - model_usage.archive_file = swag.2020-07-08.tar.gz\n",
      "2022-04-01 16:10:07,210 - INFO - allennlp.common.params - model_usage.training_config = mc/swag.jsonnet\n",
      "2022-04-01 16:10:07,211 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==1.0.0 allennlp-models==1.0.0\n",
      "2022-04-01 16:10:07,212 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-04-01 16:10:07,213 - INFO - allennlp.common.params - model_details.description = This is a multiple choice model patterned after the BERT architecture. It calculates a score for each sequence on top of the CLS token, and then chooses the alternative with the highest score.\n",
      "2022-04-01 16:10:07,215 - INFO - allennlp.common.params - model_details.short_description = RoBERTa-based multiple choice model for SWAG.\n",
      "2022-04-01 16:10:07,216 - INFO - allennlp.common.params - model_details.developed_by = Devlin et al\n",
      "2022-04-01 16:10:07,217 - INFO - allennlp.common.params - model_details.contributed_by = Dirk Groeneveld\n",
      "2022-04-01 16:10:07,218 - INFO - allennlp.common.params - model_details.date = 2020-07-08\n",
      "2022-04-01 16:10:07,221 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-04-01 16:10:07,222 - INFO - allennlp.common.params - model_details.model_type = RoBERTa large\n",
      "2022-04-01 16:10:07,223 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@article{Liu2019RoBERTaAR,\n",
      "title={RoBERTa: A Robustly Optimized BERT Pretraining Approach},\n",
      "author={Y. Liu and Myle Ott and Naman Goyal and Jingfei Du and Mandar Joshi and Danqi Chen and Omer Levy and M. Lewis and Luke Zettlemoyer and Veselin Stoyanov},\n",
      "journal={ArXiv},\n",
      "year={2019},\n",
      "volume={abs/1907.11692}}\n",
      "\n",
      "2022-04-01 16:10:07,224 - INFO - allennlp.common.params - model_details.paper.title = RoBERTa: A Robustly Optimized BERT Pretraining Approach (Liu et al)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-01 16:10:07,226 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:198953378\n",
      "2022-04-01 16:10:07,227 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-04-01 16:10:07,228 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-04-01 16:10:07,230 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-04-01 16:10:07,231 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-04-01 16:10:07,233 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-04-01 16:10:07,234 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-04-01 16:10:07,235 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-04-01 16:10:07,238 - INFO - allennlp.common.params - metrics.model_performance_measures = The chosen metric is accuracy, since it is a multiple choice model.\n",
      "2022-04-01 16:10:07,239 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-04-01 16:10:07,240 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-04-01 16:10:07,242 - INFO - allennlp.common.params - evaluation_data.dataset.name = SWAG (validation set)\n",
      "2022-04-01 16:10:07,243 - INFO - allennlp.common.params - evaluation_data.dataset.notes = Please download the data from the url provided.\n",
      "2022-04-01 16:10:07,244 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://rowanzellers.com/swag/\n",
      "2022-04-01 16:10:07,246 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-04-01 16:10:07,247 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-04-01 16:10:07,249 - INFO - allennlp.common.params - training_data.dataset.name = SWAG (train set)\n",
      "2022-04-01 16:10:07,250 - INFO - allennlp.common.params - training_data.dataset.notes = Please download the data from the url provided.\n",
      "2022-04-01 16:10:07,251 - INFO - allennlp.common.params - training_data.dataset.url = https://rowanzellers.com/swag/\n",
      "2022-04-01 16:10:07,252 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-04-01 16:10:07,254 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-04-01 16:10:07,255 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = None\n",
      "2022-04-01 16:10:07,257 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-04-01 16:10:07,258 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-04-01 16:10:07,260 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-04-01 16:10:07,324 - INFO - allennlp.common.params - id = rc-bidaf\n",
      "2022-04-01 16:10:07,325 - INFO - allennlp.common.params - registered_model_name = bidaf\n",
      "2022-04-01 16:10:07,326 - INFO - allennlp.common.params - model_class = None\n",
      "2022-04-01 16:10:07,327 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-04-01 16:10:07,328 - INFO - allennlp.common.params - display_name = BiDAF\n",
      "2022-04-01 16:10:07,329 - INFO - allennlp.common.params - task_id = rc\n",
      "2022-04-01 16:10:07,331 - INFO - allennlp.common.params - model_usage.archive_file = bidaf-model-2020.03.19.tar.gz\n",
      "2022-04-01 16:10:07,331 - INFO - allennlp.common.params - model_usage.training_config = rc/bidaf.jsonnet\n",
      "2022-04-01 16:10:07,333 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
      "2022-04-01 16:10:07,333 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-04-01 16:10:07,335 - INFO - allennlp.common.params - model_details.description = This is an implementation of the BiDAF model with GloVe embeddings. The basic layout is pretty simple: encode words as a combination of word embeddings and a character-level encoder, pass the word representations through a bi-LSTM/GRU, use a matrix of attentions to put question information into the passage word representations (this is the only part that is at all non-standard), pass this through another few layers of bi-LSTMs/GRUs, and do a softmax over span start and span end.\n",
      "2022-04-01 16:10:07,336 - INFO - allennlp.common.params - model_details.short_description = BiDAF model with GloVe embeddings.\n",
      "2022-04-01 16:10:07,337 - INFO - allennlp.common.params - model_details.developed_by = Seo et al\n",
      "2022-04-01 16:10:07,338 - INFO - allennlp.common.params - model_details.contributed_by = None\n",
      "2022-04-01 16:10:07,338 - INFO - allennlp.common.params - model_details.date = 2020-03-19\n",
      "2022-04-01 16:10:07,339 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-04-01 16:10:07,340 - INFO - allennlp.common.params - model_details.model_type = BiDAF\n",
      "2022-04-01 16:10:07,341 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@article{Seo2017BidirectionalAF,\n",
      "title={Bidirectional Attention Flow for Machine Comprehension},\n",
      "author={Minjoon Seo and Aniruddha Kembhavi and Ali Farhadi and Hannaneh Hajishirzi},\n",
      "journal={ArXiv},\n",
      "year={2017},\n",
      "volume={abs/1611.01603}}\n",
      "\n",
      "2022-04-01 16:10:07,342 - INFO - allennlp.common.params - model_details.paper.title = Bidirectional Attention Flow for Machine Comprehension\n",
      "2022-04-01 16:10:07,346 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:8535316\n",
      "2022-04-01 16:10:07,348 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-04-01 16:10:07,350 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-04-01 16:10:07,351 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-04-01 16:10:07,353 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-04-01 16:10:07,354 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-04-01 16:10:07,357 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-04-01 16:10:07,358 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-04-01 16:10:07,359 - INFO - allennlp.common.params - metrics.model_performance_measures = Start, end, and overall span accuracy, Exact Match, F1 score\n",
      "2022-04-01 16:10:07,361 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-04-01 16:10:07,362 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-04-01 16:10:07,364 - INFO - allennlp.common.params - evaluation_data.dataset.name = SQuAD dev set\n",
      "2022-04-01 16:10:07,365 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = https://s3-us-west-2.amazonaws.com/allennlp/datasets/squad/squad-dev-v1.1.json\n",
      "2022-04-01 16:10:07,366 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://rajpurkar.github.io/SQuAD-explorer/explore/1.1/dev/\n",
      "2022-04-01 16:10:07,367 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-04-01 16:10:07,369 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-04-01 16:10:07,371 - INFO - allennlp.common.params - training_data.dataset.name = SQuAD training set\n",
      "2022-04-01 16:10:07,372 - INFO - allennlp.common.params - training_data.dataset.processed_url = https://s3-us-west-2.amazonaws.com/allennlp/datasets/squad/squad-train-v1.1.json\n",
      "2022-04-01 16:10:07,375 - INFO - allennlp.common.params - training_data.dataset.url = https://rajpurkar.github.io/SQuAD-explorer/explore/1.1/dev/\n",
      "2022-04-01 16:10:07,376 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-04-01 16:10:07,377 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-04-01 16:10:07,379 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = On the validation set:\n",
      "Start accuracy: 61%\n",
      "End accuracy: 66%\n",
      "Overall span accuracy: 52%\n",
      "Exact match: 66%\n",
      "F1: 76%\n",
      "2022-04-01 16:10:07,382 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-04-01 16:10:07,383 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-04-01 16:10:07,385 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-04-01 16:10:07,441 - INFO - allennlp.common.params - id = rc-bidaf-elmo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-01 16:10:07,442 - INFO - allennlp.common.params - registered_model_name = bidaf\n",
      "2022-04-01 16:10:07,443 - INFO - allennlp.common.params - model_class = None\n",
      "2022-04-01 16:10:07,444 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-04-01 16:10:07,445 - INFO - allennlp.common.params - display_name = ELMo-BiDAF\n",
      "2022-04-01 16:10:07,447 - INFO - allennlp.common.params - task_id = rc\n",
      "2022-04-01 16:10:07,448 - INFO - allennlp.common.params - model_usage.archive_file = bidaf-elmo.2021-02-11.tar.gz\n",
      "2022-04-01 16:10:07,449 - INFO - allennlp.common.params - model_usage.training_config = rc/bidaf_elmo.jsonnet\n",
      "2022-04-01 16:10:07,450 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
      "2022-04-01 16:10:07,451 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-04-01 16:10:07,452 - INFO - allennlp.common.params - model_details.description = This is an implementation of the BiDAF model with ELMo embeddings. The basic layout is pretty simple: encode words as a combination of word embeddings and a character-level encoder, pass the word representations through a bi-LSTM/GRU, use a matrix of attentions to put question information into the passage word representations (this is the only part that is at all non-standard), pass this through another few layers of bi-LSTMs/GRUs, and do a softmax over span start and span end.\n",
      "2022-04-01 16:10:07,453 - INFO - allennlp.common.params - model_details.short_description = BiDAF model with ELMo embeddings instead of GloVe.\n",
      "2022-04-01 16:10:07,454 - INFO - allennlp.common.params - model_details.developed_by = Seo et al\n",
      "2022-04-01 16:10:07,455 - INFO - allennlp.common.params - model_details.contributed_by = None\n",
      "2022-04-01 16:10:07,455 - INFO - allennlp.common.params - model_details.date = 2020-03-19\n",
      "2022-04-01 16:10:07,456 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-04-01 16:10:07,457 - INFO - allennlp.common.params - model_details.model_type = BiDAF\n",
      "2022-04-01 16:10:07,458 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@article{Seo2017BidirectionalAF,\n",
      "title={Bidirectional Attention Flow for Machine Comprehension},\n",
      "author={Minjoon Seo and Aniruddha Kembhavi and Ali Farhadi and Hannaneh Hajishirzi},\n",
      "journal={ArXiv},\n",
      "year={2017},\n",
      "volume={abs/1611.01603}}\n",
      "\n",
      "2022-04-01 16:10:07,460 - INFO - allennlp.common.params - model_details.paper.title = Bidirectional Attention Flow for Machine Comprehension\n",
      "2022-04-01 16:10:07,461 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:8535316\n",
      "2022-04-01 16:10:07,462 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-04-01 16:10:07,463 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-04-01 16:10:07,465 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-04-01 16:10:07,466 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-04-01 16:10:07,467 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-04-01 16:10:07,470 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-04-01 16:10:07,471 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-04-01 16:10:07,473 - INFO - allennlp.common.params - metrics.model_performance_measures = Start, end and overall span accuracy, Exact Match, F1 score\n",
      "2022-04-01 16:10:07,474 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-04-01 16:10:07,475 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-04-01 16:10:07,478 - INFO - allennlp.common.params - evaluation_data.dataset.name = SQuAD dev set\n",
      "2022-04-01 16:10:07,479 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = https://s3-us-west-2.amazonaws.com/allennlp/datasets/squad/squad-dev-v1.1.json\n",
      "2022-04-01 16:10:07,481 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://rajpurkar.github.io/SQuAD-explorer/explore/1.1/dev/\n",
      "2022-04-01 16:10:07,482 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-04-01 16:10:07,483 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-04-01 16:10:07,486 - INFO - allennlp.common.params - training_data.dataset.name = SQuAD training set\n",
      "2022-04-01 16:10:07,487 - INFO - allennlp.common.params - training_data.dataset.processed_url = https://s3-us-west-2.amazonaws.com/allennlp/datasets/squad/squad-train-v1.1.json\n",
      "2022-04-01 16:10:07,488 - INFO - allennlp.common.params - training_data.dataset.url = https://rajpurkar.github.io/SQuAD-explorer/explore/1.1/dev/\n",
      "2022-04-01 16:10:07,489 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-04-01 16:10:07,490 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-04-01 16:10:07,491 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = On the validation set:\n",
      "Start accuracy: 66%\n",
      "End accuracy: 69%\n",
      "Overall span accuracy: 57%\n",
      "Exact match: 71%\n",
      "F1: 80%\n",
      "2022-04-01 16:10:07,494 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-04-01 16:10:07,495 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-04-01 16:10:07,498 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = This model is based on ELMo. ELMo is not deterministic, meaning that you will see slight differences every time you run it. Also, ELMo likes to be warmed up, so we recommend processing dummy input before processing real workloads with it.\n",
      "2022-04-01 16:10:07,558 - INFO - allennlp.common.params - id = pair-classification-adversarial-binary-gender-bias-mitigated-roberta-snli\n",
      "2022-04-01 16:10:07,559 - INFO - allennlp.common.params - registered_model_name = adversarial_bias_mitigator\n",
      "2022-04-01 16:10:07,560 - INFO - allennlp.common.params - model_class = None\n",
      "2022-04-01 16:10:07,561 - INFO - allennlp.common.params - registered_predictor_name = textual_entailment\n",
      "2022-04-01 16:10:07,563 - INFO - allennlp.common.params - display_name = Adversarial Binary Gender Bias-Mitigated RoBERTa SNLI\n",
      "2022-04-01 16:10:07,564 - INFO - allennlp.common.params - task_id = textual_entailment\n",
      "2022-04-01 16:10:07,566 - INFO - allennlp.common.params - model_usage.archive_file = adversarial-binary-gender-bias-mitigated-snli-roberta.2021-06-17.tar.gz\n",
      "2022-04-01 16:10:07,567 - INFO - allennlp.common.params - model_usage.training_config = pair_classification/adversarial_binary_gender_bias_mitigated_snli_roberta.jsonnet\n",
      "2022-04-01 16:10:07,568 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp allennlp-models\n",
      "2022-04-01 16:10:07,570 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-04-01 16:10:07,571 - INFO - allennlp.common.params - model_details.description = This `Model` implements a basic text classifier and feedforward regression adversary with an adversarial bias mitigator wrapper. The text is embedded into a text field using a RoBERTa-large model. The resulting sequence is pooled using a cls_pooler `Seq2VecEncoder` and then passed to a linear classification layer, which projects into the label space. Subsequently, a `FeedForwardRegressionAdversary` attempts to recover the coefficient of the static text embedding in the binary gender bias subspace. While the adversary's parameter updates are computed normally, the predictor's parameters are updated such that the predictor will not aid the adversary and will make it more difficult for the adversary to recover protected variables.\n",
      "2022-04-01 16:10:07,573 - INFO - allennlp.common.params - model_details.short_description = RoBERTa finetuned on SNLI with adversarial binary gender bias mitigation.\n",
      "2022-04-01 16:10:07,575 - INFO - allennlp.common.params - model_details.developed_by = Zhang at al\n",
      "2022-04-01 16:10:07,575 - INFO - allennlp.common.params - model_details.contributed_by = Arjun Subramonian\n",
      "2022-04-01 16:10:07,576 - INFO - allennlp.common.params - model_details.date = 2021-06-17\n",
      "2022-04-01 16:10:07,578 - INFO - allennlp.common.params - model_details.version = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-01 16:10:07,579 - INFO - allennlp.common.params - model_details.model_type = RoBERTa\n",
      "2022-04-01 16:10:07,581 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@article{Zhang2018MitigatingUB,\n",
      "title={Mitigating Unwanted Biases with Adversarial Learning},\n",
      "author={B. H. Zhang and B. Lemoine and Margaret Mitchell},\n",
      "journal={Proceedings of the 2018 AAAI/ACM Conference on AI, Ethics, and Society},\n",
      "year={2018}\n",
      "}\n",
      "2022-04-01 16:10:07,581 - INFO - allennlp.common.params - model_details.paper.title = Mitigating Unwanted Biases with Adversarial Learning\n",
      "2022-04-01 16:10:07,582 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:9424845\n",
      "2022-04-01 16:10:07,583 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-04-01 16:10:07,584 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-04-01 16:10:07,586 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-04-01 16:10:07,587 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-04-01 16:10:07,587 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-04-01 16:10:07,589 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-04-01 16:10:07,591 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-04-01 16:10:07,592 - INFO - allennlp.common.params - metrics.model_performance_measures = Accuracy, Net Neutral, Fraction Neutral, Threshold:tau\n",
      "2022-04-01 16:10:07,593 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-04-01 16:10:07,594 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-04-01 16:10:07,596 - INFO - allennlp.common.params - evaluation_data.dataset.name = On Measuring and Mitigating Biased Gender-Occupation Inferences SNLI Dataset\n",
      "2022-04-01 16:10:07,597 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = https://storage.googleapis.com/allennlp-public-models/binary-gender-bias-mitigated-snli-dataset.jsonl\n",
      "2022-04-01 16:10:07,598 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://github.com/sunipa/On-Measuring-and-Mitigating-Biased-Inferences-of-Word-Embeddings\n",
      "2022-04-01 16:10:07,599 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-04-01 16:10:07,600 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-04-01 16:10:07,602 - INFO - allennlp.common.params - training_data.dataset.name = Stanford Natural Language Inference (SNLI) train set\n",
      "2022-04-01 16:10:07,603 - INFO - allennlp.common.params - training_data.dataset.processed_url = https://allennlp.s3.amazonaws.com/datasets/snli/snli_1.0_train.jsonl\n",
      "2022-04-01 16:10:07,605 - INFO - allennlp.common.params - training_data.dataset.url = https://nlp.stanford.edu/projects/snli/\n",
      "2022-04-01 16:10:07,606 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-04-01 16:10:07,607 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-04-01 16:10:07,608 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = Net Neutral: 0.613096454815352, Fraction Neutral: 0.6704967487937075, Threshold:0.5: 0.6637061892722586, Threshold:0.7: 0.49490217463150243\n",
      "2022-04-01 16:10:07,609 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-04-01 16:10:07,610 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = Adversarial binary gender bias mitigation has been applied to this model. Nonetheless, the model will contain residual biases and bias mitigation does not guarantee entirely bias-free inferences.\n",
      "2022-04-01 16:10:07,612 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-04-01 16:10:07,673 - INFO - allennlp.common.params - id = structured-prediction-biaffine-parser\n",
      "2022-04-01 16:10:07,674 - INFO - allennlp.common.params - registered_model_name = biaffine_parser\n",
      "2022-04-01 16:10:07,675 - INFO - allennlp.common.params - model_class = None\n",
      "2022-04-01 16:10:07,676 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-04-01 16:10:07,676 - INFO - allennlp.common.params - display_name = Deep Biaffine Attention for Neural Dependency Parsing\n",
      "2022-04-01 16:10:07,677 - INFO - allennlp.common.params - task_id = dependency-parsing\n",
      "2022-04-01 16:10:07,679 - INFO - allennlp.common.params - model_usage.archive_file = biaffine-dependency-parser-ptb-2020.04.06.tar.gz\n",
      "2022-04-01 16:10:07,680 - INFO - allennlp.common.params - model_usage.training_config = structured_prediction/dependency_parser.jsonnet\n",
      "2022-04-01 16:10:07,681 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
      "2022-04-01 16:10:07,682 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-04-01 16:10:07,684 - INFO - allennlp.common.params - model_details.description = This dependency parser follows the model of [Deep Biaffine Attention for Neural Dependency Parsing (Dozat and Manning, 2016)](https://api.semanticscholar.org/CorpusID:7942973) .\n",
      "\n",
      "Word representations are generated using a bidirectional LSTM, followed by separate biaffine classifiers for pairs of words, predicting whether a directed arc exists between the two words and the dependency label the arc should have. Decoding can either be done greedily, or the optimal Minimum Spanning Tree can be decoded using Edmond's algorithm by viewing the dependency tree as a MST on a fully connected graph, where nodes are words and edges are scored dependency arcs.\n",
      "2022-04-01 16:10:07,685 - INFO - allennlp.common.params - model_details.short_description = A neural model for dependency parsing using biaffine classifiers on top of a bidirectional LSTM.\n",
      "2022-04-01 16:10:07,686 - INFO - allennlp.common.params - model_details.developed_by = Dozat et al\n",
      "2022-04-01 16:10:07,687 - INFO - allennlp.common.params - model_details.contributed_by = None\n",
      "2022-04-01 16:10:07,688 - INFO - allennlp.common.params - model_details.date = 2020-04-06\n",
      "2022-04-01 16:10:07,689 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-04-01 16:10:07,690 - INFO - allennlp.common.params - model_details.model_type = None\n",
      "2022-04-01 16:10:07,691 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@article{Dozat2017DeepBA,\n",
      "title={Deep Biaffine Attention for Neural Dependency Parsing},\n",
      "author={Timothy Dozat and Christopher D. Manning},\n",
      "journal={ArXiv},\n",
      "year={2017},\n",
      "volume={abs/1611.01734}}\n",
      "\n",
      "2022-04-01 16:10:07,692 - INFO - allennlp.common.params - model_details.paper.title = Deep Biaffine Attention for Neural Dependency Parsing (Dozat and Manning, 2016)\n",
      "2022-04-01 16:10:07,693 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:7942973\n",
      "2022-04-01 16:10:07,694 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-04-01 16:10:07,695 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-04-01 16:10:07,696 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-04-01 16:10:07,700 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-04-01 16:10:07,701 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-04-01 16:10:07,702 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-04-01 16:10:07,703 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-04-01 16:10:07,706 - INFO - allennlp.common.params - metrics.model_performance_measures = Attachment scores and exact matches (UAS, LAS, UEM, LEM)\n",
      "2022-04-01 16:10:07,707 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-04-01 16:10:07,709 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-04-01 16:10:07,710 - INFO - allennlp.common.params - evaluation_data.dataset.name = PTB 3.0\n",
      "2022-04-01 16:10:07,711 - INFO - allennlp.common.params - evaluation_data.dataset.notes = The dependency parser was evaluated on the Penn Tree Bank dataset. Unfortunately we cannot release this data due to licensing restrictions by the LDC. You can download the PTB data from the LDC website.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-01 16:10:07,712 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = /path/to/dataset\n",
      "2022-04-01 16:10:07,713 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://catalog.ldc.upenn.edu/LDC99T42\n",
      "2022-04-01 16:10:07,714 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-04-01 16:10:07,716 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-04-01 16:10:07,717 - INFO - allennlp.common.params - training_data.dataset.name = PTB 3.0\n",
      "2022-04-01 16:10:07,718 - INFO - allennlp.common.params - training_data.dataset.notes = The dependency parser was evaluated on the Penn Tree Bank dataset. Unfortunately we cannot release this data due to licensing restrictions by the LDC. You can download the PTB data from the LDC website.\n",
      "2022-04-01 16:10:07,720 - INFO - allennlp.common.params - training_data.dataset.processed_url = /path/to/dataset\n",
      "2022-04-01 16:10:07,721 - INFO - allennlp.common.params - training_data.dataset.url = https://catalog.ldc.upenn.edu/LDC99T42\n",
      "2022-04-01 16:10:07,722 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-04-01 16:10:07,724 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-04-01 16:10:07,726 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = The parser achieves 95.57% and 94.44% unlabeled and labeled attachement score using gold POS tags. For predicted POS tags, it achieves 94.81% UAS and 92.86% LAS respectively.\n",
      "2022-04-01 16:10:07,727 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-04-01 16:10:07,728 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-04-01 16:10:07,730 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-04-01 16:10:07,783 - INFO - allennlp.common.params - id = semparse-nlvr\n",
      "2022-04-01 16:10:07,785 - INFO - allennlp.common.params - registered_model_name = None\n",
      "2022-04-01 16:10:07,786 - INFO - allennlp.common.params - model_class = None\n",
      "2022-04-01 16:10:07,787 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-04-01 16:10:07,788 - INFO - allennlp.common.params - display_name = NLVR Semantic Parsing\n",
      "2022-04-01 16:10:07,790 - INFO - allennlp.common.params - task_id = semparse-nlvr\n",
      "2022-04-01 16:10:07,791 - INFO - allennlp.common.params - model_usage.archive_file = https://allennlp.s3.amazonaws.com/models/nlvr-erm-model-2020.02.10-rule-vocabulary-updated.tar.gz\n",
      "2022-04-01 16:10:07,792 - INFO - allennlp.common.params - model_usage.training_config = None\n",
      "2022-04-01 16:10:07,793 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==1.0.0 allennlp-models==1.0.0\n",
      "2022-04-01 16:10:07,794 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-04-01 16:10:07,795 - INFO - allennlp.common.params - model_details.description = The model is a semantic parser trained on Cornell NLVR.\n",
      "2022-04-01 16:10:07,796 - INFO - allennlp.common.params - model_details.short_description = The model is a semantic parser trained on Cornell NLVR.\n",
      "2022-04-01 16:10:07,797 - INFO - allennlp.common.params - model_details.developed_by = Dasigi et al\n",
      "2022-04-01 16:10:07,798 - INFO - allennlp.common.params - model_details.contributed_by = None\n",
      "2022-04-01 16:10:07,801 - INFO - allennlp.common.params - model_details.date = None\n",
      "2022-04-01 16:10:07,802 - INFO - allennlp.common.params - model_details.version = None\n",
      "2022-04-01 16:10:07,802 - INFO - allennlp.common.params - model_details.model_type = None\n",
      "2022-04-01 16:10:07,803 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@inproceedings{Dasigi2019IterativeSF,\n",
      "title={Iterative Search for Weakly Supervised Semantic Parsing},\n",
      "author={Pradeep Dasigi and Matt Gardner and Shikhar Murty and Luke Zettlemoyer and E. Hovy},\n",
      "booktitle={NAACL-HLT},\n",
      "year={2019}}\n",
      "\n",
      "2022-04-01 16:10:07,804 - INFO - allennlp.common.params - model_details.paper.title = Iterative Search for Weakly Supervised Semantic Parsing\n",
      "2022-04-01 16:10:07,805 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:174799945\n",
      "2022-04-01 16:10:07,805 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-04-01 16:10:07,806 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-04-01 16:10:07,808 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-04-01 16:10:07,809 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-04-01 16:10:07,810 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-04-01 16:10:07,811 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-04-01 16:10:07,813 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-04-01 16:10:07,814 - INFO - allennlp.common.params - metrics.model_performance_measures = Denotation accuracy and consistency\n",
      "2022-04-01 16:10:07,815 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-04-01 16:10:07,816 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-04-01 16:10:07,818 - INFO - allennlp.common.params - evaluation_data.dataset.name = Cornell NLVR\n",
      "2022-04-01 16:10:07,818 - INFO - allennlp.common.params - evaluation_data.dataset.notes = Please download the data from the url provided.\n",
      "2022-04-01 16:10:07,819 - INFO - allennlp.common.params - evaluation_data.dataset.url = http://lil.nlp.cornell.edu/nlvr/\n",
      "2022-04-01 16:10:07,820 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-04-01 16:10:07,821 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-04-01 16:10:07,822 - INFO - allennlp.common.params - training_data.dataset.name = Cornell NLVR\n",
      "2022-04-01 16:10:07,823 - INFO - allennlp.common.params - training_data.dataset.notes = Please download the data from the url provided.\n",
      "2022-04-01 16:10:07,824 - INFO - allennlp.common.params - training_data.dataset.url = http://lil.nlp.cornell.edu/nlvr/\n",
      "2022-04-01 16:10:07,826 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-04-01 16:10:07,827 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-04-01 16:10:07,828 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = None\n",
      "2022-04-01 16:10:07,830 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-04-01 16:10:07,831 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-04-01 16:10:07,833 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-04-01 16:10:07,885 - INFO - allennlp.common.params - id = pair-classification-roberta-mnli\n",
      "2022-04-01 16:10:07,887 - INFO - allennlp.common.params - registered_model_name = basic_classifier\n",
      "2022-04-01 16:10:07,888 - INFO - allennlp.common.params - model_class = None\n",
      "2022-04-01 16:10:07,889 - INFO - allennlp.common.params - registered_predictor_name = textual_entailment\n",
      "2022-04-01 16:10:07,889 - INFO - allennlp.common.params - display_name = RoBERTa MNLI\n",
      "2022-04-01 16:10:07,890 - INFO - allennlp.common.params - task_id = textual_entailment\n",
      "2022-04-01 16:10:07,892 - INFO - allennlp.common.params - model_usage.archive_file = mnli-roberta.2021-03-11.tar.gz\n",
      "2022-04-01 16:10:07,893 - INFO - allennlp.common.params - model_usage.training_config = pair_classification/mnli_roberta.jsonnet\n",
      "2022-04-01 16:10:07,894 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
      "2022-04-01 16:10:07,895 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-04-01 16:10:07,897 - INFO - allennlp.common.params - model_details.description = This `Model` implements a basic text classifier. The text is embedded into a text field using a RoBERTa-large model. The resulting sequence is pooled using a cls_pooler `Seq2VecEncoder` and then passed to a linear classification layer, which projects into the label space.\n",
      "2022-04-01 16:10:07,898 - INFO - allennlp.common.params - model_details.short_description = RoBERTa finetuned on MNLI.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-01 16:10:07,899 - INFO - allennlp.common.params - model_details.developed_by = Liu et al\n",
      "2022-04-01 16:10:07,900 - INFO - allennlp.common.params - model_details.contributed_by = Dirk Groeneveld\n",
      "2022-04-01 16:10:07,901 - INFO - allennlp.common.params - model_details.date = 2020-07-29\n",
      "2022-04-01 16:10:07,902 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-04-01 16:10:07,903 - INFO - allennlp.common.params - model_details.model_type = RoBERTa\n",
      "2022-04-01 16:10:07,904 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@article{Liu2019RoBERTaAR,\n",
      "title={RoBERTa: A Robustly Optimized BERT Pretraining Approach},\n",
      "author={Y. Liu and Myle Ott and Naman Goyal and Jingfei Du and Mandar Joshi and Danqi Chen and Omer Levy and M. Lewis and Luke Zettlemoyer and Veselin Stoyanov},\n",
      "journal={ArXiv},\n",
      "year={2019},\n",
      "volume={abs/1907.11692}}\n",
      "\n",
      "2022-04-01 16:10:07,905 - INFO - allennlp.common.params - model_details.paper.title = RoBERTa: A Robustly Optimized BERT Pretraining Approach (Liu et al)\n",
      "2022-04-01 16:10:07,906 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:198953378\n",
      "2022-04-01 16:10:07,907 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-04-01 16:10:07,908 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-04-01 16:10:07,910 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-04-01 16:10:07,911 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-04-01 16:10:07,913 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-04-01 16:10:07,915 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-04-01 16:10:07,916 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-04-01 16:10:07,918 - INFO - allennlp.common.params - metrics.model_performance_measures = Accuracy\n",
      "2022-04-01 16:10:07,919 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-04-01 16:10:07,920 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-04-01 16:10:07,921 - INFO - allennlp.common.params - evaluation_data.dataset.name = Multi-genre Natural Language Inference (MultiNLI) dev set\n",
      "2022-04-01 16:10:07,922 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = https://allennlp.s3.amazonaws.com/datasets/multinli/multinli_1.0_dev_mismatched.jsonl\n",
      "2022-04-01 16:10:07,923 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://cims.nyu.edu/~sbowman/multinli/\n",
      "2022-04-01 16:10:07,927 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-04-01 16:10:07,928 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-04-01 16:10:07,930 - INFO - allennlp.common.params - training_data.dataset.name = Multi-genre Natural Language Inference (MultiNLI) train set\n",
      "2022-04-01 16:10:07,931 - INFO - allennlp.common.params - training_data.dataset.processed_url = https://allennlp.s3.amazonaws.com/datasets/multinli/multinli_1.0_train.jsonl\n",
      "2022-04-01 16:10:07,932 - INFO - allennlp.common.params - training_data.dataset.url = https://cims.nyu.edu/~sbowman/multinli/\n",
      "2022-04-01 16:10:07,933 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-04-01 16:10:07,934 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-04-01 16:10:07,936 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = None\n",
      "2022-04-01 16:10:07,937 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-04-01 16:10:07,938 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-04-01 16:10:07,939 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-04-01 16:10:07,996 - INFO - allennlp.common.params - id = pair-classification-decomposable-attention-elmo\n",
      "2022-04-01 16:10:07,997 - INFO - allennlp.common.params - registered_model_name = decomposable_attention\n",
      "2022-04-01 16:10:07,998 - INFO - allennlp.common.params - model_class = None\n",
      "2022-04-01 16:10:08,000 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-04-01 16:10:08,001 - INFO - allennlp.common.params - display_name = ELMo-based Decomposable Attention\n",
      "2022-04-01 16:10:08,002 - INFO - allennlp.common.params - task_id = textual_entailment\n",
      "2022-04-01 16:10:08,004 - INFO - allennlp.common.params - model_usage.archive_file = decomposable-attention-elmo-2020.04.09.tar.gz\n",
      "2022-04-01 16:10:08,005 - INFO - allennlp.common.params - model_usage.training_config = decomposable_attention_elmo.jsonnet\n",
      "2022-04-01 16:10:08,005 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
      "2022-04-01 16:10:08,007 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-04-01 16:10:08,008 - INFO - allennlp.common.params - model_details.description = This `Model` implements the Decomposable Attention model described in [A Decomposable Attention Model for Natural Language Inference](https://api.semanticscholar.org/CorpusID:8495258) by Parikh et al., 2016, with some optional enhancements before the decomposable attention actually happens.  Parikh's original model allowed for computing an \"intra-sentence\" attention before doing the decomposable entailment step.  We generalize this to any `Seq2SeqEncoder` that can be applied to the premise and/or the hypothesis before computing entailment.\n",
      "\n",
      "The basic outline of this model is to get an embedded representation of each word in thepremise and hypothesis, align words between the two, compare the aligned phrases, and make a final entailment decision based on this aggregated comparison.  Each step in this process uses a feedforward network to modify the representation.\n",
      "\n",
      "This model uses ELMo embeddings.\n",
      "2022-04-01 16:10:08,009 - INFO - allennlp.common.params - model_details.short_description = The decomposable attention model (Parikh et al, 2017) combined with ELMo embeddings trained on SNLI.\n",
      "2022-04-01 16:10:08,010 - INFO - allennlp.common.params - model_details.developed_by = Parikh et al\n",
      "2022-04-01 16:10:08,010 - INFO - allennlp.common.params - model_details.contributed_by = Dirk Groeneveld\n",
      "2022-04-01 16:10:08,011 - INFO - allennlp.common.params - model_details.date = 2020-04-09\n",
      "2022-04-01 16:10:08,013 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-04-01 16:10:08,014 - INFO - allennlp.common.params - model_details.model_type = Seq2Seq\n",
      "2022-04-01 16:10:08,015 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@article{Parikh2016ADA,\n",
      "title={A Decomposable Attention Model for Natural Language Inference},\n",
      "author={Ankur P. Parikh and Oscar T{\"a}ckstr{\"o}m and Dipanjan Das and Jakob Uszkoreit},\n",
      "journal={ArXiv},\n",
      "year={2016},\n",
      "volume={abs/1606.01933}}\n",
      "\n",
      "2022-04-01 16:10:08,015 - INFO - allennlp.common.params - model_details.paper.title = A Decomposable Attention Model for Natural Language Inference\n",
      "2022-04-01 16:10:08,016 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:8495258\n",
      "2022-04-01 16:10:08,016 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-04-01 16:10:08,017 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-04-01 16:10:08,018 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-04-01 16:10:08,019 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-04-01 16:10:08,019 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-04-01 16:10:08,020 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-04-01 16:10:08,021 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-04-01 16:10:08,023 - INFO - allennlp.common.params - metrics.model_performance_measures = Accuracy\n",
      "2022-04-01 16:10:08,024 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-04-01 16:10:08,025 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-04-01 16:10:08,026 - INFO - allennlp.common.params - evaluation_data.dataset.name = Stanford Natural Language Inference (SNLI) dev set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-01 16:10:08,027 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = https://allennlp.s3.amazonaws.com/datasets/snli/snli_1.0_test.jsonl\n",
      "2022-04-01 16:10:08,027 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://nlp.stanford.edu/projects/snli/\n",
      "2022-04-01 16:10:08,028 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-04-01 16:10:08,028 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-04-01 16:10:08,032 - INFO - allennlp.common.params - training_data.dataset.name = Stanford Natural Language Inference (SNLI) train set\n",
      "2022-04-01 16:10:08,033 - INFO - allennlp.common.params - training_data.dataset.processed_url = https://allennlp.s3.amazonaws.com/datasets/snli/snli_1.0_train.jsonl\n",
      "2022-04-01 16:10:08,034 - INFO - allennlp.common.params - training_data.dataset.url = https://nlp.stanford.edu/projects/snli/\n",
      "2022-04-01 16:10:08,035 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-04-01 16:10:08,037 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-04-01 16:10:08,038 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = None\n",
      "2022-04-01 16:10:08,039 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-04-01 16:10:08,040 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-04-01 16:10:08,041 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-04-01 16:10:08,090 - INFO - allennlp.common.params - id = evaluate_rc-lerc\n",
      "2022-04-01 16:10:08,091 - INFO - allennlp.common.params - registered_model_name = lerc\n",
      "2022-04-01 16:10:08,092 - INFO - allennlp.common.params - model_class = None\n",
      "2022-04-01 16:10:08,093 - INFO - allennlp.common.params - registered_predictor_name = lerc\n",
      "2022-04-01 16:10:08,093 - INFO - allennlp.common.params - display_name = Learned Evaluation for Reading Comprehension (LERC)\n",
      "2022-04-01 16:10:08,094 - INFO - allennlp.common.params - task_id = evaluate_rc\n",
      "2022-04-01 16:10:08,095 - INFO - allennlp.common.params - model_usage.archive_file = lerc-2020-11-18.tar.gz\n",
      "2022-04-01 16:10:08,096 - INFO - allennlp.common.params - model_usage.training_config = None\n",
      "2022-04-01 16:10:08,098 - INFO - allennlp.common.params - model_usage.install_instructions = The model is available at https://github.com/anthonywchen/MOCHA.\n",
      "2022-04-01 16:10:08,099 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-04-01 16:10:08,100 - INFO - allennlp.common.params - model_details.description = LERC is a BERT model that is trained to mimic human judgement scores on candidate answers in the MOCHA dataset. LERC outputs scores that range from 1 to 5, however, to stay consistent with metrics such as BLEU and ROUGE, we normalize the output of LERC to be between 0 and 1 in this demo.\n",
      "2022-04-01 16:10:08,102 - INFO - allennlp.common.params - model_details.short_description = A BERT model that scores candidate answers from 0 to 1.\n",
      "2022-04-01 16:10:08,103 - INFO - allennlp.common.params - model_details.developed_by = Chen et al\n",
      "2022-04-01 16:10:08,104 - INFO - allennlp.common.params - model_details.contributed_by = Anthony Chen\n",
      "2022-04-01 16:10:08,104 - INFO - allennlp.common.params - model_details.date = 2021-03-10\n",
      "2022-04-01 16:10:08,105 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-04-01 16:10:08,105 - INFO - allennlp.common.params - model_details.model_type = BERT\n",
      "2022-04-01 16:10:08,106 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@inproceedings{Chen2020MOCHAAD,\n",
      "title={MOCHA: A Dataset for Training and Evaluating Generative Reading Comprehension Metrics},\n",
      "author={Anthony Chen and Gabriel Stanovsky and S. Singh and Matt Gardner},\n",
      "booktitle={EMNLP},\n",
      "year={2020}}\n",
      "\n",
      "2022-04-01 16:10:08,107 - INFO - allennlp.common.params - model_details.paper.title = MOCHA: A Dataset for Training and Evaluating Generative Reading Comprehension Metrics\n",
      "2022-04-01 16:10:08,107 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:222208714\n",
      "2022-04-01 16:10:08,108 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-04-01 16:10:08,108 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-04-01 16:10:08,110 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-04-01 16:10:08,111 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-04-01 16:10:08,111 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-04-01 16:10:08,112 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-04-01 16:10:08,114 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-04-01 16:10:08,116 - INFO - allennlp.common.params - metrics.model_performance_measures = Pearson Correlation\n",
      "2022-04-01 16:10:08,117 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-04-01 16:10:08,118 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-04-01 16:10:08,119 - INFO - allennlp.common.params - evaluation_data.dataset.name = MOCHA\n",
      "2022-04-01 16:10:08,120 - INFO - allennlp.common.params - evaluation_data.dataset.notes = To evaluate this model follow the instructions at https://github.com/anthonywchen/MOCHA.\n",
      "2022-04-01 16:10:08,121 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = None\n",
      "2022-04-01 16:10:08,121 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://allennlp.org/mocha\n",
      "2022-04-01 16:10:08,122 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-04-01 16:10:08,123 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-04-01 16:10:08,124 - INFO - allennlp.common.params - training_data.dataset.name = MOCHA\n",
      "2022-04-01 16:10:08,125 - INFO - allennlp.common.params - training_data.dataset.notes = To train this model follow the instructions at https://github.com/anthonywchen/MOCHA.\n",
      "2022-04-01 16:10:08,126 - INFO - allennlp.common.params - training_data.dataset.processed_url = None\n",
      "2022-04-01 16:10:08,126 - INFO - allennlp.common.params - training_data.dataset.url = https://allennlp.org/mocha\n",
      "2022-04-01 16:10:08,127 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-04-01 16:10:08,128 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-04-01 16:10:08,129 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = None\n",
      "2022-04-01 16:10:08,130 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-04-01 16:10:08,131 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-04-01 16:10:08,133 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-04-01 16:10:08,141 - WARNING - allennlp.common.model_card - lerc is not a registered model.\n",
      "2022-04-01 16:10:08,198 - INFO - allennlp.common.params - id = mc-roberta-piqa\n",
      "2022-04-01 16:10:08,199 - INFO - allennlp.common.params - registered_model_name = transformer_mc\n",
      "2022-04-01 16:10:08,200 - INFO - allennlp.common.params - model_class = None\n",
      "2022-04-01 16:10:08,201 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-04-01 16:10:08,202 - INFO - allennlp.common.params - display_name = Physical Interaction Question Answering\n",
      "2022-04-01 16:10:08,203 - INFO - allennlp.common.params - task_id = mc\n",
      "2022-04-01 16:10:08,205 - INFO - allennlp.common.params - model_usage.archive_file = piqa.2020-07-08.tar.gz\n",
      "2022-04-01 16:10:08,206 - INFO - allennlp.common.params - model_usage.training_config = mc/piqa.jsonnet\n",
      "2022-04-01 16:10:08,207 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==1.0.0 allennlp-models==1.0.0\n",
      "2022-04-01 16:10:08,207 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-04-01 16:10:08,208 - INFO - allennlp.common.params - model_details.description = This is a multiple choice model patterned after the BERT architecture. It calculates a score for each sequence on top of the CLS token, and then chooses the alternative with the highest score.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-01 16:10:08,209 - INFO - allennlp.common.params - model_details.short_description = RoBERTa-based multiple choice model for PIQA.\n",
      "2022-04-01 16:10:08,210 - INFO - allennlp.common.params - model_details.developed_by = Devlin et al\n",
      "2022-04-01 16:10:08,210 - INFO - allennlp.common.params - model_details.contributed_by = Dirk Groeneveld\n",
      "2022-04-01 16:10:08,211 - INFO - allennlp.common.params - model_details.date = 2020-07-08\n",
      "2022-04-01 16:10:08,211 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-04-01 16:10:08,212 - INFO - allennlp.common.params - model_details.model_type = RoBERTa large\n",
      "2022-04-01 16:10:08,213 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@article{Liu2019RoBERTaAR,\n",
      "title={RoBERTa: A Robustly Optimized BERT Pretraining Approach},\n",
      "author={Y. Liu and Myle Ott and Naman Goyal and Jingfei Du and Mandar Joshi and Danqi Chen and Omer Levy and M. Lewis and Luke Zettlemoyer and Veselin Stoyanov},\n",
      "journal={ArXiv},\n",
      "year={2019},\n",
      "volume={abs/1907.11692}}\n",
      "\n",
      "2022-04-01 16:10:08,214 - INFO - allennlp.common.params - model_details.paper.title = RoBERTa: A Robustly Optimized BERT Pretraining Approach (Liu et al)\n",
      "2022-04-01 16:10:08,215 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:198953378\n",
      "2022-04-01 16:10:08,216 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-04-01 16:10:08,219 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-04-01 16:10:08,220 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-04-01 16:10:08,221 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-04-01 16:10:08,222 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-04-01 16:10:08,223 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-04-01 16:10:08,224 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-04-01 16:10:08,226 - INFO - allennlp.common.params - metrics.model_performance_measures = The chosen metric is accuracy, since it is a multiple choice model.\n",
      "2022-04-01 16:10:08,226 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-04-01 16:10:08,227 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-04-01 16:10:08,229 - INFO - allennlp.common.params - evaluation_data.dataset.name = PIQA (validation set)\n",
      "2022-04-01 16:10:08,230 - INFO - allennlp.common.params - evaluation_data.dataset.notes = Please download the data from the url provided.\n",
      "2022-04-01 16:10:08,230 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://yonatanbisk.com/piqa/\n",
      "2022-04-01 16:10:08,231 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-04-01 16:10:08,234 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-04-01 16:10:08,235 - INFO - allennlp.common.params - training_data.dataset.name = PIQA (train set)\n",
      "2022-04-01 16:10:08,235 - INFO - allennlp.common.params - training_data.dataset.notes = Please download the data from the url provided.\n",
      "2022-04-01 16:10:08,236 - INFO - allennlp.common.params - training_data.dataset.url = https://yonatanbisk.com/piqa/\n",
      "2022-04-01 16:10:08,236 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-04-01 16:10:08,237 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-04-01 16:10:08,238 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = None\n",
      "2022-04-01 16:10:08,238 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-04-01 16:10:08,239 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-04-01 16:10:08,241 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-04-01 16:10:08,294 - INFO - allennlp.common.params - id = lm-next-token-lm-gpt2\n",
      "2022-04-01 16:10:08,295 - INFO - allennlp.common.params - registered_model_name = next_token_lm\n",
      "2022-04-01 16:10:08,296 - INFO - allennlp.common.params - model_class = None\n",
      "2022-04-01 16:10:08,297 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-04-01 16:10:08,298 - INFO - allennlp.common.params - display_name = GPT2-based Next Token Language Model\n",
      "2022-04-01 16:10:08,299 - INFO - allennlp.common.params - task_id = language-modeling\n",
      "2022-04-01 16:10:08,300 - INFO - allennlp.common.params - model_usage.archive_file = gpt2-next-word-lm-2020.06.30.tar.gz\n",
      "2022-04-01 16:10:08,301 - INFO - allennlp.common.params - model_usage.training_config = None\n",
      "2022-04-01 16:10:08,303 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==1.0.0 allennlp-models==1.0.0\n",
      "2022-04-01 16:10:08,304 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-04-01 16:10:08,306 - INFO - allennlp.common.params - model_details.description = This is the public 345M parameter OpenAI GPT-2 language model for generating sentences. The model embeds some input tokens, contextualizes them, then predicts the next word, computing a loss against known target. \n",
      "If `BeamSearch` is given, this model will predict a sequence of next tokens.\n",
      "2022-04-01 16:10:08,307 - INFO - allennlp.common.params - model_details.short_description = OpenAI's GPT-2 language model that generates the next token.\n",
      "2022-04-01 16:10:08,307 - INFO - allennlp.common.params - model_details.developed_by = Radford et al\n",
      "2022-04-01 16:10:08,308 - INFO - allennlp.common.params - model_details.contributed_by = None\n",
      "2022-04-01 16:10:08,309 - INFO - allennlp.common.params - model_details.date = 2020-06-30\n",
      "2022-04-01 16:10:08,310 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-04-01 16:10:08,310 - INFO - allennlp.common.params - model_details.model_type = GPT2\n",
      "2022-04-01 16:10:08,311 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@inproceedings{Radford2019LanguageMA,\n",
      "title={Language Models are Unsupervised Multitask Learners},\n",
      "author={A. Radford and Jeffrey Wu and R. Child and David Luan and Dario Amodei and Ilya Sutskever},\n",
      "year={2019}}\n",
      "\n",
      "2022-04-01 16:10:08,312 - INFO - allennlp.common.params - model_details.paper.title = Language Models are Unsupervised Multitask Learners\n",
      "2022-04-01 16:10:08,313 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:160025533\n",
      "2022-04-01 16:10:08,313 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-04-01 16:10:08,314 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-04-01 16:10:08,315 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-04-01 16:10:08,316 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-04-01 16:10:08,317 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-04-01 16:10:08,318 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-04-01 16:10:08,318 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-04-01 16:10:08,320 - INFO - allennlp.common.params - metrics.model_performance_measures = Perplexity\n",
      "2022-04-01 16:10:08,322 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-04-01 16:10:08,322 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-04-01 16:10:08,324 - INFO - allennlp.common.params - evaluation_data.dataset.name = WebText corpus\n",
      "2022-04-01 16:10:08,325 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://github.com/openai/gpt-2-output-dataset\n",
      "2022-04-01 16:10:08,325 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-04-01 16:10:08,326 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-04-01 16:10:08,328 - INFO - allennlp.common.params - training_data.dataset.name = WebText corpus\n",
      "2022-04-01 16:10:08,329 - INFO - allennlp.common.params - training_data.dataset.url = https://github.com/openai/gpt-2-output-dataset\n",
      "2022-04-01 16:10:08,330 - INFO - allennlp.common.params - training_data.motivation = WebText emphasizes document quality. Only human-curated/filtered documents are scraped. Reddit outbound links which receive at least 3 karma points are taken as a proxy for human filtered webpages that are interesting.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-01 16:10:08,330 - INFO - allennlp.common.params - training_data.preprocessing = Dragnet and [Newspaper](https://github.com/codelucas/newspaper) content extractors are used. Wikipedia articles are removed.\n",
      "2022-04-01 16:10:08,332 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = None\n",
      "2022-04-01 16:10:08,333 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-04-01 16:10:08,334 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-04-01 16:10:08,335 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-04-01 16:10:08,393 - INFO - allennlp.common.params - id = tagging-fine-grained-crf-tagger\n",
      "2022-04-01 16:10:08,394 - INFO - allennlp.common.params - registered_model_name = crf_tagger\n",
      "2022-04-01 16:10:08,394 - INFO - allennlp.common.params - model_class = None\n",
      "2022-04-01 16:10:08,395 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-04-01 16:10:08,395 - INFO - allennlp.common.params - display_name = Fine Grained Named Entity Recognition\n",
      "2022-04-01 16:10:08,396 - INFO - allennlp.common.params - task_id = ner\n",
      "2022-04-01 16:10:08,397 - INFO - allennlp.common.params - model_usage.archive_file = fine-grained-ner.2021-02-11.tar.gz\n",
      "2022-04-01 16:10:08,398 - INFO - allennlp.common.params - model_usage.training_config = tagging/fine-grained-ner.jsonnet\n",
      "2022-04-01 16:10:08,399 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
      "2022-04-01 16:10:08,400 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-04-01 16:10:08,401 - INFO - allennlp.common.params - model_details.description = This model identifies a broad range of 16 semantic types in the input text. It is a reimplementation of Lample (2016) and uses a biLSTM with a CRF layer, character embeddings and ELMo embeddings.\n",
      "2022-04-01 16:10:08,402 - INFO - allennlp.common.params - model_details.short_description = This model identifies a broad range of 16 semantic types in the input text. It is a reimplementation of Lample (2016) and uses a biLSTM with a CRF layer, character embeddings and ELMo embeddings.\n",
      "2022-04-01 16:10:08,405 - INFO - allennlp.common.params - model_details.developed_by = Lample et al\n",
      "2022-04-01 16:10:08,406 - INFO - allennlp.common.params - model_details.contributed_by = None\n",
      "2022-04-01 16:10:08,406 - INFO - allennlp.common.params - model_details.date = 2020-06-24\n",
      "2022-04-01 16:10:08,407 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-04-01 16:10:08,408 - INFO - allennlp.common.params - model_details.model_type = BiLSTM\n",
      "2022-04-01 16:10:08,409 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@article{Lample2016NeuralAF,\n",
      "title={Neural Architectures for Named Entity Recognition},\n",
      "author={Guillaume Lample and Miguel Ballesteros and Sandeep Subramanian and K. Kawakami and Chris Dyer},\n",
      "journal={ArXiv},\n",
      "year={2016},\n",
      "volume={abs/1603.01360}}\n",
      "\n",
      "2022-04-01 16:10:08,410 - INFO - allennlp.common.params - model_details.paper.title = Neural Architectures for Named Entity Recognition\n",
      "2022-04-01 16:10:08,411 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:6042994\n",
      "2022-04-01 16:10:08,412 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-04-01 16:10:08,413 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-04-01 16:10:08,414 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-04-01 16:10:08,415 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-04-01 16:10:08,416 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-04-01 16:10:08,417 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-04-01 16:10:08,418 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-04-01 16:10:08,418 - INFO - allennlp.common.params - metrics.model_performance_measures = Accuracy and Span-based F1 metric\n",
      "2022-04-01 16:10:08,422 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-04-01 16:10:08,422 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-04-01 16:10:08,424 - INFO - allennlp.common.params - evaluation_data.dataset.name = Ontonotes 5.0\n",
      "2022-04-01 16:10:08,425 - INFO - allennlp.common.params - evaluation_data.dataset.notes = Unfortunately we cannot release this data due to licensing restrictions.\n",
      "2022-04-01 16:10:08,425 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = /path/do/dataset\n",
      "2022-04-01 16:10:08,426 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://catalog.ldc.upenn.edu/LDC2013T19\n",
      "2022-04-01 16:10:08,427 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-04-01 16:10:08,427 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-04-01 16:10:08,428 - INFO - allennlp.common.params - training_data.dataset.name = Ontonotes 5.0\n",
      "2022-04-01 16:10:08,429 - INFO - allennlp.common.params - training_data.dataset.notes = Unfortunately we cannot release this data due to licensing restrictions.\n",
      "2022-04-01 16:10:08,430 - INFO - allennlp.common.params - training_data.dataset.processed_url = /path/do/dataset\n",
      "2022-04-01 16:10:08,431 - INFO - allennlp.common.params - training_data.dataset.url = https://catalog.ldc.upenn.edu/LDC2013T19\n",
      "2022-04-01 16:10:08,433 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-04-01 16:10:08,434 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-04-01 16:10:08,435 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = On the validation set:\n",
      "Accuracy: 97%\n",
      "F1: 88%\n",
      "2022-04-01 16:10:08,437 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-04-01 16:10:08,438 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-04-01 16:10:08,440 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-04-01 16:10:08,494 - INFO - allennlp.common.params - id = generation-bart\n",
      "2022-04-01 16:10:08,495 - INFO - allennlp.common.params - registered_model_name = bart\n",
      "2022-04-01 16:10:08,496 - INFO - allennlp.common.params - model_class = None\n",
      "2022-04-01 16:10:08,497 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-04-01 16:10:08,498 - INFO - allennlp.common.params - display_name = BART\n",
      "2022-04-01 16:10:08,499 - INFO - allennlp.common.params - task_id = None\n",
      "2022-04-01 16:10:08,500 - INFO - allennlp.common.params - model_usage.archive_file = bart-2020.07.25.tar.gz\n",
      "2022-04-01 16:10:08,501 - INFO - allennlp.common.params - model_usage.training_config = generation/bart_cnn_dm.jsonnet\n",
      "2022-04-01 16:10:08,502 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==1.0.0 allennlp-models==1.0.0\n",
      "2022-04-01 16:10:08,503 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-04-01 16:10:08,505 - INFO - allennlp.common.params - model_details.description = The BART model here uses a language modeling head, and therefore can be used for generation. The BART encoder, implemented as a `Seq2SeqEncoder`, which assumes it operates on already embedded inputs.  This means that we remove the token and position embeddings from BART in this module.  For the typical use case of using BART to encode inputs to your model (where we include the token and position embeddings from BART), you should use `PretrainedTransformerEmbedder(bart_model_name, sub_module=\"encoder\")` instead of this.\n",
      "2022-04-01 16:10:08,505 - INFO - allennlp.common.params - model_details.short_description = BART with a language model head for generation.\n",
      "2022-04-01 16:10:08,506 - INFO - allennlp.common.params - model_details.developed_by = Lewis et al\n",
      "2022-04-01 16:10:08,506 - INFO - allennlp.common.params - model_details.contributed_by = Dirk Groeneveld\n",
      "2022-04-01 16:10:08,507 - INFO - allennlp.common.params - model_details.date = 2020-07-25\n",
      "2022-04-01 16:10:08,507 - INFO - allennlp.common.params - model_details.version = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-01 16:10:08,508 - INFO - allennlp.common.params - model_details.model_type = BART\n",
      "2022-04-01 16:10:08,508 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@inproceedings{Lewis2020BARTDS,\n",
      "title={BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension},\n",
      "author={M. Lewis and Yinhan Liu and Naman Goyal and Marjan Ghazvininejad and A. Mohamed and Omer Levy and Ves Stoyanov and L. Zettlemoyer},\n",
      "booktitle={ACL},\n",
      "year={2020}}\n",
      "\n",
      "2022-04-01 16:10:08,509 - INFO - allennlp.common.params - model_details.paper.title = BART: Denosing Sequence-to-Sequence Pre-training for Natural Language Generation,Translation, and Comprehension\n",
      "2022-04-01 16:10:08,510 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:204960716\n",
      "2022-04-01 16:10:08,511 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-04-01 16:10:08,511 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-04-01 16:10:08,515 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-04-01 16:10:08,515 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-04-01 16:10:08,516 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-04-01 16:10:08,517 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-04-01 16:10:08,518 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-04-01 16:10:08,519 - INFO - allennlp.common.params - metrics.model_performance_measures = ROUGE and BLEU\n",
      "2022-04-01 16:10:08,519 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-04-01 16:10:08,520 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-04-01 16:10:08,523 - INFO - allennlp.common.params - evaluation_data.dataset.name = CNN/DailyMail\n",
      "2022-04-01 16:10:08,523 - INFO - allennlp.common.params - evaluation_data.dataset.notes = Please download the data from the url provided.\n",
      "2022-04-01 16:10:08,524 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://github.com/abisee/cnn-dailymail\n",
      "2022-04-01 16:10:08,525 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-04-01 16:10:08,526 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-04-01 16:10:08,528 - INFO - allennlp.common.params - training_data.dataset.name = CNN/DailyMail\n",
      "2022-04-01 16:10:08,530 - INFO - allennlp.common.params - training_data.dataset.notes = Please download the data from the url provided.\n",
      "2022-04-01 16:10:08,531 - INFO - allennlp.common.params - training_data.dataset.url = https://github.com/abisee/cnn-dailymail\n",
      "2022-04-01 16:10:08,532 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-04-01 16:10:08,533 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-04-01 16:10:08,534 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = None\n",
      "2022-04-01 16:10:08,536 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-04-01 16:10:08,537 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-04-01 16:10:08,538 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-04-01 16:10:08,864 - INFO - allennlp.common.plugins - Plugin allennlp_models available\n",
      "2022-04-01 16:10:08,922 - INFO - allennlp.common.plugins - Plugin allennlp_semparse available\n",
      "2022-04-01 16:10:08,928 - INFO - allennlp.common.plugins - Plugin allennlp_server available\n",
      "2022-04-01 16:10:09,186 - INFO - cached_path - cache of https://storage.googleapis.com/allennlp-public-models/openie-model.2020.03.26.tar.gz is up-to-date\n",
      "2022-04-01 16:10:09,188 - INFO - allennlp.models.archival - loading archive file https://storage.googleapis.com/allennlp-public-models/openie-model.2020.03.26.tar.gz from cache at /home/jg/.allennlp/cache/60314a853eb0aaa774d176d878c62469d49872feb4f2bfd071a75c77f6d76707.1b91cc27e347f2df04ce771a304bee2b70a2c487626b67e277d44c593b868c25\n",
      "2022-04-01 16:10:09,190 - INFO - allennlp.models.archival - extracting archive file /home/jg/.allennlp/cache/60314a853eb0aaa774d176d878c62469d49872feb4f2bfd071a75c77f6d76707.1b91cc27e347f2df04ce771a304bee2b70a2c487626b67e277d44c593b868c25 to temp dir /tmp/tmpdls4a4h5\n",
      "2022-04-01 16:10:09,846 - INFO - allennlp.common.params - dataset_reader.type = srl\n",
      "2022-04-01 16:10:09,848 - INFO - allennlp.common.params - dataset_reader.max_instances = None\n",
      "2022-04-01 16:10:09,849 - INFO - allennlp.common.params - dataset_reader.manual_distributed_sharding = False\n",
      "2022-04-01 16:10:09,850 - INFO - allennlp.common.params - dataset_reader.manual_multiprocess_sharding = False\n",
      "2022-04-01 16:10:09,851 - INFO - allennlp.common.params - dataset_reader.token_indexers = None\n",
      "2022-04-01 16:10:09,852 - INFO - allennlp.common.params - dataset_reader.domain_identifier = None\n",
      "2022-04-01 16:10:09,853 - INFO - allennlp.common.params - dataset_reader.bert_model_name = None\n",
      "2022-04-01 16:10:09,855 - INFO - allennlp.common.params - dataset_reader.type = srl\n",
      "2022-04-01 16:10:09,856 - INFO - allennlp.common.params - dataset_reader.max_instances = None\n",
      "2022-04-01 16:10:09,857 - INFO - allennlp.common.params - dataset_reader.manual_distributed_sharding = False\n",
      "2022-04-01 16:10:09,857 - INFO - allennlp.common.params - dataset_reader.manual_multiprocess_sharding = False\n",
      "2022-04-01 16:10:09,858 - INFO - allennlp.common.params - dataset_reader.token_indexers = None\n",
      "2022-04-01 16:10:09,859 - INFO - allennlp.common.params - dataset_reader.domain_identifier = None\n",
      "2022-04-01 16:10:09,860 - INFO - allennlp.common.params - dataset_reader.bert_model_name = None\n",
      "2022-04-01 16:10:09,860 - INFO - allennlp.common.params - type = from_instances\n",
      "2022-04-01 16:10:09,861 - INFO - allennlp.data.vocabulary - Loading token dictionary from /tmp/tmpdls4a4h5/vocabulary.\n",
      "2022-04-01 16:10:09,937 - INFO - allennlp.common.params - model.type = srl\n",
      "2022-04-01 16:10:09,939 - INFO - allennlp.common.params - model.regularizer = None\n",
      "2022-04-01 16:10:09,939 - INFO - allennlp.common.params - model.ddp_accelerator = None\n",
      "2022-04-01 16:10:09,940 - INFO - allennlp.common.params - model.text_field_embedder.type = basic\n",
      "2022-04-01 16:10:09,941 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.type = embedding\n",
      "2022-04-01 16:10:09,942 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.embedding_dim = 100\n",
      "2022-04-01 16:10:09,943 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.num_embeddings = None\n",
      "2022-04-01 16:10:09,944 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.projection_dim = None\n",
      "2022-04-01 16:10:09,945 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.weight = None\n",
      "2022-04-01 16:10:09,945 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.padding_index = None\n",
      "2022-04-01 16:10:09,946 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.trainable = True\n",
      "2022-04-01 16:10:09,947 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.max_norm = None\n",
      "2022-04-01 16:10:09,948 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.norm_type = 2.0\n",
      "2022-04-01 16:10:09,949 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.scale_grad_by_freq = False\n",
      "2022-04-01 16:10:09,950 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.sparse = False\n",
      "2022-04-01 16:10:09,952 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.vocab_namespace = tokens\n",
      "2022-04-01 16:10:09,953 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.pretrained_file = None\n",
      "2022-04-01 16:10:10,031 - INFO - allennlp.common.params - model.encoder.type = alternating_lstm\n",
      "2022-04-01 16:10:10,033 - INFO - allennlp.common.params - model.encoder.input_size = 200\n",
      "2022-04-01 16:10:10,034 - INFO - allennlp.common.params - model.encoder.hidden_size = 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-01 16:10:10,035 - INFO - allennlp.common.params - model.encoder.num_layers = 8\n",
      "2022-04-01 16:10:10,036 - INFO - allennlp.common.params - model.encoder.recurrent_dropout_probability = 0.1\n",
      "2022-04-01 16:10:10,037 - INFO - allennlp.common.params - model.encoder.use_highway = True\n",
      "2022-04-01 16:10:10,039 - INFO - allennlp.common.params - model.encoder.use_input_projection_bias = True\n",
      "2022-04-01 16:10:10,040 - INFO - allennlp.common.params - model.encoder.stateful = False\n",
      "2022-04-01 16:10:10,500 - INFO - allennlp.common.params - model.binary_feature_dim = 100\n",
      "2022-04-01 16:10:10,501 - INFO - allennlp.common.params - model.embedding_dropout = 0.0\n",
      "2022-04-01 16:10:10,502 - INFO - allennlp.common.params - model.initializer = <allennlp.nn.initializers.InitializerApplicator object at 0x7f3be08f7b10>\n",
      "2022-04-01 16:10:10,503 - INFO - allennlp.common.params - model.label_smoothing = None\n",
      "2022-04-01 16:10:10,503 - INFO - allennlp.common.params - model.ignore_span_metric = False\n",
      "2022-04-01 16:10:10,504 - INFO - allennlp.common.params - model.srl_eval_path = /home/jg/anaconda3/envs/allennlp37/lib/python3.7/site-packages/allennlp_models/structured_prediction/tools/srl-eval.pl\n",
      "2022-04-01 16:10:10,507 - INFO - allennlp.nn.initializers - Initializing parameters\n",
      "2022-04-01 16:10:10,508 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code\n",
      "2022-04-01 16:10:10,509 - INFO - allennlp.nn.initializers -    binary_feature_embedding.weight\n",
      "2022-04-01 16:10:10,509 - INFO - allennlp.nn.initializers -    encoder._module.layer_0.cell.input_linearity.bias\n",
      "2022-04-01 16:10:10,510 - INFO - allennlp.nn.initializers -    encoder._module.layer_0.cell.input_linearity.weight\n",
      "2022-04-01 16:10:10,510 - INFO - allennlp.nn.initializers -    encoder._module.layer_0.cell.state_linearity.bias\n",
      "2022-04-01 16:10:10,511 - INFO - allennlp.nn.initializers -    encoder._module.layer_0.cell.state_linearity.weight\n",
      "2022-04-01 16:10:10,511 - INFO - allennlp.nn.initializers -    encoder._module.layer_1.cell.input_linearity.bias\n",
      "2022-04-01 16:10:10,512 - INFO - allennlp.nn.initializers -    encoder._module.layer_1.cell.input_linearity.weight\n",
      "2022-04-01 16:10:10,513 - INFO - allennlp.nn.initializers -    encoder._module.layer_1.cell.state_linearity.bias\n",
      "2022-04-01 16:10:10,514 - INFO - allennlp.nn.initializers -    encoder._module.layer_1.cell.state_linearity.weight\n",
      "2022-04-01 16:10:10,515 - INFO - allennlp.nn.initializers -    encoder._module.layer_2.cell.input_linearity.bias\n",
      "2022-04-01 16:10:10,516 - INFO - allennlp.nn.initializers -    encoder._module.layer_2.cell.input_linearity.weight\n",
      "2022-04-01 16:10:10,517 - INFO - allennlp.nn.initializers -    encoder._module.layer_2.cell.state_linearity.bias\n",
      "2022-04-01 16:10:10,518 - INFO - allennlp.nn.initializers -    encoder._module.layer_2.cell.state_linearity.weight\n",
      "2022-04-01 16:10:10,519 - INFO - allennlp.nn.initializers -    encoder._module.layer_3.cell.input_linearity.bias\n",
      "2022-04-01 16:10:10,522 - INFO - allennlp.nn.initializers -    encoder._module.layer_3.cell.input_linearity.weight\n",
      "2022-04-01 16:10:10,522 - INFO - allennlp.nn.initializers -    encoder._module.layer_3.cell.state_linearity.bias\n",
      "2022-04-01 16:10:10,523 - INFO - allennlp.nn.initializers -    encoder._module.layer_3.cell.state_linearity.weight\n",
      "2022-04-01 16:10:10,524 - INFO - allennlp.nn.initializers -    encoder._module.layer_4.cell.input_linearity.bias\n",
      "2022-04-01 16:10:10,525 - INFO - allennlp.nn.initializers -    encoder._module.layer_4.cell.input_linearity.weight\n",
      "2022-04-01 16:10:10,526 - INFO - allennlp.nn.initializers -    encoder._module.layer_4.cell.state_linearity.bias\n",
      "2022-04-01 16:10:10,527 - INFO - allennlp.nn.initializers -    encoder._module.layer_4.cell.state_linearity.weight\n",
      "2022-04-01 16:10:10,528 - INFO - allennlp.nn.initializers -    encoder._module.layer_5.cell.input_linearity.bias\n",
      "2022-04-01 16:10:10,529 - INFO - allennlp.nn.initializers -    encoder._module.layer_5.cell.input_linearity.weight\n",
      "2022-04-01 16:10:10,530 - INFO - allennlp.nn.initializers -    encoder._module.layer_5.cell.state_linearity.bias\n",
      "2022-04-01 16:10:10,530 - INFO - allennlp.nn.initializers -    encoder._module.layer_5.cell.state_linearity.weight\n",
      "2022-04-01 16:10:10,531 - INFO - allennlp.nn.initializers -    encoder._module.layer_6.cell.input_linearity.bias\n",
      "2022-04-01 16:10:10,532 - INFO - allennlp.nn.initializers -    encoder._module.layer_6.cell.input_linearity.weight\n",
      "2022-04-01 16:10:10,533 - INFO - allennlp.nn.initializers -    encoder._module.layer_6.cell.state_linearity.bias\n",
      "2022-04-01 16:10:10,534 - INFO - allennlp.nn.initializers -    encoder._module.layer_6.cell.state_linearity.weight\n",
      "2022-04-01 16:10:10,535 - INFO - allennlp.nn.initializers -    encoder._module.layer_7.cell.input_linearity.bias\n",
      "2022-04-01 16:10:10,535 - INFO - allennlp.nn.initializers -    encoder._module.layer_7.cell.input_linearity.weight\n",
      "2022-04-01 16:10:10,536 - INFO - allennlp.nn.initializers -    encoder._module.layer_7.cell.state_linearity.bias\n",
      "2022-04-01 16:10:10,539 - INFO - allennlp.nn.initializers -    encoder._module.layer_7.cell.state_linearity.weight\n",
      "2022-04-01 16:10:10,541 - INFO - allennlp.nn.initializers -    tag_projection_layer._module.bias\n",
      "2022-04-01 16:10:10,542 - INFO - allennlp.nn.initializers -    tag_projection_layer._module.weight\n",
      "2022-04-01 16:10:10,543 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_tokens.weight\n",
      "2022-04-01 16:10:10,548 - INFO - allennlp.modules.token_embedders.embedding - Loading a model trained before embedding extension was implemented; pass an explicit vocab namespace if you want to extend the vocabulary.\n",
      "2022-04-01 16:10:10,593 - INFO - allennlp.models.archival - removing temporary unarchived model dir at /tmp/tmpdls4a4h5\n",
      "2022-04-01 16:10:11,631 - INFO - allennlp.common.plugins - Plugin allennlp_models available\n",
      "2022-04-01 16:10:11,702 - INFO - allennlp.common.plugins - Plugin allennlp_semparse available\n",
      "2022-04-01 16:10:11,707 - INFO - allennlp.common.plugins - Plugin allennlp_server available\n",
      "2022-04-01 16:10:11,754 - INFO - allennlp.common.params - id = pair-classification-esim\n",
      "2022-04-01 16:10:11,755 - INFO - allennlp.common.params - registered_model_name = esim\n",
      "2022-04-01 16:10:11,756 - INFO - allennlp.common.params - model_class = None\n",
      "2022-04-01 16:10:11,756 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-04-01 16:10:11,757 - INFO - allennlp.common.params - display_name = Enhanced LSTM for Natural Language Inference\n",
      "2022-04-01 16:10:11,758 - INFO - allennlp.common.params - task_id = textual_entailment\n",
      "2022-04-01 16:10:11,759 - INFO - allennlp.common.params - model_usage.archive_file = esim-elmo-2020.11.11.tar.gz\n",
      "2022-04-01 16:10:11,760 - INFO - allennlp.common.params - model_usage.training_config = esim.jsonnet\n",
      "2022-04-01 16:10:11,760 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==1.0.0 allennlp-models==1.0.0\n",
      "2022-04-01 16:10:11,761 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-04-01 16:10:11,762 - INFO - allennlp.common.params - model_details.description = This `Model` implements the ESIM model, which is a sequential neural inference model based on chain LSTMs.\n",
      "2022-04-01 16:10:11,763 - INFO - allennlp.common.params - model_details.short_description = Enhanced LSTM trained on SNLI.\n",
      "2022-04-01 16:10:11,765 - INFO - allennlp.common.params - model_details.developed_by = Chen et al\n",
      "2022-04-01 16:10:11,766 - INFO - allennlp.common.params - model_details.contributed_by = Dirk Groeneveld\n",
      "2022-04-01 16:10:11,767 - INFO - allennlp.common.params - model_details.date = 2020-04-09\n",
      "2022-04-01 16:10:11,768 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-04-01 16:10:11,772 - INFO - allennlp.common.params - model_details.model_type = LSTM\n",
      "2022-04-01 16:10:11,773 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@inproceedings{Chen2017EnhancedLF,\n",
      "title={Enhanced LSTM for Natural Language Inference},\n",
      "author={Qian Chen and Xiao-Dan Zhu and Z. Ling and Si Wei and Hui Jiang and Diana Inkpen},\n",
      "booktitle={ACL},\n",
      "year={2017}}\n",
      "\n",
      "2022-04-01 16:10:11,774 - INFO - allennlp.common.params - model_details.paper.title = Enhanced LSTM for Natural Language Inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-01 16:10:11,775 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:34032948\n",
      "2022-04-01 16:10:11,776 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-04-01 16:10:11,778 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-04-01 16:10:11,779 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-04-01 16:10:11,780 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-04-01 16:10:11,781 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-04-01 16:10:11,783 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-04-01 16:10:11,784 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-04-01 16:10:11,786 - INFO - allennlp.common.params - metrics.model_performance_measures = Accuracy\n",
      "2022-04-01 16:10:11,787 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-04-01 16:10:11,788 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-04-01 16:10:11,790 - INFO - allennlp.common.params - evaluation_data.dataset.name = Stanford Natural Language Inference (SNLI) dev set\n",
      "2022-04-01 16:10:11,791 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = https://allennlp.s3.amazonaws.com/datasets/snli/snli_1.0_test.jsonl\n",
      "2022-04-01 16:10:11,792 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://nlp.stanford.edu/projects/snli/\n",
      "2022-04-01 16:10:11,795 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-04-01 16:10:11,796 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-04-01 16:10:11,797 - INFO - allennlp.common.params - training_data.dataset.name = Stanford Natural Language Inference (SNLI) train set\n",
      "2022-04-01 16:10:11,798 - INFO - allennlp.common.params - training_data.dataset.processed_url = https://allennlp.s3.amazonaws.com/datasets/snli/snli_1.0_train.jsonl\n",
      "2022-04-01 16:10:11,799 - INFO - allennlp.common.params - training_data.dataset.url = https://nlp.stanford.edu/projects/snli/\n",
      "2022-04-01 16:10:11,801 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-04-01 16:10:11,801 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-04-01 16:10:11,802 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = None\n",
      "2022-04-01 16:10:11,805 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-04-01 16:10:11,806 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-04-01 16:10:11,807 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-04-01 16:10:11,858 - INFO - allennlp.common.params - id = rc-nmn\n",
      "2022-04-01 16:10:11,859 - INFO - allennlp.common.params - registered_model_name = None\n",
      "2022-04-01 16:10:11,860 - INFO - allennlp.common.params - model_class = None\n",
      "2022-04-01 16:10:11,861 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-04-01 16:10:11,862 - INFO - allennlp.common.params - display_name = Neural Module Network (NMN)\n",
      "2022-04-01 16:10:11,863 - INFO - allennlp.common.params - task_id = rc\n",
      "2022-04-01 16:10:11,864 - INFO - allennlp.common.params - model_usage.archive_file = drop-nmn-2020.04.04.tar.gz\n",
      "2022-04-01 16:10:11,865 - INFO - allennlp.common.params - model_usage.training_config = None\n",
      "2022-04-01 16:10:11,866 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==1.0.0 allennlp-models==1.0.0\n",
      "2022-04-01 16:10:11,868 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-04-01 16:10:11,869 - INFO - allennlp.common.params - model_details.description = A neural module network trained on DROP.\n",
      "2022-04-01 16:10:11,870 - INFO - allennlp.common.params - model_details.short_description = A neural module network trained on DROP.\n",
      "2022-04-01 16:10:11,872 - INFO - allennlp.common.params - model_details.developed_by = Andreas et al\n",
      "2022-04-01 16:10:11,873 - INFO - allennlp.common.params - model_details.contributed_by = None\n",
      "2022-04-01 16:10:11,874 - INFO - allennlp.common.params - model_details.date = 2020-04-04\n",
      "2022-04-01 16:10:11,875 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-04-01 16:10:11,875 - INFO - allennlp.common.params - model_details.model_type = Neural Module Network\n",
      "2022-04-01 16:10:11,876 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@article{Andreas2016NeuralMN,\n",
      "title={Neural Module Networks},\n",
      "author={Jacob Andreas and Marcus Rohrbach and Trevor Darrell and D. Klein},\n",
      "journal={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},\n",
      "year={2016},\n",
      "pages={39-48}}\n",
      "\n",
      "2022-04-01 16:10:11,877 - INFO - allennlp.common.params - model_details.paper.title = Neural Module Networks\n",
      "2022-04-01 16:10:11,878 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:5276660\n",
      "2022-04-01 16:10:11,879 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-04-01 16:10:11,880 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-04-01 16:10:11,882 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-04-01 16:10:11,882 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-04-01 16:10:11,883 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-04-01 16:10:11,884 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-04-01 16:10:11,885 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-04-01 16:10:11,886 - INFO - allennlp.common.params - metrics.model_performance_measures = None\n",
      "2022-04-01 16:10:11,887 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-04-01 16:10:11,888 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-04-01 16:10:11,889 - INFO - allennlp.common.params - evaluation_data.dataset = None\n",
      "2022-04-01 16:10:11,890 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-04-01 16:10:11,891 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-04-01 16:10:11,897 - INFO - allennlp.common.params - training_data.dataset.name = DROP\n",
      "2022-04-01 16:10:11,898 - INFO - allennlp.common.params - training_data.dataset.url = https://allennlp.org/drop\n",
      "2022-04-01 16:10:11,899 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-04-01 16:10:11,901 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-04-01 16:10:11,902 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = None\n",
      "2022-04-01 16:10:11,904 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-04-01 16:10:11,906 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-04-01 16:10:11,907 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-04-01 16:10:11,958 - INFO - allennlp.common.params - id = roberta-sst\n",
      "2022-04-01 16:10:11,959 - INFO - allennlp.common.params - registered_model_name = None\n",
      "2022-04-01 16:10:11,960 - INFO - allennlp.common.params - model_class = None\n",
      "2022-04-01 16:10:11,960 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-04-01 16:10:11,961 - INFO - allennlp.common.params - display_name = RoBERTa large\n",
      "2022-04-01 16:10:11,961 - INFO - allennlp.common.params - task_id = sentiment-analysis\n",
      "2022-04-01 16:10:11,962 - INFO - allennlp.common.params - model_usage.archive_file = stanford-sentiment-treebank-roberta.2021-03-11.tar.gz\n",
      "2022-04-01 16:10:11,963 - INFO - allennlp.common.params - model_usage.training_config = classification/stanford_sentiment_treebank_roberta.jsonnet\n",
      "2022-04-01 16:10:11,963 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.4.0 allennlp-models==2.4.0\n",
      "2022-04-01 16:10:11,964 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-04-01 16:10:11,965 - INFO - allennlp.common.params - model_details.description = This model is trained on RoBERTa large with the binary classification setting of the Stanford Sentiment Treebank. It achieves 95.11% accuracy on the test set.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-01 16:10:11,966 - INFO - allennlp.common.params - model_details.short_description = RoBERTa-based binary classifier for Stanford Sentiment Treebank\n",
      "2022-04-01 16:10:11,967 - INFO - allennlp.common.params - model_details.developed_by = Devlin et al\n",
      "2022-04-01 16:10:11,968 - INFO - allennlp.common.params - model_details.contributed_by = Zhaofeng Wu\n",
      "2022-04-01 16:10:11,968 - INFO - allennlp.common.params - model_details.date = 2020-06-08\n",
      "2022-04-01 16:10:11,969 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-04-01 16:10:11,970 - INFO - allennlp.common.params - model_details.model_type = RoBERTa large\n",
      "2022-04-01 16:10:11,971 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@article{Liu2019RoBERTaAR,\n",
      "title={RoBERTa: A Robustly Optimized BERT Pretraining Approach},\n",
      "author={Y. Liu and Myle Ott and Naman Goyal and Jingfei Du and Mandar Joshi and Danqi Chen and Omer Levy and M. Lewis and Luke Zettlemoyer and Veselin Stoyanov},\n",
      "journal={ArXiv},\n",
      "year={2019},\n",
      "volume={abs/1907.11692}}\n",
      "\n",
      "2022-04-01 16:10:11,972 - INFO - allennlp.common.params - model_details.paper.title = RoBERTa: A Robustly Optimized BERT Pretraining Approach (Liu et al)\n",
      "2022-04-01 16:10:11,972 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:198953378\n",
      "2022-04-01 16:10:11,973 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-04-01 16:10:11,974 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-04-01 16:10:11,977 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-04-01 16:10:11,978 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-04-01 16:10:11,978 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-04-01 16:10:11,979 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-04-01 16:10:11,980 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-04-01 16:10:11,981 - INFO - allennlp.common.params - metrics.model_performance_measures = Accuracy\n",
      "2022-04-01 16:10:11,982 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-04-01 16:10:11,983 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-04-01 16:10:11,985 - INFO - allennlp.common.params - evaluation_data.dataset.name = Stanford Sentiment Treebank\n",
      "2022-04-01 16:10:11,985 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = https://allennlp.s3.amazonaws.com/datasets/sst/test.txt\n",
      "2022-04-01 16:10:11,986 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://nlp.stanford.edu/sentiment/treebank.html\n",
      "2022-04-01 16:10:11,987 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-04-01 16:10:11,988 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-04-01 16:10:11,989 - INFO - allennlp.common.params - training_data.dataset.name = Stanford Sentiment Treebank\n",
      "2022-04-01 16:10:11,990 - INFO - allennlp.common.params - training_data.dataset.processed_url = https://allennlp.s3.amazonaws.com/datasets/sst/train.txt\n",
      "2022-04-01 16:10:11,991 - INFO - allennlp.common.params - training_data.dataset.url = https://nlp.stanford.edu/sentiment/treebank.html\n",
      "2022-04-01 16:10:11,992 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-04-01 16:10:11,993 - INFO - allennlp.common.params - training_data.preprocessing = Binary classification setting\n",
      "2022-04-01 16:10:11,994 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = Accuracy: 95.11% on SST test set.\n",
      "2022-04-01 16:10:11,995 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-04-01 16:10:11,996 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-04-01 16:10:11,998 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-04-01 16:10:12,054 - INFO - allennlp.common.params - id = mc-roberta-commonsenseqa\n",
      "2022-04-01 16:10:12,054 - INFO - allennlp.common.params - registered_model_name = transformer_mc\n",
      "2022-04-01 16:10:12,055 - INFO - allennlp.common.params - model_class = None\n",
      "2022-04-01 16:10:12,056 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-04-01 16:10:12,057 - INFO - allennlp.common.params - display_name = RoBERTa Common Sense QA\n",
      "2022-04-01 16:10:12,058 - INFO - allennlp.common.params - task_id = mc\n",
      "2022-04-01 16:10:12,059 - INFO - allennlp.common.params - model_usage.archive_file = commonsenseqa.2020-07-08.tar.gz\n",
      "2022-04-01 16:10:12,060 - INFO - allennlp.common.params - model_usage.training_config = mc/commonsenseqa.jsonnet\n",
      "2022-04-01 16:10:12,061 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==1.0.0 allennlp-models==1.0.0\n",
      "2022-04-01 16:10:12,062 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-04-01 16:10:12,064 - INFO - allennlp.common.params - model_details.description = This is a multiple choice model patterned after the BERT architecture. It calculates a score for each sequence on top of the CLS token, and then chooses the alternative with the highest score.\n",
      "2022-04-01 16:10:12,065 - INFO - allennlp.common.params - model_details.short_description = RoBERTa-based multiple choice model for CommonSenseQA.\n",
      "2022-04-01 16:10:12,067 - INFO - allennlp.common.params - model_details.developed_by = Liu et al\n",
      "2022-04-01 16:10:12,068 - INFO - allennlp.common.params - model_details.contributed_by = Dirk Groeneveld\n",
      "2022-04-01 16:10:12,069 - INFO - allennlp.common.params - model_details.date = 2020-07-08\n",
      "2022-04-01 16:10:12,069 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-04-01 16:10:12,070 - INFO - allennlp.common.params - model_details.model_type = RoBERTa large\n",
      "2022-04-01 16:10:12,070 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@article{Liu2019RoBERTaAR,\n",
      "title={RoBERTa: A Robustly Optimized BERT Pretraining Approach},\n",
      "author={Y. Liu and Myle Ott and Naman Goyal and Jingfei Du and Mandar Joshi and Danqi Chen and Omer Levy and M. Lewis and Luke Zettlemoyer and Veselin Stoyanov},\n",
      "journal={ArXiv},\n",
      "year={2019},\n",
      "volume={abs/1907.11692}}\n",
      "\n",
      "2022-04-01 16:10:12,071 - INFO - allennlp.common.params - model_details.paper.title = RoBERTa: A Robustly Optimized BERT Pretraining Approach (Liu et al)\n",
      "2022-04-01 16:10:12,072 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:198953378\n",
      "2022-04-01 16:10:12,072 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-04-01 16:10:12,073 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-04-01 16:10:12,074 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-04-01 16:10:12,074 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-04-01 16:10:12,075 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-04-01 16:10:12,077 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-04-01 16:10:12,078 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-04-01 16:10:12,079 - INFO - allennlp.common.params - metrics.model_performance_measures = The chosen metric is accuracy, since it is a multiple choice model.\n",
      "2022-04-01 16:10:12,080 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-04-01 16:10:12,080 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-04-01 16:10:12,082 - INFO - allennlp.common.params - evaluation_data.dataset.name = CommonSenseQA (validation set)\n",
      "2022-04-01 16:10:12,082 - INFO - allennlp.common.params - evaluation_data.dataset.notes = Please download the data from the url provided.\n",
      "2022-04-01 16:10:12,083 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://github.com/jonathanherzig/commonsenseqa\n",
      "2022-04-01 16:10:12,084 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-04-01 16:10:12,084 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-04-01 16:10:12,085 - INFO - allennlp.common.params - training_data.dataset.name = CommonSenseQA (train set)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-01 16:10:12,086 - INFO - allennlp.common.params - training_data.dataset.notes = Please download the data from the url provided.\n",
      "2022-04-01 16:10:12,087 - INFO - allennlp.common.params - training_data.dataset.url = https://github.com/jonathanherzig/commonsenseqa\n",
      "2022-04-01 16:10:12,087 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-04-01 16:10:12,088 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-04-01 16:10:12,090 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = None\n",
      "2022-04-01 16:10:12,096 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-04-01 16:10:12,098 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-04-01 16:10:12,099 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-04-01 16:10:12,148 - INFO - allennlp.common.params - id = glove-sst\n",
      "2022-04-01 16:10:12,150 - INFO - allennlp.common.params - registered_model_name = None\n",
      "2022-04-01 16:10:12,152 - INFO - allennlp.common.params - model_class = None\n",
      "2022-04-01 16:10:12,152 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-04-01 16:10:12,153 - INFO - allennlp.common.params - display_name = GLoVe-LSTM\n",
      "2022-04-01 16:10:12,154 - INFO - allennlp.common.params - task_id = sentiment-analysis\n",
      "2022-04-01 16:10:12,155 - INFO - allennlp.common.params - model_usage.archive_file = basic_stanford_sentiment_treebank-2020.06.09.tar.gz\n",
      "2022-04-01 16:10:12,156 - INFO - allennlp.common.params - model_usage.training_config = classification/basic_stanford_sentiment_treebank.jsonnet\n",
      "2022-04-01 16:10:12,157 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
      "2022-04-01 16:10:12,158 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-04-01 16:10:12,159 - INFO - allennlp.common.params - model_details.description = This model uses GloVe embeddings and is trained on the binary classification setting of the Stanford Sentiment Treebank. It achieves about 87% on the test set.\n",
      "2022-04-01 16:10:12,160 - INFO - allennlp.common.params - model_details.short_description = LSTM binary classifier with GloVe embeddings.\n",
      "2022-04-01 16:10:12,161 - INFO - allennlp.common.params - model_details.developed_by = None\n",
      "2022-04-01 16:10:12,161 - INFO - allennlp.common.params - model_details.contributed_by = None\n",
      "2022-04-01 16:10:12,162 - INFO - allennlp.common.params - model_details.date = 2020-06-09\n",
      "2022-04-01 16:10:12,163 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-04-01 16:10:12,163 - INFO - allennlp.common.params - model_details.model_type = LSTM\n",
      "2022-04-01 16:10:12,164 - INFO - allennlp.common.params - model_details.paper = None\n",
      "2022-04-01 16:10:12,165 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-04-01 16:10:12,165 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-04-01 16:10:12,166 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-04-01 16:10:12,167 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-04-01 16:10:12,167 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-04-01 16:10:12,168 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-04-01 16:10:12,169 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-04-01 16:10:12,170 - INFO - allennlp.common.params - metrics.model_performance_measures = Accuracy\n",
      "2022-04-01 16:10:12,171 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-04-01 16:10:12,171 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-04-01 16:10:12,172 - INFO - allennlp.common.params - evaluation_data.dataset.name = Stanford Sentiment Treebank\n",
      "2022-04-01 16:10:12,173 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = https://allennlp.s3.amazonaws.com/datasets/sst/test.txt\n",
      "2022-04-01 16:10:12,173 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://nlp.stanford.edu/sentiment/treebank.html\n",
      "2022-04-01 16:10:12,174 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-04-01 16:10:12,175 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-04-01 16:10:12,176 - INFO - allennlp.common.params - training_data.dataset.name = Stanford Sentiment Treebank\n",
      "2022-04-01 16:10:12,177 - INFO - allennlp.common.params - training_data.dataset.processed_url = https://allennlp.s3.amazonaws.com/datasets/sst/train.txt\n",
      "2022-04-01 16:10:12,177 - INFO - allennlp.common.params - training_data.dataset.url = https://nlp.stanford.edu/sentiment/treebank.html\n",
      "2022-04-01 16:10:12,178 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-04-01 16:10:12,179 - INFO - allennlp.common.params - training_data.preprocessing = Binary classification setting\n",
      "2022-04-01 16:10:12,180 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = Accuracy: 87% on SST test set.\n",
      "2022-04-01 16:10:12,181 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-04-01 16:10:12,182 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-04-01 16:10:12,184 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-04-01 16:10:12,232 - INFO - allennlp.common.params - id = coref-spanbert\n",
      "2022-04-01 16:10:12,233 - INFO - allennlp.common.params - registered_model_name = coref\n",
      "2022-04-01 16:10:12,235 - INFO - allennlp.common.params - model_class = None\n",
      "2022-04-01 16:10:12,236 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-04-01 16:10:12,237 - INFO - allennlp.common.params - display_name = Coreference Resolution\n",
      "2022-04-01 16:10:12,237 - INFO - allennlp.common.params - task_id = coref\n",
      "2022-04-01 16:10:12,239 - INFO - allennlp.common.params - model_usage.archive_file = coref-spanbert-large-2021.03.10.tar.gz\n",
      "2022-04-01 16:10:12,240 - INFO - allennlp.common.params - model_usage.training_config = coref/coref_spanbert_large.jsonnet\n",
      "2022-04-01 16:10:12,241 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
      "2022-04-01 16:10:12,242 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-04-01 16:10:12,245 - INFO - allennlp.common.params - model_details.description = The basic outline of this model is to get an embedded representation of each span in the document. These span representations are scored  and used to prune away spans that are unlikely to occur in a coreference  cluster. For the remaining spans, the model decides which antecedent span (if any) they are coreferent with. The resulting coreference links, after applying transitivity, imply a clustering of the spans in the document. The GloVe embeddings in the original paper have been substituted with SpanBERT embeddings.\n",
      "2022-04-01 16:10:12,247 - INFO - allennlp.common.params - model_details.short_description = Higher-order coref with coarse-to-fine inference (with SpanBERT embeddings).\n",
      "2022-04-01 16:10:12,248 - INFO - allennlp.common.params - model_details.developed_by = Lee et al\n",
      "2022-04-01 16:10:12,249 - INFO - allennlp.common.params - model_details.contributed_by = Zhaofeng Wu\n",
      "2022-04-01 16:10:12,251 - INFO - allennlp.common.params - model_details.date = 2020-02-27\n",
      "2022-04-01 16:10:12,252 - INFO - allennlp.common.params - model_details.version = 2\n",
      "2022-04-01 16:10:12,253 - INFO - allennlp.common.params - model_details.model_type = SpanBERT\n",
      "2022-04-01 16:10:12,254 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@inproceedings{Lee2018HigherorderCR,\n",
      "title={Higher-order Coreference Resolution with Coarse-to-fine Inference},\n",
      "author={Kenton Lee and Luheng He and L. Zettlemoyer},\n",
      "booktitle={NAACL-HLT},\n",
      "year={2018}}\n",
      "\n",
      "2022-04-01 16:10:12,255 - INFO - allennlp.common.params - model_details.paper.title = Higher-order Coreference Resolution with Coarse-to-fine Inference\n",
      "2022-04-01 16:10:12,256 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:4891749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-01 16:10:12,256 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-04-01 16:10:12,259 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-04-01 16:10:12,261 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-04-01 16:10:12,263 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-04-01 16:10:12,264 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-04-01 16:10:12,265 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-04-01 16:10:12,267 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-04-01 16:10:12,268 - INFO - allennlp.common.params - metrics.model_performance_measures = CoNLL coref scores and Mention Recall\n",
      "2022-04-01 16:10:12,269 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-04-01 16:10:12,270 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-04-01 16:10:12,273 - INFO - allennlp.common.params - evaluation_data.dataset.name = Ontonotes 5.0\n",
      "2022-04-01 16:10:12,274 - INFO - allennlp.common.params - evaluation_data.dataset.notes = The Coreference model was evaluated on the CoNLL 2012 dataset. Unfortunately we cannot release this data due to licensing restrictions by the LDC. To compile the data in the right format for evaluating the Coreference model, please see scripts/compile_coref_data.sh. This script requires the Ontonotes 5.0 dataset, available on the LDC website.\n",
      "2022-04-01 16:10:12,274 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = /path/to/dataset\n",
      "2022-04-01 16:10:12,276 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://catalog.ldc.upenn.edu/LDC2013T19\n",
      "2022-04-01 16:10:12,277 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-04-01 16:10:12,279 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-04-01 16:10:12,280 - INFO - allennlp.common.params - training_data.dataset.name = Ontonotes 5.0\n",
      "2022-04-01 16:10:12,281 - INFO - allennlp.common.params - training_data.dataset.notes = The Coreference model was evaluated on the CoNLL 2012 dataset. Unfortunately we cannot release this data due to licensing restrictions by the LDC. To compile the data in the right format for evaluating the Coreference model, please see scripts/compile_coref_data.sh. This script requires the Ontonotes 5.0 dataset, available on the LDC website.\n",
      "2022-04-01 16:10:12,282 - INFO - allennlp.common.params - training_data.dataset.processed_url = /path/to/dataset\n",
      "2022-04-01 16:10:12,284 - INFO - allennlp.common.params - training_data.dataset.url = https://catalog.ldc.upenn.edu/LDC2013T19\n",
      "2022-04-01 16:10:12,285 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-04-01 16:10:12,286 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-04-01 16:10:12,288 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = None\n",
      "2022-04-01 16:10:12,289 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-04-01 16:10:12,290 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-04-01 16:10:12,293 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-04-01 16:10:12,341 - INFO - allennlp.common.params - id = nlvr2-vilbert\n",
      "2022-04-01 16:10:12,341 - INFO - allennlp.common.params - registered_model_name = nlvr2\n",
      "2022-04-01 16:10:12,342 - INFO - allennlp.common.params - model_class = None\n",
      "2022-04-01 16:10:12,343 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-04-01 16:10:12,345 - INFO - allennlp.common.params - display_name = Visual Entailment - NLVR2\n",
      "2022-04-01 16:10:12,346 - INFO - allennlp.common.params - task_id = nlvr2\n",
      "2022-04-01 16:10:12,347 - INFO - allennlp.common.params - model_usage.archive_file = vilbert-nlvr2-head-2021.06.01.tar.gz\n",
      "2022-04-01 16:10:12,348 - INFO - allennlp.common.params - model_usage.training_config = vilbert_nlvr2_pretrained.jsonnet\n",
      "2022-04-01 16:10:12,349 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp>=2.5.1 allennlp-models>=2.5.1\n",
      "2022-04-01 16:10:12,350 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-04-01 16:10:12,351 - INFO - allennlp.common.params - model_details.description = This model uses a VilBERT-based backbone with an NLVR2-specific model head. The image features are obtained using the ResNet backbone and Faster RCNN (region detection).\n",
      "2022-04-01 16:10:12,352 - INFO - allennlp.common.params - model_details.short_description = ViLBERT-based model for Visual Entailment.\n",
      "2022-04-01 16:10:12,352 - INFO - allennlp.common.params - model_details.developed_by = Lu et al\n",
      "2022-04-01 16:10:12,353 - INFO - allennlp.common.params - model_details.contributed_by = Jacob Morrison\n",
      "2022-04-01 16:10:12,354 - INFO - allennlp.common.params - model_details.date = 2021-05-27\n",
      "2022-04-01 16:10:12,356 - INFO - allennlp.common.params - model_details.version = 2\n",
      "2022-04-01 16:10:12,357 - INFO - allennlp.common.params - model_details.model_type = ViLBERT based on BERT large\n",
      "2022-04-01 16:10:12,358 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@inproceedings{Lu2019ViLBERTPT,\n",
      "title={ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks},\n",
      "author={Jiasen Lu and Dhruv Batra and D. Parikh and Stefan Lee},\n",
      "booktitle={NeurIPS},\n",
      "year={2019}\n",
      "2022-04-01 16:10:12,359 - INFO - allennlp.common.params - model_details.paper.title = ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks\n",
      "2022-04-01 16:10:12,360 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:199453025\n",
      "2022-04-01 16:10:12,365 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-04-01 16:10:12,366 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-04-01 16:10:12,368 - INFO - allennlp.common.params - intended_use.primary_uses = This model is developed for the AllenNLP demo.\n",
      "2022-04-01 16:10:12,369 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-04-01 16:10:12,371 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-04-01 16:10:12,373 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-04-01 16:10:12,374 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-04-01 16:10:12,375 - INFO - allennlp.common.params - metrics.model_performance_measures = Accuracy and F1-score\n",
      "2022-04-01 16:10:12,376 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-04-01 16:10:12,378 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-04-01 16:10:12,379 - INFO - allennlp.common.params - evaluation_data.dataset.name = Natural Language for Visual Reasoning For Real dev set\n",
      "2022-04-01 16:10:12,380 - INFO - allennlp.common.params - evaluation_data.dataset.notes = Evaluation requires a large amount of images to be accessible locally, so we cannot provide a command you can easily copy and paste.\n",
      "2022-04-01 16:10:12,381 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://github.com/lil-lab/nlvr/tree/master/nlvr2\n",
      "2022-04-01 16:10:12,383 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-04-01 16:10:12,386 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-04-01 16:10:12,388 - INFO - allennlp.common.params - training_data.dataset.name = Natural Language for Visual Reasoning For Real train set\n",
      "2022-04-01 16:10:12,389 - INFO - allennlp.common.params - training_data.dataset.url = https://github.com/lil-lab/nlvr/tree/master/nlvr2\n",
      "2022-04-01 16:10:12,390 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-04-01 16:10:12,392 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-04-01 16:10:12,394 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = On the validation set:\n",
      "F1: 33.7%\n",
      "Accuracy: 50.8%.\n",
      "These scores do not match the performance in the 12-in-1 paper because this was trained as a standalone task, not as part of a multitask setup. Please contact us if you want to match those scores!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-01 16:10:12,396 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-04-01 16:10:12,397 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-04-01 16:10:12,399 - INFO - allennlp.common.params - model_caveats_and_recommendations = None\n",
      "2022-04-01 16:10:12,446 - INFO - allennlp.common.params - id = tagging-elmo-crf-tagger\n",
      "2022-04-01 16:10:12,447 - INFO - allennlp.common.params - registered_model_name = crf_tagger\n",
      "2022-04-01 16:10:12,448 - INFO - allennlp.common.params - model_class = None\n",
      "2022-04-01 16:10:12,449 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-04-01 16:10:12,449 - INFO - allennlp.common.params - display_name = ELMo-based Named Entity Recognition\n",
      "2022-04-01 16:10:12,451 - INFO - allennlp.common.params - task_id = ner\n",
      "2022-04-01 16:10:12,452 - INFO - allennlp.common.params - model_usage.archive_file = ner-elmo.2021-02-12.tar.gz\n",
      "2022-04-01 16:10:12,452 - INFO - allennlp.common.params - model_usage.training_config = tagging/ner_elmo.jsonnet\n",
      "2022-04-01 16:10:12,453 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
      "2022-04-01 16:10:12,456 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-04-01 16:10:12,457 - INFO - allennlp.common.params - model_details.description = This model is the baseline model described in [Semi-supervised sequence tagging with bidirectional language models](https://api.semanticscholar.org/CorpusID:7197241). It uses a Gated Recurrent Unit (GRU) character encoder as well as a GRU phrase encoder, and it starts with pretrained GloVe vectors for its token embeddings. It was trained on the CoNLL-2003 NER dataset.\n",
      "2022-04-01 16:10:12,459 - INFO - allennlp.common.params - model_details.short_description = NER tagger using a Gated Recurrent Unit (GRU) character encoder as well as a GRU phrase encoder, with GloVe embeddings.\n",
      "2022-04-01 16:10:12,461 - INFO - allennlp.common.params - model_details.developed_by = Peters et al\n",
      "2022-04-01 16:10:12,463 - INFO - allennlp.common.params - model_details.contributed_by = None\n",
      "2022-04-01 16:10:12,464 - INFO - allennlp.common.params - model_details.date = 2020-02-10\n",
      "2022-04-01 16:10:12,465 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-04-01 16:10:12,466 - INFO - allennlp.common.params - model_details.model_type = Gated Recurrent Unit (GRU)\n",
      "2022-04-01 16:10:12,468 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@inproceedings{Peters2017SemisupervisedST,\n",
      "title={Semi-supervised sequence tagging with bidirectional language models},\n",
      "author={Matthew E. Peters and Waleed Ammar and Chandra Bhagavatula and R. Power},\n",
      "booktitle={ACL},\n",
      "year={2017}}\n",
      "\n",
      "2022-04-01 16:10:12,469 - INFO - allennlp.common.params - model_details.paper.title = Semi-supervised sequence tagging with bidirectional language models\n",
      "2022-04-01 16:10:12,470 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:7197241\n",
      "2022-04-01 16:10:12,471 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-04-01 16:10:12,471 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-04-01 16:10:12,473 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-04-01 16:10:12,474 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-04-01 16:10:12,476 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-04-01 16:10:12,478 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-04-01 16:10:12,479 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-04-01 16:10:12,480 - INFO - allennlp.common.params - metrics.model_performance_measures = Accuracy and Span-based F1 metric\n",
      "2022-04-01 16:10:12,481 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-04-01 16:10:12,482 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-04-01 16:10:12,485 - INFO - allennlp.common.params - evaluation_data.dataset.name = CoNLL-2003 NER dataset\n",
      "2022-04-01 16:10:12,485 - INFO - allennlp.common.params - evaluation_data.dataset.notes = The NER model was evaluated on the CoNLL-2003 NER dataset. Unfortunately we cannot release this data due to licensing restrictions.\n",
      "2022-04-01 16:10:12,486 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = path/to/dataset\n",
      "2022-04-01 16:10:12,487 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://www.clips.uantwerpen.be/conll2003/ner/\n",
      "2022-04-01 16:10:12,488 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-04-01 16:10:12,489 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-04-01 16:10:12,491 - INFO - allennlp.common.params - training_data.dataset.name = CoNLL-2003 NER dataset\n",
      "2022-04-01 16:10:12,492 - INFO - allennlp.common.params - training_data.dataset.notes = The NER model was trained on the CoNLL-2003 NER dataset. Unfortunately we cannot release this data due to licensing restrictions.\n",
      "2022-04-01 16:10:12,494 - INFO - allennlp.common.params - training_data.dataset.processed_url = /path/to/dataset\n",
      "2022-04-01 16:10:12,495 - INFO - allennlp.common.params - training_data.dataset.url = https://www.clips.uantwerpen.be/conll2003/ner/\n",
      "2022-04-01 16:10:12,496 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-04-01 16:10:12,496 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-04-01 16:10:12,498 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = Achieves 99% accuracy and 96% F1 on the CoNLL-2003 validation set.\n",
      "2022-04-01 16:10:12,499 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-04-01 16:10:12,501 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-04-01 16:10:12,502 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = This model is based on ELMo. ELMo is not deterministic, meaning that you will see slight differences every time you run it. Also, ELMo likes to be warmed up, so we recommend processing dummy input before processing real workloads with it.\n",
      "2022-04-01 16:10:12,548 - INFO - allennlp.common.params - id = semparse-text-to-sql\n",
      "2022-04-01 16:10:12,549 - INFO - allennlp.common.params - registered_model_name = None\n",
      "2022-04-01 16:10:12,550 - INFO - allennlp.common.params - model_class = None\n",
      "2022-04-01 16:10:12,551 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-04-01 16:10:12,552 - INFO - allennlp.common.params - display_name = Text to SQL (ATIS)\n",
      "2022-04-01 16:10:12,553 - INFO - allennlp.common.params - task_id = semparse-text-to-sql\n",
      "2022-04-01 16:10:12,553 - INFO - allennlp.common.params - model_usage.archive_file = https://allennlp.s3.amazonaws.com/models/atis-parser-2020.02.10.tar.gz\n",
      "2022-04-01 16:10:12,554 - INFO - allennlp.common.params - model_usage.training_config = None\n",
      "2022-04-01 16:10:12,555 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==1.0.0 allennlp-models==1.0.0\n",
      "2022-04-01 16:10:12,556 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-04-01 16:10:12,558 - INFO - allennlp.common.params - model_details.description = This model is an implementation of an encoder-decoder architecture with LSTMs and constrained type decoding trained on the ATIS dataset. This model is still a proof-of-concept of what you can do with semantic parsing in AllenNLP and its performance is not state-of-the-art (this naive model gets around 40% exact denotation accuracy on the contextual ATIS dataset).\n",
      "2022-04-01 16:10:12,560 - INFO - allennlp.common.params - model_details.short_description = This model is an implementation of an encoder-decoder architecture with LSTMs and constrained type decoding trained on the ATIS dataset.\n",
      "2022-04-01 16:10:12,561 - INFO - allennlp.common.params - model_details.developed_by = Dasigi et al\n",
      "2022-04-01 16:10:12,562 - INFO - allennlp.common.params - model_details.contributed_by = None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-01 16:10:12,563 - INFO - allennlp.common.params - model_details.date = 2020-02-10\n",
      "2022-04-01 16:10:12,563 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-04-01 16:10:12,564 - INFO - allennlp.common.params - model_details.model_type = None\n",
      "2022-04-01 16:10:12,565 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@inproceedings{Dasigi2019IterativeSF,\n",
      "title={Iterative Search for Weakly Supervised Semantic Parsing},\n",
      "author={Pradeep Dasigi and Matt Gardner and Shikhar Murty and Luke Zettlemoyer and E. Hovy},\n",
      "booktitle={NAACL-HLT},\n",
      "year={2019}}\n",
      "\n",
      "2022-04-01 16:10:12,566 - INFO - allennlp.common.params - model_details.paper.title = Iterative Search for Weakly Supervised Semantic Parsing\n",
      "2022-04-01 16:10:12,567 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:174799945\n",
      "2022-04-01 16:10:12,568 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-04-01 16:10:12,568 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-04-01 16:10:12,570 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-04-01 16:10:12,571 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-04-01 16:10:12,572 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-04-01 16:10:12,573 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-04-01 16:10:12,574 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-04-01 16:10:12,575 - INFO - allennlp.common.params - metrics.model_performance_measures = 1. `exact_match`; the percentage of the time that our best output action sequence matches the SQL query exactly.\n",
      "2. `denotation_acc`; the percentage of examples where we get the correct denotation.\n",
      "3. `valid_sql_query`; the percentage of time that decoding actually produces avalid SQL query.\n",
      "4. `action_similarity`; how similar the action sequence predicted is to the actual action sequence.\n",
      "2022-04-01 16:10:12,576 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-04-01 16:10:12,577 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-04-01 16:10:12,578 - INFO - allennlp.common.params - evaluation_data.dataset.name = ATIS\n",
      "2022-04-01 16:10:12,579 - INFO - allennlp.common.params - evaluation_data.dataset.notes = Please download the data from the url provided.\n",
      "2022-04-01 16:10:12,579 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://api.semanticscholar.org/CorpusID:1094063\n",
      "2022-04-01 16:10:12,580 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-04-01 16:10:12,581 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-04-01 16:10:12,583 - INFO - allennlp.common.params - training_data.dataset.name = ATIS\n",
      "2022-04-01 16:10:12,585 - INFO - allennlp.common.params - training_data.dataset.notes = Please download the data from the url provided.\n",
      "2022-04-01 16:10:12,586 - INFO - allennlp.common.params - training_data.dataset.url = https://api.semanticscholar.org/CorpusID:1094063\n",
      "2022-04-01 16:10:12,587 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-04-01 16:10:12,588 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-04-01 16:10:12,589 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = None\n",
      "2022-04-01 16:10:12,590 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-04-01 16:10:12,591 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-04-01 16:10:12,592 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-04-01 16:10:12,634 - INFO - allennlp.common.params - id = tagging-fine-grained-transformer-crf-tagger\n",
      "2022-04-01 16:10:12,635 - INFO - allennlp.common.params - registered_model_name = crf_tagger\n",
      "2022-04-01 16:10:12,635 - INFO - allennlp.common.params - model_class = None\n",
      "2022-04-01 16:10:12,636 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-04-01 16:10:12,637 - INFO - allennlp.common.params - display_name = Fine Grained Named Entity Recognition with Transformer\n",
      "2022-04-01 16:10:12,637 - INFO - allennlp.common.params - task_id = ner\n",
      "2022-04-01 16:10:12,638 - INFO - allennlp.common.params - model_usage.archive_file = fgner-transformer.2021-02-11.tar.gz\n",
      "2022-04-01 16:10:12,639 - INFO - allennlp.common.params - model_usage.training_config = tagging/fgner_transformer.jsonnet\n",
      "2022-04-01 16:10:12,639 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
      "2022-04-01 16:10:12,640 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-04-01 16:10:12,641 - INFO - allennlp.common.params - model_details.description = Fine-grained NER model\n",
      "2022-04-01 16:10:12,641 - INFO - allennlp.common.params - model_details.short_description = Fine-grained NER model\n",
      "2022-04-01 16:10:12,642 - INFO - allennlp.common.params - model_details.developed_by = None\n",
      "2022-04-01 16:10:12,642 - INFO - allennlp.common.params - model_details.contributed_by = None\n",
      "2022-04-01 16:10:12,643 - INFO - allennlp.common.params - model_details.date = 2020-07-14\n",
      "2022-04-01 16:10:12,644 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-04-01 16:10:12,644 - INFO - allennlp.common.params - model_details.model_type = Transformer\n",
      "2022-04-01 16:10:12,645 - INFO - allennlp.common.params - model_details.paper = None\n",
      "2022-04-01 16:10:12,646 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-04-01 16:10:12,647 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-04-01 16:10:12,649 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-04-01 16:10:12,650 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-04-01 16:10:12,651 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-04-01 16:10:12,652 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-04-01 16:10:12,657 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-04-01 16:10:12,658 - INFO - allennlp.common.params - metrics.model_performance_measures = Accuracy and Span-based F1 metric\n",
      "2022-04-01 16:10:12,659 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-04-01 16:10:12,660 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-04-01 16:10:12,661 - INFO - allennlp.common.params - evaluation_data.dataset.name = Ontonotes 5.0\n",
      "2022-04-01 16:10:12,662 - INFO - allennlp.common.params - evaluation_data.dataset.notes = Unfortunately we cannot release this data due to licensing restrictions.\n",
      "2022-04-01 16:10:12,663 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://catalog.ldc.upenn.edu/LDC2013T19\n",
      "2022-04-01 16:10:12,663 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-04-01 16:10:12,664 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-04-01 16:10:12,666 - INFO - allennlp.common.params - training_data.dataset.name = Ontonotes 5.0\n",
      "2022-04-01 16:10:12,667 - INFO - allennlp.common.params - training_data.dataset.notes = Unfortunately we cannot release this data due to licensing restrictions.\n",
      "2022-04-01 16:10:12,668 - INFO - allennlp.common.params - training_data.dataset.url = https://catalog.ldc.upenn.edu/LDC2013T19\n",
      "2022-04-01 16:10:12,669 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-04-01 16:10:12,670 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-04-01 16:10:12,672 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = On the validation set:\n",
      "Accuracy: 98%\n",
      "F1: 88%\n",
      "2022-04-01 16:10:12,673 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-04-01 16:10:12,674 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-04-01 16:10:12,675 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-01 16:10:12,724 - INFO - allennlp.common.params - id = nlvr2-vilbert\n",
      "2022-04-01 16:10:12,725 - INFO - allennlp.common.params - registered_model_name = nlvr2\n",
      "2022-04-01 16:10:12,726 - INFO - allennlp.common.params - model_class = None\n",
      "2022-04-01 16:10:12,727 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-04-01 16:10:12,728 - INFO - allennlp.common.params - display_name = Visual Entailment - NLVR2\n",
      "2022-04-01 16:10:12,728 - INFO - allennlp.common.params - task_id = nlvr2\n",
      "2022-04-01 16:10:12,729 - INFO - allennlp.common.params - model_usage.archive_file = vilbert-nlvr2-2021.06.01.tar.gz\n",
      "2022-04-01 16:10:12,730 - INFO - allennlp.common.params - model_usage.training_config = vilbert_nlvr2_pretrained.jsonnet\n",
      "2022-04-01 16:10:12,731 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp>=2.5.1 allennlp-models>=2.5.1\n",
      "2022-04-01 16:10:12,732 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-04-01 16:10:12,733 - INFO - allennlp.common.params - model_details.description = This model is based on the ViLBERT multitask architecture. The image features are obtained using the ResNet backbone and Faster RCNN (region detection).\n",
      "2022-04-01 16:10:12,734 - INFO - allennlp.common.params - model_details.short_description = ViLBERT-based model for Visual Entailment.\n",
      "2022-04-01 16:10:12,736 - INFO - allennlp.common.params - model_details.developed_by = Lu et al\n",
      "2022-04-01 16:10:12,740 - INFO - allennlp.common.params - model_details.contributed_by = Jacob Morrison\n",
      "2022-04-01 16:10:12,741 - INFO - allennlp.common.params - model_details.date = 2021-05-27\n",
      "2022-04-01 16:10:12,742 - INFO - allennlp.common.params - model_details.version = 2\n",
      "2022-04-01 16:10:12,743 - INFO - allennlp.common.params - model_details.model_type = ViLBERT based on BERT large\n",
      "2022-04-01 16:10:12,744 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@inproceedings{Lu2019ViLBERTPT,\n",
      "title={ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks},\n",
      "author={Jiasen Lu and Dhruv Batra and D. Parikh and Stefan Lee},\n",
      "booktitle={NeurIPS},\n",
      "year={2019}\n",
      "2022-04-01 16:10:12,745 - INFO - allennlp.common.params - model_details.paper.title = ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks\n",
      "2022-04-01 16:10:12,746 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:199453025\n",
      "2022-04-01 16:10:12,747 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-04-01 16:10:12,747 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-04-01 16:10:12,749 - INFO - allennlp.common.params - intended_use.primary_uses = This model is developed for the AllenNLP demo.\n",
      "2022-04-01 16:10:12,750 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-04-01 16:10:12,751 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-04-01 16:10:12,752 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-04-01 16:10:12,754 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-04-01 16:10:12,756 - INFO - allennlp.common.params - metrics.model_performance_measures = Accuracy and F1-score\n",
      "2022-04-01 16:10:12,758 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-04-01 16:10:12,759 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-04-01 16:10:12,760 - INFO - allennlp.common.params - evaluation_data.dataset.name = Natural Language for Visual Reasoning For Real dev set\n",
      "2022-04-01 16:10:12,761 - INFO - allennlp.common.params - evaluation_data.dataset.notes = Evaluation requires a large amount of images to be accessible locally, so we cannot provide a command you can easily copy and paste.\n",
      "2022-04-01 16:10:12,762 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://github.com/lil-lab/nlvr/tree/master/nlvr2\n",
      "2022-04-01 16:10:12,762 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-04-01 16:10:12,763 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-04-01 16:10:12,765 - INFO - allennlp.common.params - training_data.dataset.name = Natural Language for Visual Reasoning For Real train set\n",
      "2022-04-01 16:10:12,766 - INFO - allennlp.common.params - training_data.dataset.url = https://github.com/lil-lab/nlvr/tree/master/nlvr2\n",
      "2022-04-01 16:10:12,767 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-04-01 16:10:12,768 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-04-01 16:10:12,769 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = On the validation set:\n",
      "F1: 33.7%\n",
      "Accuracy: 50.8%.\n",
      "These scores do not match the performance in the 12-in-1 paper because this was trained as a standalone task, not as part of a multitask setup. Please contact us if you want to match those scores!\n",
      "2022-04-01 16:10:12,770 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-04-01 16:10:12,770 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-04-01 16:10:12,771 - INFO - allennlp.common.params - model_caveats_and_recommendations = None\n",
      "2022-04-01 16:10:12,817 - INFO - allennlp.common.params - id = pair-classification-roberta-snli\n",
      "2022-04-01 16:10:12,818 - INFO - allennlp.common.params - registered_model_name = basic_classifier\n",
      "2022-04-01 16:10:12,818 - INFO - allennlp.common.params - model_class = None\n",
      "2022-04-01 16:10:12,818 - INFO - allennlp.common.params - registered_predictor_name = textual_entailment\n",
      "2022-04-01 16:10:12,818 - INFO - allennlp.common.params - display_name = RoBERTa SNLI\n",
      "2022-04-01 16:10:12,819 - INFO - allennlp.common.params - task_id = textual_entailment\n",
      "2022-04-01 16:10:12,819 - INFO - allennlp.common.params - model_usage.archive_file = snli-roberta.2021-03-11.tar.gz\n",
      "2022-04-01 16:10:12,819 - INFO - allennlp.common.params - model_usage.training_config = pair_classification/snli_roberta.jsonnet\n",
      "2022-04-01 16:10:12,820 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
      "2022-04-01 16:10:12,820 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-04-01 16:10:12,821 - INFO - allennlp.common.params - model_details.description = This `Model` implements a basic text classifier. The text is embedded into a text field using a RoBERTa-large model. The resulting sequence is pooled using a cls_pooler `Seq2VecEncoder` and then passed to a linear classification layer, which projects into the label space.\n",
      "2022-04-01 16:10:12,822 - INFO - allennlp.common.params - model_details.short_description = RoBERTa finetuned on SNLI.\n",
      "2022-04-01 16:10:12,822 - INFO - allennlp.common.params - model_details.developed_by = Liu et al\n",
      "2022-04-01 16:10:12,822 - INFO - allennlp.common.params - model_details.contributed_by = Dirk Groeneveld\n",
      "2022-04-01 16:10:12,822 - INFO - allennlp.common.params - model_details.date = 2020-07-29\n",
      "2022-04-01 16:10:12,823 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-04-01 16:10:12,823 - INFO - allennlp.common.params - model_details.model_type = RoBERTa\n",
      "2022-04-01 16:10:12,824 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@article{Liu2019RoBERTaAR,\n",
      "title={RoBERTa: A Robustly Optimized BERT Pretraining Approach},\n",
      "author={Y. Liu and Myle Ott and Naman Goyal and Jingfei Du and Mandar Joshi and Danqi Chen and Omer Levy and M. Lewis and Luke Zettlemoyer and Veselin Stoyanov},\n",
      "journal={ArXiv},\n",
      "year={2019},\n",
      "volume={abs/1907.11692}}\n",
      "\n",
      "2022-04-01 16:10:12,825 - INFO - allennlp.common.params - model_details.paper.title = RoBERTa: A Robustly Optimized BERT Pretraining Approach (Liu et al)\n",
      "2022-04-01 16:10:12,826 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:198953378\n",
      "2022-04-01 16:10:12,826 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-04-01 16:10:12,826 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-04-01 16:10:12,827 - INFO - allennlp.common.params - intended_use.primary_uses = None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-01 16:10:12,827 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-04-01 16:10:12,827 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-04-01 16:10:12,828 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-04-01 16:10:12,828 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-04-01 16:10:12,828 - INFO - allennlp.common.params - metrics.model_performance_measures = Accuracy\n",
      "2022-04-01 16:10:12,829 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-04-01 16:10:12,829 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-04-01 16:10:12,829 - INFO - allennlp.common.params - evaluation_data.dataset.name = Stanford Natural Language Inference (SNLI) dev set\n",
      "2022-04-01 16:10:12,830 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = https://allennlp.s3.amazonaws.com/datasets/snli/snli_1.0_test.jsonl\n",
      "2022-04-01 16:10:12,830 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://nlp.stanford.edu/projects/snli/\n",
      "2022-04-01 16:10:12,830 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-04-01 16:10:12,830 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-04-01 16:10:12,831 - INFO - allennlp.common.params - training_data.dataset.name = Stanford Natural Language Inference (SNLI) train set\n",
      "2022-04-01 16:10:12,831 - INFO - allennlp.common.params - training_data.dataset.processed_url = https://allennlp.s3.amazonaws.com/datasets/snli/snli_1.0_train.jsonl\n",
      "2022-04-01 16:10:12,832 - INFO - allennlp.common.params - training_data.dataset.url = https://nlp.stanford.edu/projects/snli/\n",
      "2022-04-01 16:10:12,832 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-04-01 16:10:12,833 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-04-01 16:10:12,834 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = Net Neutral: 0.49562665820121765, Fraction Neutral: 0.5068705677986145, Threshold:0.5: 0.47600528597831726, Threshold:0.7: 0.3036800026893616\n",
      "2022-04-01 16:10:12,834 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-04-01 16:10:12,835 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-04-01 16:10:12,835 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-04-01 16:10:12,880 - INFO - allennlp.common.params - id = semparse-wikitables\n",
      "2022-04-01 16:10:12,881 - INFO - allennlp.common.params - registered_model_name = None\n",
      "2022-04-01 16:10:12,882 - INFO - allennlp.common.params - model_class = None\n",
      "2022-04-01 16:10:12,882 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-04-01 16:10:12,883 - INFO - allennlp.common.params - display_name = WikiTables Semantic Parsing\n",
      "2022-04-01 16:10:12,884 - INFO - allennlp.common.params - task_id = semparse-tabular\n",
      "2022-04-01 16:10:12,885 - INFO - allennlp.common.params - model_usage.archive_file = wikitables-model-2020.02.10.tar.gz\n",
      "2022-04-01 16:10:12,885 - INFO - allennlp.common.params - model_usage.training_config = None\n",
      "2022-04-01 16:10:12,886 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==1.0.0 allennlp-models==1.0.0\n",
      "2022-04-01 16:10:12,886 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-04-01 16:10:12,888 - INFO - allennlp.common.params - model_details.description = The model is a semantic parser trained on WikiTableQuestions.\n",
      "2022-04-01 16:10:12,889 - INFO - allennlp.common.params - model_details.short_description = The model is a semantic parser trained on WikiTableQuestions.\n",
      "2022-04-01 16:10:12,891 - INFO - allennlp.common.params - model_details.developed_by = Dasigi et al\n",
      "2022-04-01 16:10:12,892 - INFO - allennlp.common.params - model_details.contributed_by = None\n",
      "2022-04-01 16:10:12,894 - INFO - allennlp.common.params - model_details.date = 2020-02-10\n",
      "2022-04-01 16:10:12,895 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-04-01 16:10:12,895 - INFO - allennlp.common.params - model_details.model_type = None\n",
      "2022-04-01 16:10:12,896 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@inproceedings{Dasigi2019IterativeSF,\n",
      "title={Iterative Search for Weakly Supervised Semantic Parsing},\n",
      "author={Pradeep Dasigi and Matt Gardner and Shikhar Murty and Luke Zettlemoyer and E. Hovy},\n",
      "booktitle={NAACL-HLT},\n",
      "year={2019}}\n",
      "\n",
      "2022-04-01 16:10:12,897 - INFO - allennlp.common.params - model_details.paper.title = Iterative Search for Weakly Supervised Semantic Parsing\n",
      "2022-04-01 16:10:12,898 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:174799945\n",
      "2022-04-01 16:10:12,899 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-04-01 16:10:12,900 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-04-01 16:10:12,904 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-04-01 16:10:12,905 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-04-01 16:10:12,906 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-04-01 16:10:12,907 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-04-01 16:10:12,909 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-04-01 16:10:12,911 - INFO - allennlp.common.params - metrics.model_performance_measures = 1. `lf_retrieval_acc`; the percentage of the time that our best output action sequence is in the set of action sequences provided by offline search.\n",
      "2. `denotation_acc`; the percentage of examples where we get the correct denotation.\n",
      "3. `lf_percent`; the percentage of time that decoding actually produces a finished logical form\n",
      "2022-04-01 16:10:12,912 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-04-01 16:10:12,913 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-04-01 16:10:12,914 - INFO - allennlp.common.params - evaluation_data.dataset.name = WikiTableQuestions\n",
      "2022-04-01 16:10:12,915 - INFO - allennlp.common.params - evaluation_data.dataset.notes = Please download the data from the url provided.\n",
      "2022-04-01 16:10:12,915 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://ppasupat.github.io/WikiTableQuestions/\n",
      "2022-04-01 16:10:12,917 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-04-01 16:10:12,918 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-04-01 16:10:12,919 - INFO - allennlp.common.params - training_data.dataset.name = WikiTableQuestions\n",
      "2022-04-01 16:10:12,922 - INFO - allennlp.common.params - training_data.dataset.notes = Please download the data from the url provided.\n",
      "2022-04-01 16:10:12,923 - INFO - allennlp.common.params - training_data.dataset.url = https://ppasupat.github.io/WikiTableQuestions/\n",
      "2022-04-01 16:10:12,924 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-04-01 16:10:12,925 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-04-01 16:10:12,926 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = None\n",
      "2022-04-01 16:10:12,927 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-04-01 16:10:12,928 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-04-01 16:10:12,930 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-04-01 16:10:12,966 - INFO - allennlp.common.params - id = structured-prediction-srl-bert\n",
      "2022-04-01 16:10:12,967 - INFO - allennlp.common.params - registered_model_name = srl_bert\n",
      "2022-04-01 16:10:12,968 - INFO - allennlp.common.params - model_class = None\n",
      "2022-04-01 16:10:12,969 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-04-01 16:10:12,969 - INFO - allennlp.common.params - display_name = SRL BERT\n",
      "2022-04-01 16:10:12,970 - INFO - allennlp.common.params - task_id = srl\n",
      "2022-04-01 16:10:12,972 - INFO - allennlp.common.params - model_usage.archive_file = structured-prediction-srl-bert.2020.12.15.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-01 16:10:12,974 - INFO - allennlp.common.params - model_usage.training_config = structured_prediction/bert_base_srl.jsonnet\n",
      "2022-04-01 16:10:12,975 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
      "2022-04-01 16:10:12,976 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-04-01 16:10:12,977 - INFO - allennlp.common.params - model_details.description = An implementation of a BERT based model (Shi et al, 2019) with some modifications (no additional parameters apart from a linear classification layer), which is currently the state of the art single model for English PropBank SRL (Newswire sentences). It achieves 86.49 test F1 on the Ontonotes 5.0 dataset.\n",
      "2022-04-01 16:10:12,978 - INFO - allennlp.common.params - model_details.short_description = A BERT based model (Shi et al, 2019) with some modifications (no additional parameters apart from a linear classification layer)\n",
      "2022-04-01 16:10:12,980 - INFO - allennlp.common.params - model_details.developed_by = Shi et al\n",
      "2022-04-01 16:10:12,981 - INFO - allennlp.common.params - model_details.contributed_by = None\n",
      "2022-04-01 16:10:12,982 - INFO - allennlp.common.params - model_details.date = 2020-09-03\n",
      "2022-04-01 16:10:12,983 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-04-01 16:10:12,984 - INFO - allennlp.common.params - model_details.model_type = BERT\n",
      "2022-04-01 16:10:12,985 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@article{Shi2019SimpleBM,\n",
      "title={Simple BERT Models for Relation Extraction and Semantic Role Labeling},\n",
      "author={Peng Shi and Jimmy Lin},\n",
      "journal={ArXiv},\n",
      "year={2019},\n",
      "volume={abs/1904.05255}}\n",
      "\n",
      "2022-04-01 16:10:12,986 - INFO - allennlp.common.params - model_details.paper.title = Simple BERT Models for Relation Extraction and Semantic Role Labeling\n",
      "2022-04-01 16:10:12,986 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:131773936\n",
      "2022-04-01 16:10:12,987 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-04-01 16:10:12,988 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-04-01 16:10:12,990 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-04-01 16:10:12,991 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-04-01 16:10:12,992 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-04-01 16:10:12,994 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-04-01 16:10:12,995 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-04-01 16:10:12,996 - INFO - allennlp.common.params - metrics.model_performance_measures = Precision, recall and F1-score\n",
      "2022-04-01 16:10:12,996 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-04-01 16:10:12,997 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-04-01 16:10:12,998 - INFO - allennlp.common.params - evaluation_data.dataset.name = Ontonotes 5.0\n",
      "2022-04-01 16:10:13,000 - INFO - allennlp.common.params - evaluation_data.dataset.notes = We cannot release this data due to licensing restrictions.\n",
      "2022-04-01 16:10:13,001 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://catalog.ldc.upenn.edu/LDC2013T19\n",
      "2022-04-01 16:10:13,001 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-04-01 16:10:13,002 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-04-01 16:10:13,003 - INFO - allennlp.common.params - training_data.dataset.name = Ontonotes 5.0\n",
      "2022-04-01 16:10:13,003 - INFO - allennlp.common.params - training_data.dataset.notes = We cannot release this data due to licensing restrictions.\n",
      "2022-04-01 16:10:13,004 - INFO - allennlp.common.params - training_data.dataset.url = https://catalog.ldc.upenn.edu/LDC2013T19\n",
      "2022-04-01 16:10:13,005 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-04-01 16:10:13,006 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-04-01 16:10:13,007 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = 86.49 test F1 on the Ontonotes 5.0 dataset\n",
      "2022-04-01 16:10:13,009 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-04-01 16:10:13,011 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-04-01 16:10:13,012 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-04-01 16:10:13,061 - INFO - allennlp.common.params - id = structured-prediction-srl\n",
      "2022-04-01 16:10:13,061 - INFO - allennlp.common.params - registered_model_name = srl\n",
      "2022-04-01 16:10:13,062 - INFO - allennlp.common.params - model_class = None\n",
      "2022-04-01 16:10:13,062 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-04-01 16:10:13,063 - INFO - allennlp.common.params - display_name = Open Information Extraction\n",
      "2022-04-01 16:10:13,063 - INFO - allennlp.common.params - task_id = srl\n",
      "2022-04-01 16:10:13,065 - INFO - allennlp.common.params - model_usage.archive_file = openie-model.2020.03.26.tar.gz\n",
      "2022-04-01 16:10:13,065 - INFO - allennlp.common.params - model_usage.training_config = structured-prediction/srl.jsonnet\n",
      "2022-04-01 16:10:13,066 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
      "2022-04-01 16:10:13,067 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-04-01 16:10:13,068 - INFO - allennlp.common.params - model_details.description = A reimplementation of a deep BiLSTM sequence prediction model (Stanovsky et al., 2018).\n",
      "2022-04-01 16:10:13,069 - INFO - allennlp.common.params - model_details.short_description = A reimplementation of a deep BiLSTM sequence prediction model (Stanovsky et al., 2018)\n",
      "2022-04-01 16:10:13,069 - INFO - allennlp.common.params - model_details.developed_by = Stanovsky et al\n",
      "2022-04-01 16:10:13,070 - INFO - allennlp.common.params - model_details.contributed_by = None\n",
      "2022-04-01 16:10:13,071 - INFO - allennlp.common.params - model_details.date = 2020-03-26\n",
      "2022-04-01 16:10:13,071 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-04-01 16:10:13,072 - INFO - allennlp.common.params - model_details.model_type = BiLSTM\n",
      "2022-04-01 16:10:13,073 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@inproceedings{Stanovsky2018SupervisedOI,\n",
      "title={Supervised Open Information Extraction},\n",
      "author={Gabriel Stanovsky and Julian Michael and Luke Zettlemoyer and I. Dagan},\n",
      "booktitle={NAACL-HLT},\n",
      "year={2018}}\n",
      "\n",
      "2022-04-01 16:10:13,074 - INFO - allennlp.common.params - model_details.paper.title = Supervised Open Information Extraction\n",
      "2022-04-01 16:10:13,075 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:44145304\n",
      "2022-04-01 16:10:13,076 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-04-01 16:10:13,077 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-04-01 16:10:13,079 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-04-01 16:10:13,080 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-04-01 16:10:13,087 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-04-01 16:10:13,089 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-04-01 16:10:13,091 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-04-01 16:10:13,092 - INFO - allennlp.common.params - metrics.model_performance_measures = CoNLL SRL metrics\n",
      "2022-04-01 16:10:13,093 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-04-01 16:10:13,094 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-04-01 16:10:13,095 - INFO - allennlp.common.params - evaluation_data.dataset.name = OIE2016, WEB and NYT, PENN\n",
      "2022-04-01 16:10:13,096 - INFO - allennlp.common.params - evaluation_data.dataset.notes = The Open Information extractor was evaluated on the OIE2016 corpus. Unfortunately we cannot release this data due to licensing restrictions by the LDC. You can get the data on the corpus homepage.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-01 16:10:13,097 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://github.com/gabrielStanovsky/oie-benchmark\n",
      "2022-04-01 16:10:13,098 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-04-01 16:10:13,099 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-04-01 16:10:13,101 - INFO - allennlp.common.params - training_data.dataset.name = All Words Open IE\n",
      "2022-04-01 16:10:13,102 - INFO - allennlp.common.params - training_data.dataset.url = https://github.com/gabrielStanovsky/supervised-oie/tree/master/data\n",
      "2022-04-01 16:10:13,102 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-04-01 16:10:13,103 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-04-01 16:10:13,104 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = None\n",
      "2022-04-01 16:10:13,105 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-04-01 16:10:13,106 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-04-01 16:10:13,109 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-04-01 16:10:13,152 - INFO - allennlp.common.params - id = ve-vilbert\n",
      "2022-04-01 16:10:13,153 - INFO - allennlp.common.params - registered_model_name = ve_vilbert\n",
      "2022-04-01 16:10:13,154 - INFO - allennlp.common.params - model_class = None\n",
      "2022-04-01 16:10:13,155 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-04-01 16:10:13,156 - INFO - allennlp.common.params - display_name = Visual Entailment\n",
      "2022-04-01 16:10:13,157 - INFO - allennlp.common.params - task_id = ve\n",
      "2022-04-01 16:10:13,158 - INFO - allennlp.common.params - model_usage.archive_file = visual-entailment-torchvision-2021.03.04.tar.gz\n",
      "2022-04-01 16:10:13,159 - INFO - allennlp.common.params - model_usage.training_config = vilbert_ve_pretrained.jsonnet\n",
      "2022-04-01 16:10:13,160 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==1.0.0 allennlp-models==1.0.0\n",
      "2022-04-01 16:10:13,160 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-04-01 16:10:13,161 - INFO - allennlp.common.params - model_details.description = This model is based on the ViLBERT architecture. The image features are obtained using the ResNet backbone and Faster RCNN (region detection).\n",
      "2022-04-01 16:10:13,162 - INFO - allennlp.common.params - model_details.short_description = ViLBERT-based model for Visual Entailment.\n",
      "2022-04-01 16:10:13,162 - INFO - allennlp.common.params - model_details.developed_by = Lu et al\n",
      "2022-04-01 16:10:13,163 - INFO - allennlp.common.params - model_details.contributed_by = Akshita Bhagia\n",
      "2022-04-01 16:10:13,164 - INFO - allennlp.common.params - model_details.date = 2021-03-04\n",
      "2022-04-01 16:10:13,164 - INFO - allennlp.common.params - model_details.version = 2\n",
      "2022-04-01 16:10:13,165 - INFO - allennlp.common.params - model_details.model_type = ViLBERT based on BERT large\n",
      "2022-04-01 16:10:13,166 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@inproceedings{Lu2019ViLBERTPT,\n",
      "title={ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks},\n",
      "author={Jiasen Lu and Dhruv Batra and D. Parikh and Stefan Lee},\n",
      "booktitle={NeurIPS},\n",
      "year={2019}\n",
      "2022-04-01 16:10:13,167 - INFO - allennlp.common.params - model_details.paper.title = ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks\n",
      "2022-04-01 16:10:13,167 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:199453025\n",
      "2022-04-01 16:10:13,168 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-04-01 16:10:13,168 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-04-01 16:10:13,169 - INFO - allennlp.common.params - intended_use.primary_uses = This model is developed for the AllenNLP demo.\n",
      "2022-04-01 16:10:13,170 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-04-01 16:10:13,170 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-04-01 16:10:13,172 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-04-01 16:10:13,173 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-04-01 16:10:13,175 - INFO - allennlp.common.params - metrics.model_performance_measures = Accuracy and F1-score\n",
      "2022-04-01 16:10:13,179 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-04-01 16:10:13,180 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-04-01 16:10:13,182 - INFO - allennlp.common.params - evaluation_data.dataset.name = Stanford Natural Language Inference - Visual Entailment(SNLI-VE) dev set\n",
      "2022-04-01 16:10:13,183 - INFO - allennlp.common.params - evaluation_data.dataset.notes = Evaluation requires a large amount of images to be accessible locally, so we cannot provide a command you can easily copy and paste.\n",
      "2022-04-01 16:10:13,185 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://github.com/necla-ml/SNLI-VE\n",
      "2022-04-01 16:10:13,185 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-04-01 16:10:13,186 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-04-01 16:10:13,188 - INFO - allennlp.common.params - training_data.dataset.name = Stanford Natural Language Inference - Visual Entailment(SNLI-VE) train set\n",
      "2022-04-01 16:10:13,188 - INFO - allennlp.common.params - training_data.dataset.url = https://github.com/necla-ml/SNLI-VE\n",
      "2022-04-01 16:10:13,189 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-04-01 16:10:13,191 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-04-01 16:10:13,193 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = None\n",
      "2022-04-01 16:10:13,194 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-04-01 16:10:13,195 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-04-01 16:10:13,196 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = This model is trained on the original SNLI-VE dataset. [Subsequent work](https://api.semanticscholar.org/CorpusID:215415945) has found that an estimated 31% of `neutral` labels in the dataset are incorrect. The `e-SNLI-VE-2.0` dataset contains the re-annotated validation and test sets.\n",
      "2022-04-01 16:10:13,245 - INFO - allennlp.common.params - id = vgqa-vilbert\n",
      "2022-04-01 16:10:13,245 - INFO - allennlp.common.params - registered_model_name = vqa_vilbert_from_huggingface\n",
      "2022-04-01 16:10:13,246 - INFO - allennlp.common.params - model_class = None\n",
      "2022-04-01 16:10:13,246 - INFO - allennlp.common.params - registered_predictor_name = vgqa_vilbert\n",
      "2022-04-01 16:10:13,246 - INFO - allennlp.common.params - display_name = ViLBERT - Visual Genome Question Answering\n",
      "2022-04-01 16:10:13,246 - INFO - allennlp.common.params - task_id = vgqa\n",
      "2022-04-01 16:10:13,247 - INFO - allennlp.common.params - model_usage.archive_file = vilbert-vgqa-pretrained.2021-05-10.tar.gz\n",
      "2022-04-01 16:10:13,247 - INFO - allennlp.common.params - model_usage.training_config = vision/vilbert_vgqa_pretrained.jsonnet\n",
      "2022-04-01 16:10:13,247 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.5.0 allennlp-models==2.5.0\n",
      "2022-04-01 16:10:13,247 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-04-01 16:10:13,248 - INFO - allennlp.common.params - model_details.description = ViLBERT (short for Vision-and-Language BERT), is a model for learning task-agnostic joint representations of image content and natural language.\n",
      "2022-04-01 16:10:13,249 - INFO - allennlp.common.params - model_details.short_description = ViLBERT (short for Vision-and-Language BERT), is a model for learning task-agnostic joint representations of image content and natural language.\n",
      "2022-04-01 16:10:13,249 - INFO - allennlp.common.params - model_details.developed_by = Lu et al\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-01 16:10:13,250 - INFO - allennlp.common.params - model_details.contributed_by = Jacob Morrison\n",
      "2022-04-01 16:10:13,251 - INFO - allennlp.common.params - model_details.date = 2021-05-07\n",
      "2022-04-01 16:10:13,251 - INFO - allennlp.common.params - model_details.version = 2\n",
      "2022-04-01 16:10:13,251 - INFO - allennlp.common.params - model_details.model_type = ViLBERT based on BERT large\n",
      "2022-04-01 16:10:13,251 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@inproceedings{Lu2019ViLBERTPT,\n",
      "title={ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks},\n",
      "author={Jiasen Lu and Dhruv Batra and D. Parikh and Stefan Lee},\n",
      "booktitle={NeurIPS},\n",
      "year={2019}\n",
      "}\n",
      "2022-04-01 16:10:13,251 - INFO - allennlp.common.params - model_details.paper.title = ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks\n",
      "2022-04-01 16:10:13,252 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:199453025\n",
      "2022-04-01 16:10:13,252 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-04-01 16:10:13,252 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-04-01 16:10:13,253 - INFO - allennlp.common.params - intended_use.primary_uses = This model is developed for the AllenNLP demo.\n",
      "2022-04-01 16:10:13,254 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-04-01 16:10:13,255 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-04-01 16:10:13,255 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-04-01 16:10:13,255 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-04-01 16:10:13,256 - INFO - allennlp.common.params - metrics.model_performance_measures = F1-metric and VQA score\n",
      "2022-04-01 16:10:13,257 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-04-01 16:10:13,259 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-04-01 16:10:13,261 - INFO - allennlp.common.params - evaluation_data.dataset.name = VGQA dataset\n",
      "2022-04-01 16:10:13,262 - INFO - allennlp.common.params - evaluation_data.dataset.notes = Evaluation requires a large amount of images to be accessible locally, so we cannot provide a command you can easily copy and paste. The first time you run it, you will get an error message that tells you how to get the rest of the data.\n",
      "2022-04-01 16:10:13,262 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = https://visualgenome.org/static/data/dataset/question_answers.json.zip!question_answers.json[:5000]\n",
      "2022-04-01 16:10:13,263 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://visualgenome.org/\n",
      "2022-04-01 16:10:13,264 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-04-01 16:10:13,266 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-04-01 16:10:13,268 - INFO - allennlp.common.params - training_data.dataset.name = VGQA dataset\n",
      "2022-04-01 16:10:13,268 - INFO - allennlp.common.params - training_data.dataset.notes = Training requires a large amount of images to be accessible locally, so we cannot provide a command you can easily copy and paste. The first time you run it, you will get an error message that tells you how to get the rest of the data.\n",
      "2022-04-01 16:10:13,269 - INFO - allennlp.common.params - training_data.dataset.processed_url = https://visualgenome.org/static/data/dataset/question_answers.json.zip!question_answers.json[5000:]\n",
      "2022-04-01 16:10:13,269 - INFO - allennlp.common.params - training_data.dataset.url = https://visualgenome.org/\n",
      "2022-04-01 16:10:13,271 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-04-01 16:10:13,272 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-04-01 16:10:13,273 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = On the validation set:\n",
      "F1: 29.6%\n",
      "VQA: 26.5%.\n",
      "These scores do not match the performance in the VilBERT paper. Please contact us if you want to match those scores!\n",
      "2022-04-01 16:10:13,274 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-04-01 16:10:13,275 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-04-01 16:10:13,276 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-04-01 16:10:13,315 - INFO - allennlp.common.params - id = pair-classification-binary-gender-bias-mitigated-roberta-snli\n",
      "2022-04-01 16:10:13,316 - INFO - allennlp.common.params - registered_model_name = bias_mitigator_applicator\n",
      "2022-04-01 16:10:13,316 - INFO - allennlp.common.params - model_class = None\n",
      "2022-04-01 16:10:13,318 - INFO - allennlp.common.params - registered_predictor_name = textual_entailment\n",
      "2022-04-01 16:10:13,320 - INFO - allennlp.common.params - display_name = Binary Gender Bias-Mitigated RoBERTa SNLI\n",
      "2022-04-01 16:10:13,321 - INFO - allennlp.common.params - task_id = textual_entailment\n",
      "2022-04-01 16:10:13,322 - INFO - allennlp.common.params - model_usage.archive_file = binary-gender-bias-mitigated-snli-roberta.2021-05-20.tar.gz\n",
      "2022-04-01 16:10:13,323 - INFO - allennlp.common.params - model_usage.training_config = pair_classification/binary_gender_bias_mitigated_snli_roberta.jsonnet\n",
      "2022-04-01 16:10:13,326 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.5.0 allennlp-models==2.5.0\n",
      "2022-04-01 16:10:13,327 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-04-01 16:10:13,328 - INFO - allennlp.common.params - model_details.description = This `Model` implements a basic text classifier with a bias mitigator applicator wrapper. The text is embedded into a text field using a RoBERTa-large model. Following the static embedding layer, the embeddings are projected onto the subspace orthogonal to the binary gender bias subspace. The resulting sequence is pooled using a cls_pooler `Seq2VecEncoder` and then passed to a linear classification layer, which projects into the label space.\n",
      "2022-04-01 16:10:13,329 - INFO - allennlp.common.params - model_details.short_description = RoBERTa finetuned on SNLI with binary gender bias mitigation.\n",
      "2022-04-01 16:10:13,330 - INFO - allennlp.common.params - model_details.developed_by = Dev at al\n",
      "2022-04-01 16:10:13,330 - INFO - allennlp.common.params - model_details.contributed_by = Arjun Subramonian\n",
      "2022-04-01 16:10:13,331 - INFO - allennlp.common.params - model_details.date = 2021-05-20\n",
      "2022-04-01 16:10:13,332 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-04-01 16:10:13,332 - INFO - allennlp.common.params - model_details.model_type = RoBERTa\n",
      "2022-04-01 16:10:13,333 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@article{Dev2020OnMA,\n",
      "title={On Measuring and Mitigating Biased Inferences of Word Embeddings},\n",
      "author={Sunipa Dev and Tao Li and J. M. Phillips and Vivek Srikumar},\n",
      "journal={Proceedings of the AAAI Conference on Artificial Intelligence},\n",
      "year={2020},\n",
      "volume={34},\n",
      "number={05},\n",
      "pages={7659-7666},\n",
      "DOI={10.1609/aaai.v34i05.6267}\n",
      "\n",
      "2022-04-01 16:10:13,333 - INFO - allennlp.common.params - model_details.paper.title = On Measuring and Mitigating Biased Inferences of Word Embeddings\n",
      "2022-04-01 16:10:13,334 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:201670701\n",
      "2022-04-01 16:10:13,334 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-04-01 16:10:13,335 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-04-01 16:10:13,335 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-04-01 16:10:13,336 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-04-01 16:10:13,336 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-04-01 16:10:13,338 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-04-01 16:10:13,338 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-04-01 16:10:13,339 - INFO - allennlp.common.params - metrics.model_performance_measures = Accuracy, Net Neutral, Fraction Neutral, Threshold:tau\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-01 16:10:13,340 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-04-01 16:10:13,340 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-04-01 16:10:13,341 - INFO - allennlp.common.params - evaluation_data.dataset.name = On Measuring and Mitigating Biased Gender-Occupation Inferences SNLI Dataset\n",
      "2022-04-01 16:10:13,343 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = https://storage.googleapis.com/allennlp-public-models/binary-gender-bias-mitigated-snli-dataset.jsonl\n",
      "2022-04-01 16:10:13,343 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://github.com/sunipa/On-Measuring-and-Mitigating-Biased-Inferences-of-Word-Embeddings\n",
      "2022-04-01 16:10:13,344 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-04-01 16:10:13,345 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-04-01 16:10:13,346 - INFO - allennlp.common.params - training_data.dataset.name = Stanford Natural Language Inference (SNLI) train set\n",
      "2022-04-01 16:10:13,349 - INFO - allennlp.common.params - training_data.dataset.processed_url = https://allennlp.s3.amazonaws.com/datasets/snli/snli_1.0_train.jsonl\n",
      "2022-04-01 16:10:13,349 - INFO - allennlp.common.params - training_data.dataset.url = https://nlp.stanford.edu/projects/snli/\n",
      "2022-04-01 16:10:13,351 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-04-01 16:10:13,351 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-04-01 16:10:13,352 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = Net Neutral: 0.6417539715766907, Fraction Neutral: 0.7002295255661011, Threshold:0.5: 0.6902161836624146, Threshold:0.7: 0.49243637919425964\n",
      "2022-04-01 16:10:13,353 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-04-01 16:10:13,354 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = Binary gender bias mitigation has been applied to this model. Nonetheless, the model will contain residual biases and bias mitigation does not guarantee entirely bias-free inferences.\n",
      "2022-04-01 16:10:13,355 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-04-01 16:10:13,400 - INFO - allennlp.common.params - id = vqa-vilbert\n",
      "2022-04-01 16:10:13,402 - INFO - allennlp.common.params - registered_model_name = vqa_vilbert\n",
      "2022-04-01 16:10:13,402 - INFO - allennlp.common.params - model_class = None\n",
      "2022-04-01 16:10:13,403 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-04-01 16:10:13,404 - INFO - allennlp.common.params - display_name = ViLBERT - Visual Question Answering\n",
      "2022-04-01 16:10:13,405 - INFO - allennlp.common.params - task_id = vqa\n",
      "2022-04-01 16:10:13,406 - INFO - allennlp.common.params - model_usage.archive_file = vilbert-vqa-pretrained.2021-03-15.tar.gz\n",
      "2022-04-01 16:10:13,407 - INFO - allennlp.common.params - model_usage.training_config = vision/vilbert_vqa_pretrained.jsonnet\n",
      "2022-04-01 16:10:13,408 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
      "2022-04-01 16:10:13,408 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-04-01 16:10:13,409 - INFO - allennlp.common.params - model_details.description = ViLBERT (short for Vision-and-Language BERT), is a model for learning task-agnostic joint representations of image content and natural language.\n",
      "2022-04-01 16:10:13,410 - INFO - allennlp.common.params - model_details.short_description = ViLBERT (short for Vision-and-Language BERT), is a model for learning task-agnostic joint representations of image content and natural language.\n",
      "2022-04-01 16:10:13,410 - INFO - allennlp.common.params - model_details.developed_by = Lu et al\n",
      "2022-04-01 16:10:13,410 - INFO - allennlp.common.params - model_details.contributed_by = Dirk Groeneveld\n",
      "2022-04-01 16:10:13,411 - INFO - allennlp.common.params - model_details.date = 2021-03-15\n",
      "2022-04-01 16:10:13,411 - INFO - allennlp.common.params - model_details.version = 2\n",
      "2022-04-01 16:10:13,412 - INFO - allennlp.common.params - model_details.model_type = ViLBERT based on BERT large\n",
      "2022-04-01 16:10:13,412 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@inproceedings{Lu2019ViLBERTPT,\n",
      "title={ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks},\n",
      "author={Jiasen Lu and Dhruv Batra and D. Parikh and Stefan Lee},\n",
      "booktitle={NeurIPS},\n",
      "year={2019}\n",
      "}\n",
      "2022-04-01 16:10:13,416 - INFO - allennlp.common.params - model_details.paper.title = ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks\n",
      "2022-04-01 16:10:13,417 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:199453025\n",
      "2022-04-01 16:10:13,418 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-04-01 16:10:13,419 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-04-01 16:10:13,420 - INFO - allennlp.common.params - intended_use.primary_uses = This model is developed for the AllenNLP demo.\n",
      "2022-04-01 16:10:13,422 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-04-01 16:10:13,422 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-04-01 16:10:13,423 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-04-01 16:10:13,424 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-04-01 16:10:13,426 - INFO - allennlp.common.params - metrics.model_performance_measures = F1-metric and VQA score\n",
      "2022-04-01 16:10:13,427 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-04-01 16:10:13,427 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-04-01 16:10:13,429 - INFO - allennlp.common.params - evaluation_data.dataset.name = VQA dataset\n",
      "2022-04-01 16:10:13,430 - INFO - allennlp.common.params - evaluation_data.dataset.notes = Evaluation requires a large amount of images to be accessible locally, so we cannot provide a command you can easily copy and paste. The first time you run it, you will get an error message that tells you how to get the rest of the data.\n",
      "2022-04-01 16:10:13,431 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = balanced_real_val\n",
      "2022-04-01 16:10:13,431 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://visualqa.org/\n",
      "2022-04-01 16:10:13,432 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-04-01 16:10:13,432 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-04-01 16:10:13,433 - INFO - allennlp.common.params - training_data.dataset.name = VQA dataset\n",
      "2022-04-01 16:10:13,435 - INFO - allennlp.common.params - training_data.dataset.notes = Training requires a large amount of images to be accessible locally, so we cannot provide a command you can easily copy and paste. The first time you run it, you will get an error message that tells you how to get the rest of the data.\n",
      "2022-04-01 16:10:13,435 - INFO - allennlp.common.params - training_data.dataset.processed_url = balanced_real_train\n",
      "2022-04-01 16:10:13,435 - INFO - allennlp.common.params - training_data.dataset.url = https://visualqa.org/\n",
      "2022-04-01 16:10:13,436 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-04-01 16:10:13,436 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-04-01 16:10:13,438 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = On the validation set:\n",
      "F1: 40%\n",
      "VQA: 54%.\n",
      "These scores do not match the performance in the VilBERT paper. Please contact us if you want to match those scores!\n",
      "2022-04-01 16:10:13,438 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-04-01 16:10:13,439 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-04-01 16:10:13,443 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-01 16:10:13,482 - INFO - allennlp.common.params - id = rc-naqanet\n",
      "2022-04-01 16:10:13,482 - INFO - allennlp.common.params - registered_model_name = naqanet\n",
      "2022-04-01 16:10:13,483 - INFO - allennlp.common.params - model_class = None\n",
      "2022-04-01 16:10:13,484 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-04-01 16:10:13,485 - INFO - allennlp.common.params - display_name = Numerically Augmented QA Net\n",
      "2022-04-01 16:10:13,485 - INFO - allennlp.common.params - task_id = rc\n",
      "2022-04-01 16:10:13,487 - INFO - allennlp.common.params - model_usage.archive_file = naqanet-2021.02.26.tar.gz\n",
      "2022-04-01 16:10:13,488 - INFO - allennlp.common.params - model_usage.training_config = rc/naqanet.jsonnet\n",
      "2022-04-01 16:10:13,489 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
      "2022-04-01 16:10:13,489 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-04-01 16:10:13,490 - INFO - allennlp.common.params - model_details.description = An augmented version of QANet model with some rudimentary numerical reasoning abilities. The main idea here is that instead of just predicting a passage span after doing all of the QANet modeling stuff, we add several different 'answer abilities': predicting a span from the question, predicting a count, or predicting an arithmetic expression.  Near the end of the QANet model, we have a variable that predicts what kind of answer type we need, and each branch has separate modeling logic to predict that answer type.  We then marginalize over all possible ways of getting to the right answer through each of these answer types.\n",
      "2022-04-01 16:10:13,491 - INFO - allennlp.common.params - model_details.short_description = An augmented version of QANet that adds rudimentary numerical reasoning ability, trained on DROP (Dua et al., 2019), as published in the original DROP paper.\n",
      "2022-04-01 16:10:13,492 - INFO - allennlp.common.params - model_details.developed_by = Dua et al\n",
      "2022-04-01 16:10:13,493 - INFO - allennlp.common.params - model_details.contributed_by = None\n",
      "2022-04-01 16:10:13,494 - INFO - allennlp.common.params - model_details.date = 2020-02-19\n",
      "2022-04-01 16:10:13,495 - INFO - allennlp.common.params - model_details.version = 2\n",
      "2022-04-01 16:10:13,496 - INFO - allennlp.common.params - model_details.model_type = QANet\n",
      "2022-04-01 16:10:13,497 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@inproceedings{Dua2019DROPAR,\n",
      "title={DROP: A Reading Comprehension Benchmark Requiring Discrete Reasoning Over Paragraphs},\n",
      "author={Dheeru Dua and Yizhong Wang and Pradeep Dasigi and Gabriel Stanovsky and Sameer Singh and Matt Gardner},\n",
      "booktitle={NAACL-HLT},\n",
      "year={2019}}\n",
      "\n",
      "2022-04-01 16:10:13,498 - INFO - allennlp.common.params - model_details.paper.title = DROP: A Reading Comprehension Benchmark Requiring Discrete Reasoning Over Paragraphs\n",
      "2022-04-01 16:10:13,499 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:67855846\n",
      "2022-04-01 16:10:13,500 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-04-01 16:10:13,501 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-04-01 16:10:13,502 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-04-01 16:10:13,502 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-04-01 16:10:13,503 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-04-01 16:10:13,504 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-04-01 16:10:13,505 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-04-01 16:10:13,508 - INFO - allennlp.common.params - metrics.model_performance_measures = Exact Match and F1-score\n",
      "2022-04-01 16:10:13,509 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-04-01 16:10:13,509 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-04-01 16:10:13,511 - INFO - allennlp.common.params - evaluation_data.dataset.name = DROP\n",
      "2022-04-01 16:10:13,511 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = https://s3-us-west-2.amazonaws.com/allennlp/datasets/drop/drop_dataset.zip!drop_dataset/drop_dataset_dev.json\n",
      "2022-04-01 16:10:13,512 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://allennlp.org/drop\n",
      "2022-04-01 16:10:13,513 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-04-01 16:10:13,514 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-04-01 16:10:13,515 - INFO - allennlp.common.params - training_data.dataset.name = DROP\n",
      "2022-04-01 16:10:13,516 - INFO - allennlp.common.params - training_data.dataset.processed_url = https://s3-us-west-2.amazonaws.com/allennlp/datasets/drop/drop_dataset.zip!drop_dataset/drop_dataset_train.json\n",
      "2022-04-01 16:10:13,518 - INFO - allennlp.common.params - training_data.dataset.url = https://allennlp.org/drop\n",
      "2022-04-01 16:10:13,519 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-04-01 16:10:13,519 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-04-01 16:10:13,521 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = Validation F1-score: 0.509, Exact Match: 0.473\n",
      "2022-04-01 16:10:13,522 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-04-01 16:10:13,523 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-04-01 16:10:13,526 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-04-01 16:10:13,569 - INFO - allennlp.common.params - id = structured-prediction-constituency-parser\n",
      "2022-04-01 16:10:13,570 - INFO - allennlp.common.params - registered_model_name = constituency_parser\n",
      "2022-04-01 16:10:13,571 - INFO - allennlp.common.params - model_class = None\n",
      "2022-04-01 16:10:13,572 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-04-01 16:10:13,572 - INFO - allennlp.common.params - display_name = Constituency Parser with ELMo embeddings\n",
      "2022-04-01 16:10:13,573 - INFO - allennlp.common.params - task_id = constituency-parsing\n",
      "2022-04-01 16:10:13,574 - INFO - allennlp.common.params - model_usage.archive_file = elmo-constituency-parser-2020.02.10.tar.gz\n",
      "2022-04-01 16:10:13,575 - INFO - allennlp.common.params - model_usage.training_config = structured-prediction/constituency_parser_elmo.jsonnet\n",
      "2022-04-01 16:10:13,575 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
      "2022-04-01 16:10:13,576 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-04-01 16:10:13,578 - INFO - allennlp.common.params - model_details.description = This is an implementation of a minimal neural model for constituency parsing based on an independent scoring of labels and spans. This `SpanConstituencyParser` simply encodes a sequence of text with a stacked `Seq2SeqEncoder`, extracts span representations using a `SpanExtractor`, and then predicts a label for each span in the sequence. These labels are non-terminal nodes in a constituency parse tree, which we then greedily reconstruct. The model uses ELMo embeddings, which are completely character-based and improves single model performance from 92.6 F1 to 94.11 F1 on the Penn Treebank, a 20% relative error reduction.\n",
      "2022-04-01 16:10:13,578 - INFO - allennlp.common.params - model_details.short_description = Constituency parser with character-based ELMo embeddings\n",
      "2022-04-01 16:10:13,579 - INFO - allennlp.common.params - model_details.developed_by = Joshi et al\n",
      "2022-04-01 16:10:13,579 - INFO - allennlp.common.params - model_details.contributed_by = None\n",
      "2022-04-01 16:10:13,580 - INFO - allennlp.common.params - model_details.date = 2020-02-10\n",
      "2022-04-01 16:10:13,581 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-04-01 16:10:13,582 - INFO - allennlp.common.params - model_details.model_type = Seq2SeqEncoder\n",
      "2022-04-01 16:10:13,586 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@inproceedings{Joshi2018ExtendingAP,\n",
      "title={Extending a Parser to Distant Domains Using a Few Dozen Partially Annotated Examples},\n",
      "author={V. Joshi and Matthew E. Peters and Mark Hopkins},\n",
      "booktitle={ACL},\n",
      "year={2018}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-01 16:10:13,587 - INFO - allennlp.common.params - model_details.paper.title = Extending a Parser to Distant Domains Using a Few Dozen Partially Annotated Examples\n",
      "2022-04-01 16:10:13,588 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:21712653\n",
      "2022-04-01 16:10:13,589 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-04-01 16:10:13,590 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-04-01 16:10:13,591 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-04-01 16:10:13,593 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-04-01 16:10:13,594 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-04-01 16:10:13,595 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-04-01 16:10:13,596 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-04-01 16:10:13,597 - INFO - allennlp.common.params - metrics.model_performance_measures = Precision, Recall and F1-score for parse trees (EVALB_bracketing_scorer)\n",
      "2022-04-01 16:10:13,597 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-04-01 16:10:13,598 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-04-01 16:10:13,600 - INFO - allennlp.common.params - evaluation_data.dataset.name = PTB 3.0\n",
      "2022-04-01 16:10:13,601 - INFO - allennlp.common.params - evaluation_data.dataset.notes = Please download the data from the url provided.\n",
      "2022-04-01 16:10:13,602 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = /path/do/dataset\n",
      "2022-04-01 16:10:13,602 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://catalog.ldc.upenn.edu/LDC99T42\n",
      "2022-04-01 16:10:13,603 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-04-01 16:10:13,603 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-04-01 16:10:13,605 - INFO - allennlp.common.params - training_data.dataset.name = PTB 3.0\n",
      "2022-04-01 16:10:13,605 - INFO - allennlp.common.params - training_data.dataset.notes = Please download the data from the url provided.\n",
      "2022-04-01 16:10:13,606 - INFO - allennlp.common.params - training_data.dataset.processed_url = /path/do/dataset\n",
      "2022-04-01 16:10:13,607 - INFO - allennlp.common.params - training_data.dataset.url = https://catalog.ldc.upenn.edu/LDC99T42\n",
      "2022-04-01 16:10:13,607 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-04-01 16:10:13,608 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-04-01 16:10:13,609 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = 94.11 F1 score\n",
      "2022-04-01 16:10:13,610 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-04-01 16:10:13,611 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-04-01 16:10:13,612 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-04-01 16:10:13,654 - INFO - allennlp.common.params - id = pair-classification-roberta-rte\n",
      "2022-04-01 16:10:13,655 - INFO - allennlp.common.params - registered_model_name = basic_classifier\n",
      "2022-04-01 16:10:13,655 - INFO - allennlp.common.params - model_class = None\n",
      "2022-04-01 16:10:13,657 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-04-01 16:10:13,657 - INFO - allennlp.common.params - display_name = RoBERTa RTE\n",
      "2022-04-01 16:10:13,658 - INFO - allennlp.common.params - task_id = pair_classification\n",
      "2022-04-01 16:10:13,659 - INFO - allennlp.common.params - model_usage.archive_file = superglue-rte-roberta.2021-04-09.tar.gz\n",
      "2022-04-01 16:10:13,661 - INFO - allennlp.common.params - model_usage.training_config = pair-classification/superglue_rte_roberta.jsonnet\n",
      "2022-04-01 16:10:13,662 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.3.1 allennlp-models==2.3.1\n",
      "2022-04-01 16:10:13,663 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-04-01 16:10:13,665 - INFO - allennlp.common.params - model_details.description = The model implements a pair classification model patterned after the proposed model in [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding (Devlin et al, 2018)](https://api.semanticscholar.org/CorpusID:52967399), fine-tuned on the MultiNLI corpus. It predicts labels with a linear layer on top of word piece embeddings.\n",
      "2022-04-01 16:10:13,666 - INFO - allennlp.common.params - model_details.short_description = A pair classification model patterned after the proposed model in Devlin et al, fine-tuned on the SuperGLUE RTE corpus\n",
      "2022-04-01 16:10:13,667 - INFO - allennlp.common.params - model_details.developed_by = Devlin et al\n",
      "2022-04-01 16:10:13,670 - INFO - allennlp.common.params - model_details.contributed_by = Jacob Morrison\n",
      "2022-04-01 16:10:13,671 - INFO - allennlp.common.params - model_details.date = 2021-04-09\n",
      "2022-04-01 16:10:13,673 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-04-01 16:10:13,674 - INFO - allennlp.common.params - model_details.model_type = RoBERTa\n",
      "2022-04-01 16:10:13,676 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@article{Liu2019RoBERTaAR,\n",
      "title={RoBERTa: A Robustly Optimized BERT Pretraining Approach},\n",
      "author={Y. Liu and Myle Ott and Naman Goyal and Jingfei Du and Mandar Joshi and Danqi Chen and Omer Levy and M. Lewis and L. Zettlemoyer and V. Stoyanov},\n",
      "journal={ArXiv},\n",
      "year={2019},\n",
      "volume={abs/1907.11692}}\n",
      "\n",
      "2022-04-01 16:10:13,676 - INFO - allennlp.common.params - model_details.paper.title = RoBERTa: A Robustly Optimized BERT Pretraining Approach\n",
      "2022-04-01 16:10:13,677 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:198953378\n",
      "2022-04-01 16:10:13,677 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-04-01 16:10:13,678 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-04-01 16:10:13,679 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-04-01 16:10:13,680 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-04-01 16:10:13,680 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-04-01 16:10:13,681 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-04-01 16:10:13,682 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-04-01 16:10:13,684 - INFO - allennlp.common.params - metrics.model_performance_measures = Accuracy\n",
      "2022-04-01 16:10:13,685 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-04-01 16:10:13,685 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-04-01 16:10:13,686 - INFO - allennlp.common.params - evaluation_data.dataset.name = SuperGLUE Recognizing Textual Entailment validation set\n",
      "2022-04-01 16:10:13,687 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = https://dl.fbaipublicfiles.com/glue/superglue/data/v2/RTE.zip!RTE/val.jsonl\n",
      "2022-04-01 16:10:13,688 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://super.gluebenchmark.com/tasks\n",
      "2022-04-01 16:10:13,689 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-04-01 16:10:13,690 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-04-01 16:10:13,692 - INFO - allennlp.common.params - training_data.dataset.name = SuperGLUE Recognizing Textual Entailment training set\n",
      "2022-04-01 16:10:13,693 - INFO - allennlp.common.params - training_data.dataset.processed_url = https://dl.fbaipublicfiles.com/glue/superglue/data/v2/RTE.zip!RTE/train.jsonl\n",
      "2022-04-01 16:10:13,693 - INFO - allennlp.common.params - training_data.dataset.url = https://super.gluebenchmark.com/tasks\n",
      "2022-04-01 16:10:13,694 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-04-01 16:10:13,695 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-04-01 16:10:13,696 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = Accuracy: 89.9% on the SuperGLUE RTE validation dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-01 16:10:13,696 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-04-01 16:10:13,697 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-04-01 16:10:13,699 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-04-01 16:10:13,744 - INFO - allennlp.common.params - id = lm-masked-language-model\n",
      "2022-04-01 16:10:13,745 - INFO - allennlp.common.params - registered_model_name = masked_language_model\n",
      "2022-04-01 16:10:13,746 - INFO - allennlp.common.params - model_class = None\n",
      "2022-04-01 16:10:13,746 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-04-01 16:10:13,747 - INFO - allennlp.common.params - display_name = BERT-based Masked Language Model\n",
      "2022-04-01 16:10:13,748 - INFO - allennlp.common.params - task_id = masked-language-modeling\n",
      "2022-04-01 16:10:13,749 - INFO - allennlp.common.params - model_usage.archive_file = bert-masked-lm-2020-10-07.tar.gz\n",
      "2022-04-01 16:10:13,750 - INFO - allennlp.common.params - model_usage.training_config = lm/bidirectional_language_model.jsonnet\n",
      "2022-04-01 16:10:13,751 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
      "2022-04-01 16:10:13,752 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-04-01 16:10:13,753 - INFO - allennlp.common.params - model_details.description = The `MaskedLanguageModel` embeds some input tokens (including some which are masked), contextualizes them, then predicts targets for the masked tokens, computing a loss against known targets.\n",
      "2022-04-01 16:10:13,754 - INFO - allennlp.common.params - model_details.short_description = BERT-based masked language model\n",
      "2022-04-01 16:10:13,754 - INFO - allennlp.common.params - model_details.developed_by = Devlin et al\n",
      "2022-04-01 16:10:13,755 - INFO - allennlp.common.params - model_details.contributed_by = None\n",
      "2022-04-01 16:10:13,756 - INFO - allennlp.common.params - model_details.date = 2020-10-07\n",
      "2022-04-01 16:10:13,756 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-04-01 16:10:13,757 - INFO - allennlp.common.params - model_details.model_type = BERT\n",
      "2022-04-01 16:10:13,758 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@inproceedings{Devlin2019BERTPO,\n",
      "title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},\n",
      "author={J. Devlin and Ming-Wei Chang and Kenton Lee and Kristina Toutanova},\n",
      "booktitle={NAACL-HLT},\n",
      "year={2019}}\n",
      "\n",
      "2022-04-01 16:10:13,759 - INFO - allennlp.common.params - model_details.paper.title = BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\n",
      "2022-04-01 16:10:13,760 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:52967399\n",
      "2022-04-01 16:10:13,761 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-04-01 16:10:13,761 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-04-01 16:10:13,762 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-04-01 16:10:13,763 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-04-01 16:10:13,764 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-04-01 16:10:13,765 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-04-01 16:10:13,766 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-04-01 16:10:13,768 - INFO - allennlp.common.params - metrics.model_performance_measures = Perplexity\n",
      "2022-04-01 16:10:13,769 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-04-01 16:10:13,770 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-04-01 16:10:13,772 - INFO - allennlp.common.params - evaluation_data.dataset = BooksCorpus (800M words) and English Wikipedia (2,500M words).\n",
      "2022-04-01 16:10:13,773 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-04-01 16:10:13,774 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-04-01 16:10:13,775 - INFO - allennlp.common.params - training_data.dataset = BooksCorpus (800M words) and English Wikipedia (2,500M words).\n",
      "2022-04-01 16:10:13,776 - INFO - allennlp.common.params - training_data.motivation = Document-level corpus is used rather than shuffled sentence-level corpus, to extract long contiguous sequences.\n",
      "2022-04-01 16:10:13,777 - INFO - allennlp.common.params - training_data.preprocessing = For Wikipedia, text passages are extracted and lists, tables, and headers are ignored.\n",
      "2022-04-01 16:10:13,778 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = None\n",
      "2022-04-01 16:10:13,779 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-04-01 16:10:13,780 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = BERT demonstrates gender bias in that it thinks the doctor is more likely a man ('his') than a woman ('her'). An important issue in NLP is how to understand and address such biases in our linguistic models.\n",
      "2022-04-01 16:10:13,782 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = NOTE: This was developed for use in a demo, not for training.  It's possible that it will still work for training a masked LM, but it is very likely that some other code would be much more efficient for that.  This `does` compute correct gradients of the loss, because we use that in our demo, so in principle it should be able to train a model, we just don't necessarily endorse that use.\n",
      "2022-04-01 16:10:13,827 - INFO - allennlp.common.params - id = rc-transformer-qa\n",
      "2022-04-01 16:10:13,828 - INFO - allennlp.common.params - registered_model_name = transformer_qa\n",
      "2022-04-01 16:10:13,829 - INFO - allennlp.common.params - model_class = None\n",
      "2022-04-01 16:10:13,829 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-04-01 16:10:13,830 - INFO - allennlp.common.params - display_name = Transformer QA\n",
      "2022-04-01 16:10:13,831 - INFO - allennlp.common.params - task_id = rc\n",
      "2022-04-01 16:10:13,832 - INFO - allennlp.common.params - model_usage.archive_file = transformer-qa.2021-02-11.tar.gz\n",
      "2022-04-01 16:10:13,833 - INFO - allennlp.common.params - model_usage.training_config = rc/transformer_qa.jsonnet\n",
      "2022-04-01 16:10:13,834 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
      "2022-04-01 16:10:13,835 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-04-01 16:10:13,837 - INFO - allennlp.common.params - model_details.description = The model implements a reading comprehension model patterned after the proposed model in [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding (Devlin et al, 2018)](https://api.semanticscholar.org/CorpusID:52967399), with improvements borrowed from the SQuAD model in the transformers project. It predicts start tokens and end tokens with a linear layer on top of word piece embeddings.\n",
      "2022-04-01 16:10:13,838 - INFO - allennlp.common.params - model_details.short_description = A reading comprehension model patterned after the proposed model in Devlin et al, with improvements borrowed from the SQuAD model in the transformers project\n",
      "2022-04-01 16:10:13,840 - INFO - allennlp.common.params - model_details.developed_by = Devlin et al\n",
      "2022-04-01 16:10:13,841 - INFO - allennlp.common.params - model_details.contributed_by = Dirk Groeneveld and Evan Pete Walsh\n",
      "2022-04-01 16:10:13,842 - INFO - allennlp.common.params - model_details.date = 2020-10-03\n",
      "2022-04-01 16:10:13,843 - INFO - allennlp.common.params - model_details.version = 2\n",
      "2022-04-01 16:10:13,844 - INFO - allennlp.common.params - model_details.model_type = RoBERTa\n",
      "2022-04-01 16:10:13,846 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@article{Liu2019RoBERTaAR,\n",
      "title={RoBERTa: A Robustly Optimized BERT Pretraining Approach},\n",
      "author={Y. Liu and Myle Ott and Naman Goyal and Jingfei Du and Mandar Joshi and Danqi Chen and Omer Levy and M. Lewis and L. Zettlemoyer and V. Stoyanov},\n",
      "journal={ArXiv},\n",
      "year={2019},\n",
      "volume={abs/1907.11692}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-01 16:10:13,847 - INFO - allennlp.common.params - model_details.paper.title = RoBERTa: A Robustly Optimized BERT Pretraining Approach\n",
      "2022-04-01 16:10:13,847 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:198953378\n",
      "2022-04-01 16:10:13,852 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-04-01 16:10:13,853 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-04-01 16:10:13,854 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-04-01 16:10:13,855 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-04-01 16:10:13,857 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-04-01 16:10:13,858 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-04-01 16:10:13,859 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-04-01 16:10:13,860 - INFO - allennlp.common.params - metrics.model_performance_measures = F1-score, Span Accuracy, Exact Match\n",
      "2022-04-01 16:10:13,861 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-04-01 16:10:13,862 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-04-01 16:10:13,864 - INFO - allennlp.common.params - evaluation_data.dataset.name = SQuAD dev set\n",
      "2022-04-01 16:10:13,865 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = https://s3-us-west-2.amazonaws.com/allennlp/datasets/squad/squad-dev-v2.0.json\n",
      "2022-04-01 16:10:13,866 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://rajpurkar.github.io/SQuAD-explorer/explore/2.0/dev/\n",
      "2022-04-01 16:10:13,867 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-04-01 16:10:13,868 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-04-01 16:10:13,872 - INFO - allennlp.common.params - training_data.dataset.name = SQuAD training set\n",
      "2022-04-01 16:10:13,873 - INFO - allennlp.common.params - training_data.dataset.processed_url = https://s3-us-west-2.amazonaws.com/allennlp/datasets/squad/squad-train-v2.0.json\n",
      "2022-04-01 16:10:13,874 - INFO - allennlp.common.params - training_data.dataset.url = https://rajpurkar.github.io/SQuAD-explorer/explore/2.0/dev/\n",
      "2022-04-01 16:10:13,875 - INFO - allennlp.common.params - training_data.motivation = For the pretrained RoBERTa model, document-level corpora were used rather than a shuffled sentence-level corpus such as the Billion Word Benchmark (Chelba et al., 2013) in order to extract long contiguous sequences\n",
      "2022-04-01 16:10:13,877 - INFO - allennlp.common.params - training_data.preprocessing = For the pretrained RoBERTa model, only the text passages were extracted from English Wikipedia; lists, tables, and headers were ignored.\n",
      "2022-04-01 16:10:13,878 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = On the validation set:\n",
      "F1: 88%\n",
      "Exact match: 84%\n",
      "These are metrics using the official evaluation. Note that the metrics that the model produces while training are calculated on a per-instance basis only. Since there could be more than one instance per question, these metrics are not the official numbers on the SQuAD task. To get official numbers, run the evaluation script at allennlp_models/rc/tools/transformer_qa_eval.py.\n",
      "2022-04-01 16:10:13,879 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-04-01 16:10:13,881 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-04-01 16:10:13,883 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-04-01 16:10:13,927 - INFO - allennlp.common.params - id = mc-roberta-swag\n",
      "2022-04-01 16:10:13,929 - INFO - allennlp.common.params - registered_model_name = transformer_mc\n",
      "2022-04-01 16:10:13,930 - INFO - allennlp.common.params - model_class = None\n",
      "2022-04-01 16:10:13,931 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-04-01 16:10:13,932 - INFO - allennlp.common.params - display_name = RoBERTa SWAG\n",
      "2022-04-01 16:10:13,932 - INFO - allennlp.common.params - task_id = mc\n",
      "2022-04-01 16:10:13,934 - INFO - allennlp.common.params - model_usage.archive_file = swag.2020-07-08.tar.gz\n",
      "2022-04-01 16:10:13,934 - INFO - allennlp.common.params - model_usage.training_config = mc/swag.jsonnet\n",
      "2022-04-01 16:10:13,935 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==1.0.0 allennlp-models==1.0.0\n",
      "2022-04-01 16:10:13,935 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-04-01 16:10:13,936 - INFO - allennlp.common.params - model_details.description = This is a multiple choice model patterned after the BERT architecture. It calculates a score for each sequence on top of the CLS token, and then chooses the alternative with the highest score.\n",
      "2022-04-01 16:10:13,937 - INFO - allennlp.common.params - model_details.short_description = RoBERTa-based multiple choice model for SWAG.\n",
      "2022-04-01 16:10:13,938 - INFO - allennlp.common.params - model_details.developed_by = Devlin et al\n",
      "2022-04-01 16:10:13,938 - INFO - allennlp.common.params - model_details.contributed_by = Dirk Groeneveld\n",
      "2022-04-01 16:10:13,939 - INFO - allennlp.common.params - model_details.date = 2020-07-08\n",
      "2022-04-01 16:10:13,939 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-04-01 16:10:13,940 - INFO - allennlp.common.params - model_details.model_type = RoBERTa large\n",
      "2022-04-01 16:10:13,941 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@article{Liu2019RoBERTaAR,\n",
      "title={RoBERTa: A Robustly Optimized BERT Pretraining Approach},\n",
      "author={Y. Liu and Myle Ott and Naman Goyal and Jingfei Du and Mandar Joshi and Danqi Chen and Omer Levy and M. Lewis and Luke Zettlemoyer and Veselin Stoyanov},\n",
      "journal={ArXiv},\n",
      "year={2019},\n",
      "volume={abs/1907.11692}}\n",
      "\n",
      "2022-04-01 16:10:13,942 - INFO - allennlp.common.params - model_details.paper.title = RoBERTa: A Robustly Optimized BERT Pretraining Approach (Liu et al)\n",
      "2022-04-01 16:10:13,942 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:198953378\n",
      "2022-04-01 16:10:13,943 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-04-01 16:10:13,944 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-04-01 16:10:13,945 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-04-01 16:10:13,946 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-04-01 16:10:13,946 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-04-01 16:10:13,947 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-04-01 16:10:13,948 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-04-01 16:10:13,949 - INFO - allennlp.common.params - metrics.model_performance_measures = The chosen metric is accuracy, since it is a multiple choice model.\n",
      "2022-04-01 16:10:13,951 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-04-01 16:10:13,951 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-04-01 16:10:13,953 - INFO - allennlp.common.params - evaluation_data.dataset.name = SWAG (validation set)\n",
      "2022-04-01 16:10:13,954 - INFO - allennlp.common.params - evaluation_data.dataset.notes = Please download the data from the url provided.\n",
      "2022-04-01 16:10:13,955 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://rowanzellers.com/swag/\n",
      "2022-04-01 16:10:13,957 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-04-01 16:10:13,958 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-04-01 16:10:13,959 - INFO - allennlp.common.params - training_data.dataset.name = SWAG (train set)\n",
      "2022-04-01 16:10:13,961 - INFO - allennlp.common.params - training_data.dataset.notes = Please download the data from the url provided.\n",
      "2022-04-01 16:10:13,961 - INFO - allennlp.common.params - training_data.dataset.url = https://rowanzellers.com/swag/\n",
      "2022-04-01 16:10:13,963 - INFO - allennlp.common.params - training_data.motivation = None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-01 16:10:13,968 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-04-01 16:10:13,969 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = None\n",
      "2022-04-01 16:10:13,970 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-04-01 16:10:13,972 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-04-01 16:10:13,974 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-04-01 16:10:14,014 - INFO - allennlp.common.params - id = rc-bidaf\n",
      "2022-04-01 16:10:14,016 - INFO - allennlp.common.params - registered_model_name = bidaf\n",
      "2022-04-01 16:10:14,018 - INFO - allennlp.common.params - model_class = None\n",
      "2022-04-01 16:10:14,019 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-04-01 16:10:14,020 - INFO - allennlp.common.params - display_name = BiDAF\n",
      "2022-04-01 16:10:14,021 - INFO - allennlp.common.params - task_id = rc\n",
      "2022-04-01 16:10:14,023 - INFO - allennlp.common.params - model_usage.archive_file = bidaf-model-2020.03.19.tar.gz\n",
      "2022-04-01 16:10:14,024 - INFO - allennlp.common.params - model_usage.training_config = rc/bidaf.jsonnet\n",
      "2022-04-01 16:10:14,025 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
      "2022-04-01 16:10:14,026 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-04-01 16:10:14,028 - INFO - allennlp.common.params - model_details.description = This is an implementation of the BiDAF model with GloVe embeddings. The basic layout is pretty simple: encode words as a combination of word embeddings and a character-level encoder, pass the word representations through a bi-LSTM/GRU, use a matrix of attentions to put question information into the passage word representations (this is the only part that is at all non-standard), pass this through another few layers of bi-LSTMs/GRUs, and do a softmax over span start and span end.\n",
      "2022-04-01 16:10:14,029 - INFO - allennlp.common.params - model_details.short_description = BiDAF model with GloVe embeddings.\n",
      "2022-04-01 16:10:14,029 - INFO - allennlp.common.params - model_details.developed_by = Seo et al\n",
      "2022-04-01 16:10:14,030 - INFO - allennlp.common.params - model_details.contributed_by = None\n",
      "2022-04-01 16:10:14,031 - INFO - allennlp.common.params - model_details.date = 2020-03-19\n",
      "2022-04-01 16:10:14,034 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-04-01 16:10:14,034 - INFO - allennlp.common.params - model_details.model_type = BiDAF\n",
      "2022-04-01 16:10:14,035 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@article{Seo2017BidirectionalAF,\n",
      "title={Bidirectional Attention Flow for Machine Comprehension},\n",
      "author={Minjoon Seo and Aniruddha Kembhavi and Ali Farhadi and Hannaneh Hajishirzi},\n",
      "journal={ArXiv},\n",
      "year={2017},\n",
      "volume={abs/1611.01603}}\n",
      "\n",
      "2022-04-01 16:10:14,036 - INFO - allennlp.common.params - model_details.paper.title = Bidirectional Attention Flow for Machine Comprehension\n",
      "2022-04-01 16:10:14,037 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:8535316\n",
      "2022-04-01 16:10:14,038 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-04-01 16:10:14,039 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-04-01 16:10:14,041 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-04-01 16:10:14,043 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-04-01 16:10:14,044 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-04-01 16:10:14,045 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-04-01 16:10:14,047 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-04-01 16:10:14,048 - INFO - allennlp.common.params - metrics.model_performance_measures = Start, end, and overall span accuracy, Exact Match, F1 score\n",
      "2022-04-01 16:10:14,049 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-04-01 16:10:14,051 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-04-01 16:10:14,052 - INFO - allennlp.common.params - evaluation_data.dataset.name = SQuAD dev set\n",
      "2022-04-01 16:10:14,053 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = https://s3-us-west-2.amazonaws.com/allennlp/datasets/squad/squad-dev-v1.1.json\n",
      "2022-04-01 16:10:14,054 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://rajpurkar.github.io/SQuAD-explorer/explore/1.1/dev/\n",
      "2022-04-01 16:10:14,055 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-04-01 16:10:14,056 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-04-01 16:10:14,058 - INFO - allennlp.common.params - training_data.dataset.name = SQuAD training set\n",
      "2022-04-01 16:10:14,060 - INFO - allennlp.common.params - training_data.dataset.processed_url = https://s3-us-west-2.amazonaws.com/allennlp/datasets/squad/squad-train-v1.1.json\n",
      "2022-04-01 16:10:14,060 - INFO - allennlp.common.params - training_data.dataset.url = https://rajpurkar.github.io/SQuAD-explorer/explore/1.1/dev/\n",
      "2022-04-01 16:10:14,061 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-04-01 16:10:14,062 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-04-01 16:10:14,063 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = On the validation set:\n",
      "Start accuracy: 61%\n",
      "End accuracy: 66%\n",
      "Overall span accuracy: 52%\n",
      "Exact match: 66%\n",
      "F1: 76%\n",
      "2022-04-01 16:10:14,064 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-04-01 16:10:14,066 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-04-01 16:10:14,068 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-04-01 16:10:14,111 - INFO - allennlp.common.params - id = rc-bidaf-elmo\n",
      "2022-04-01 16:10:14,112 - INFO - allennlp.common.params - registered_model_name = bidaf\n",
      "2022-04-01 16:10:14,113 - INFO - allennlp.common.params - model_class = None\n",
      "2022-04-01 16:10:14,114 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-04-01 16:10:14,115 - INFO - allennlp.common.params - display_name = ELMo-BiDAF\n",
      "2022-04-01 16:10:14,116 - INFO - allennlp.common.params - task_id = rc\n",
      "2022-04-01 16:10:14,117 - INFO - allennlp.common.params - model_usage.archive_file = bidaf-elmo.2021-02-11.tar.gz\n",
      "2022-04-01 16:10:14,117 - INFO - allennlp.common.params - model_usage.training_config = rc/bidaf_elmo.jsonnet\n",
      "2022-04-01 16:10:14,118 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
      "2022-04-01 16:10:14,119 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-04-01 16:10:14,119 - INFO - allennlp.common.params - model_details.description = This is an implementation of the BiDAF model with ELMo embeddings. The basic layout is pretty simple: encode words as a combination of word embeddings and a character-level encoder, pass the word representations through a bi-LSTM/GRU, use a matrix of attentions to put question information into the passage word representations (this is the only part that is at all non-standard), pass this through another few layers of bi-LSTMs/GRUs, and do a softmax over span start and span end.\n",
      "2022-04-01 16:10:14,121 - INFO - allennlp.common.params - model_details.short_description = BiDAF model with ELMo embeddings instead of GloVe.\n",
      "2022-04-01 16:10:14,121 - INFO - allennlp.common.params - model_details.developed_by = Seo et al\n",
      "2022-04-01 16:10:14,122 - INFO - allennlp.common.params - model_details.contributed_by = None\n",
      "2022-04-01 16:10:14,123 - INFO - allennlp.common.params - model_details.date = 2020-03-19\n",
      "2022-04-01 16:10:14,124 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-04-01 16:10:14,125 - INFO - allennlp.common.params - model_details.model_type = BiDAF\n",
      "2022-04-01 16:10:14,128 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@article{Seo2017BidirectionalAF,\n",
      "title={Bidirectional Attention Flow for Machine Comprehension},\n",
      "author={Minjoon Seo and Aniruddha Kembhavi and Ali Farhadi and Hannaneh Hajishirzi},\n",
      "journal={ArXiv},\n",
      "year={2017},\n",
      "volume={abs/1611.01603}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-01 16:10:14,129 - INFO - allennlp.common.params - model_details.paper.title = Bidirectional Attention Flow for Machine Comprehension\n",
      "2022-04-01 16:10:14,129 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:8535316\n",
      "2022-04-01 16:10:14,130 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-04-01 16:10:14,131 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-04-01 16:10:14,132 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-04-01 16:10:14,133 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-04-01 16:10:14,134 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-04-01 16:10:14,135 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-04-01 16:10:14,137 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-04-01 16:10:14,139 - INFO - allennlp.common.params - metrics.model_performance_measures = Start, end and overall span accuracy, Exact Match, F1 score\n",
      "2022-04-01 16:10:14,141 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-04-01 16:10:14,142 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-04-01 16:10:14,144 - INFO - allennlp.common.params - evaluation_data.dataset.name = SQuAD dev set\n",
      "2022-04-01 16:10:14,145 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = https://s3-us-west-2.amazonaws.com/allennlp/datasets/squad/squad-dev-v1.1.json\n",
      "2022-04-01 16:10:14,145 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://rajpurkar.github.io/SQuAD-explorer/explore/1.1/dev/\n",
      "2022-04-01 16:10:14,146 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-04-01 16:10:14,146 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-04-01 16:10:14,148 - INFO - allennlp.common.params - training_data.dataset.name = SQuAD training set\n",
      "2022-04-01 16:10:14,149 - INFO - allennlp.common.params - training_data.dataset.processed_url = https://s3-us-west-2.amazonaws.com/allennlp/datasets/squad/squad-train-v1.1.json\n",
      "2022-04-01 16:10:14,149 - INFO - allennlp.common.params - training_data.dataset.url = https://rajpurkar.github.io/SQuAD-explorer/explore/1.1/dev/\n",
      "2022-04-01 16:10:14,152 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-04-01 16:10:14,153 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-04-01 16:10:14,154 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = On the validation set:\n",
      "Start accuracy: 66%\n",
      "End accuracy: 69%\n",
      "Overall span accuracy: 57%\n",
      "Exact match: 71%\n",
      "F1: 80%\n",
      "2022-04-01 16:10:14,155 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-04-01 16:10:14,156 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-04-01 16:10:14,159 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = This model is based on ELMo. ELMo is not deterministic, meaning that you will see slight differences every time you run it. Also, ELMo likes to be warmed up, so we recommend processing dummy input before processing real workloads with it.\n",
      "2022-04-01 16:10:14,195 - INFO - allennlp.common.params - id = pair-classification-adversarial-binary-gender-bias-mitigated-roberta-snli\n",
      "2022-04-01 16:10:14,196 - INFO - allennlp.common.params - registered_model_name = adversarial_bias_mitigator\n",
      "2022-04-01 16:10:14,197 - INFO - allennlp.common.params - model_class = None\n",
      "2022-04-01 16:10:14,198 - INFO - allennlp.common.params - registered_predictor_name = textual_entailment\n",
      "2022-04-01 16:10:14,199 - INFO - allennlp.common.params - display_name = Adversarial Binary Gender Bias-Mitigated RoBERTa SNLI\n",
      "2022-04-01 16:10:14,199 - INFO - allennlp.common.params - task_id = textual_entailment\n",
      "2022-04-01 16:10:14,201 - INFO - allennlp.common.params - model_usage.archive_file = adversarial-binary-gender-bias-mitigated-snli-roberta.2021-06-17.tar.gz\n",
      "2022-04-01 16:10:14,202 - INFO - allennlp.common.params - model_usage.training_config = pair_classification/adversarial_binary_gender_bias_mitigated_snli_roberta.jsonnet\n",
      "2022-04-01 16:10:14,203 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp allennlp-models\n",
      "2022-04-01 16:10:14,204 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-04-01 16:10:14,206 - INFO - allennlp.common.params - model_details.description = This `Model` implements a basic text classifier and feedforward regression adversary with an adversarial bias mitigator wrapper. The text is embedded into a text field using a RoBERTa-large model. The resulting sequence is pooled using a cls_pooler `Seq2VecEncoder` and then passed to a linear classification layer, which projects into the label space. Subsequently, a `FeedForwardRegressionAdversary` attempts to recover the coefficient of the static text embedding in the binary gender bias subspace. While the adversary's parameter updates are computed normally, the predictor's parameters are updated such that the predictor will not aid the adversary and will make it more difficult for the adversary to recover protected variables.\n",
      "2022-04-01 16:10:14,208 - INFO - allennlp.common.params - model_details.short_description = RoBERTa finetuned on SNLI with adversarial binary gender bias mitigation.\n",
      "2022-04-01 16:10:14,209 - INFO - allennlp.common.params - model_details.developed_by = Zhang at al\n",
      "2022-04-01 16:10:14,210 - INFO - allennlp.common.params - model_details.contributed_by = Arjun Subramonian\n",
      "2022-04-01 16:10:14,210 - INFO - allennlp.common.params - model_details.date = 2021-06-17\n",
      "2022-04-01 16:10:14,212 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-04-01 16:10:14,212 - INFO - allennlp.common.params - model_details.model_type = RoBERTa\n",
      "2022-04-01 16:10:14,213 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@article{Zhang2018MitigatingUB,\n",
      "title={Mitigating Unwanted Biases with Adversarial Learning},\n",
      "author={B. H. Zhang and B. Lemoine and Margaret Mitchell},\n",
      "journal={Proceedings of the 2018 AAAI/ACM Conference on AI, Ethics, and Society},\n",
      "year={2018}\n",
      "}\n",
      "2022-04-01 16:10:14,214 - INFO - allennlp.common.params - model_details.paper.title = Mitigating Unwanted Biases with Adversarial Learning\n",
      "2022-04-01 16:10:14,215 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:9424845\n",
      "2022-04-01 16:10:14,216 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-04-01 16:10:14,216 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-04-01 16:10:14,219 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-04-01 16:10:14,220 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-04-01 16:10:14,221 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-04-01 16:10:14,222 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-04-01 16:10:14,223 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-04-01 16:10:14,224 - INFO - allennlp.common.params - metrics.model_performance_measures = Accuracy, Net Neutral, Fraction Neutral, Threshold:tau\n",
      "2022-04-01 16:10:14,225 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-04-01 16:10:14,226 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-04-01 16:10:14,227 - INFO - allennlp.common.params - evaluation_data.dataset.name = On Measuring and Mitigating Biased Gender-Occupation Inferences SNLI Dataset\n",
      "2022-04-01 16:10:14,228 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = https://storage.googleapis.com/allennlp-public-models/binary-gender-bias-mitigated-snli-dataset.jsonl\n",
      "2022-04-01 16:10:14,229 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://github.com/sunipa/On-Measuring-and-Mitigating-Biased-Inferences-of-Word-Embeddings\n",
      "2022-04-01 16:10:14,229 - INFO - allennlp.common.params - evaluation_data.motivation = None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-01 16:10:14,230 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-04-01 16:10:14,231 - INFO - allennlp.common.params - training_data.dataset.name = Stanford Natural Language Inference (SNLI) train set\n",
      "2022-04-01 16:10:14,232 - INFO - allennlp.common.params - training_data.dataset.processed_url = https://allennlp.s3.amazonaws.com/datasets/snli/snli_1.0_train.jsonl\n",
      "2022-04-01 16:10:14,233 - INFO - allennlp.common.params - training_data.dataset.url = https://nlp.stanford.edu/projects/snli/\n",
      "2022-04-01 16:10:14,234 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-04-01 16:10:14,235 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-04-01 16:10:14,236 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = Net Neutral: 0.613096454815352, Fraction Neutral: 0.6704967487937075, Threshold:0.5: 0.6637061892722586, Threshold:0.7: 0.49490217463150243\n",
      "2022-04-01 16:10:14,237 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-04-01 16:10:14,239 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = Adversarial binary gender bias mitigation has been applied to this model. Nonetheless, the model will contain residual biases and bias mitigation does not guarantee entirely bias-free inferences.\n",
      "2022-04-01 16:10:14,240 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-04-01 16:10:14,276 - INFO - allennlp.common.params - id = structured-prediction-biaffine-parser\n",
      "2022-04-01 16:10:14,277 - INFO - allennlp.common.params - registered_model_name = biaffine_parser\n",
      "2022-04-01 16:10:14,278 - INFO - allennlp.common.params - model_class = None\n",
      "2022-04-01 16:10:14,278 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-04-01 16:10:14,279 - INFO - allennlp.common.params - display_name = Deep Biaffine Attention for Neural Dependency Parsing\n",
      "2022-04-01 16:10:14,279 - INFO - allennlp.common.params - task_id = dependency-parsing\n",
      "2022-04-01 16:10:14,280 - INFO - allennlp.common.params - model_usage.archive_file = biaffine-dependency-parser-ptb-2020.04.06.tar.gz\n",
      "2022-04-01 16:10:14,281 - INFO - allennlp.common.params - model_usage.training_config = structured_prediction/dependency_parser.jsonnet\n",
      "2022-04-01 16:10:14,282 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
      "2022-04-01 16:10:14,283 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-04-01 16:10:14,284 - INFO - allennlp.common.params - model_details.description = This dependency parser follows the model of [Deep Biaffine Attention for Neural Dependency Parsing (Dozat and Manning, 2016)](https://api.semanticscholar.org/CorpusID:7942973) .\n",
      "\n",
      "Word representations are generated using a bidirectional LSTM, followed by separate biaffine classifiers for pairs of words, predicting whether a directed arc exists between the two words and the dependency label the arc should have. Decoding can either be done greedily, or the optimal Minimum Spanning Tree can be decoded using Edmond's algorithm by viewing the dependency tree as a MST on a fully connected graph, where nodes are words and edges are scored dependency arcs.\n",
      "2022-04-01 16:10:14,285 - INFO - allennlp.common.params - model_details.short_description = A neural model for dependency parsing using biaffine classifiers on top of a bidirectional LSTM.\n",
      "2022-04-01 16:10:14,286 - INFO - allennlp.common.params - model_details.developed_by = Dozat et al\n",
      "2022-04-01 16:10:14,287 - INFO - allennlp.common.params - model_details.contributed_by = None\n",
      "2022-04-01 16:10:14,288 - INFO - allennlp.common.params - model_details.date = 2020-04-06\n",
      "2022-04-01 16:10:14,289 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-04-01 16:10:14,290 - INFO - allennlp.common.params - model_details.model_type = None\n",
      "2022-04-01 16:10:14,290 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@article{Dozat2017DeepBA,\n",
      "title={Deep Biaffine Attention for Neural Dependency Parsing},\n",
      "author={Timothy Dozat and Christopher D. Manning},\n",
      "journal={ArXiv},\n",
      "year={2017},\n",
      "volume={abs/1611.01734}}\n",
      "\n",
      "2022-04-01 16:10:14,291 - INFO - allennlp.common.params - model_details.paper.title = Deep Biaffine Attention for Neural Dependency Parsing (Dozat and Manning, 2016)\n",
      "2022-04-01 16:10:14,292 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:7942973\n",
      "2022-04-01 16:10:14,293 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-04-01 16:10:14,293 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-04-01 16:10:14,294 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-04-01 16:10:14,295 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-04-01 16:10:14,296 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-04-01 16:10:14,297 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-04-01 16:10:14,298 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-04-01 16:10:14,299 - INFO - allennlp.common.params - metrics.model_performance_measures = Attachment scores and exact matches (UAS, LAS, UEM, LEM)\n",
      "2022-04-01 16:10:14,299 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-04-01 16:10:14,301 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-04-01 16:10:14,302 - INFO - allennlp.common.params - evaluation_data.dataset.name = PTB 3.0\n",
      "2022-04-01 16:10:14,303 - INFO - allennlp.common.params - evaluation_data.dataset.notes = The dependency parser was evaluated on the Penn Tree Bank dataset. Unfortunately we cannot release this data due to licensing restrictions by the LDC. You can download the PTB data from the LDC website.\n",
      "2022-04-01 16:10:14,304 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = /path/to/dataset\n",
      "2022-04-01 16:10:14,304 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://catalog.ldc.upenn.edu/LDC99T42\n",
      "2022-04-01 16:10:14,305 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-04-01 16:10:14,306 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-04-01 16:10:14,307 - INFO - allennlp.common.params - training_data.dataset.name = PTB 3.0\n",
      "2022-04-01 16:10:14,308 - INFO - allennlp.common.params - training_data.dataset.notes = The dependency parser was evaluated on the Penn Tree Bank dataset. Unfortunately we cannot release this data due to licensing restrictions by the LDC. You can download the PTB data from the LDC website.\n",
      "2022-04-01 16:10:14,308 - INFO - allennlp.common.params - training_data.dataset.processed_url = /path/to/dataset\n",
      "2022-04-01 16:10:14,309 - INFO - allennlp.common.params - training_data.dataset.url = https://catalog.ldc.upenn.edu/LDC99T42\n",
      "2022-04-01 16:10:14,312 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-04-01 16:10:14,313 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-04-01 16:10:14,314 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = The parser achieves 95.57% and 94.44% unlabeled and labeled attachement score using gold POS tags. For predicted POS tags, it achieves 94.81% UAS and 92.86% LAS respectively.\n",
      "2022-04-01 16:10:14,315 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-04-01 16:10:14,316 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-04-01 16:10:14,319 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-04-01 16:10:14,363 - INFO - allennlp.common.params - id = semparse-nlvr\n",
      "2022-04-01 16:10:14,365 - INFO - allennlp.common.params - registered_model_name = None\n",
      "2022-04-01 16:10:14,366 - INFO - allennlp.common.params - model_class = None\n",
      "2022-04-01 16:10:14,367 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-04-01 16:10:14,368 - INFO - allennlp.common.params - display_name = NLVR Semantic Parsing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-01 16:10:14,368 - INFO - allennlp.common.params - task_id = semparse-nlvr\n",
      "2022-04-01 16:10:14,369 - INFO - allennlp.common.params - model_usage.archive_file = https://allennlp.s3.amazonaws.com/models/nlvr-erm-model-2020.02.10-rule-vocabulary-updated.tar.gz\n",
      "2022-04-01 16:10:14,370 - INFO - allennlp.common.params - model_usage.training_config = None\n",
      "2022-04-01 16:10:14,371 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==1.0.0 allennlp-models==1.0.0\n",
      "2022-04-01 16:10:14,371 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-04-01 16:10:14,372 - INFO - allennlp.common.params - model_details.description = The model is a semantic parser trained on Cornell NLVR.\n",
      "2022-04-01 16:10:14,373 - INFO - allennlp.common.params - model_details.short_description = The model is a semantic parser trained on Cornell NLVR.\n",
      "2022-04-01 16:10:14,374 - INFO - allennlp.common.params - model_details.developed_by = Dasigi et al\n",
      "2022-04-01 16:10:14,374 - INFO - allennlp.common.params - model_details.contributed_by = None\n",
      "2022-04-01 16:10:14,375 - INFO - allennlp.common.params - model_details.date = None\n",
      "2022-04-01 16:10:14,376 - INFO - allennlp.common.params - model_details.version = None\n",
      "2022-04-01 16:10:14,376 - INFO - allennlp.common.params - model_details.model_type = None\n",
      "2022-04-01 16:10:14,377 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@inproceedings{Dasigi2019IterativeSF,\n",
      "title={Iterative Search for Weakly Supervised Semantic Parsing},\n",
      "author={Pradeep Dasigi and Matt Gardner and Shikhar Murty and Luke Zettlemoyer and E. Hovy},\n",
      "booktitle={NAACL-HLT},\n",
      "year={2019}}\n",
      "\n",
      "2022-04-01 16:10:14,377 - INFO - allennlp.common.params - model_details.paper.title = Iterative Search for Weakly Supervised Semantic Parsing\n",
      "2022-04-01 16:10:14,380 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:174799945\n",
      "2022-04-01 16:10:14,380 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-04-01 16:10:14,381 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-04-01 16:10:14,382 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-04-01 16:10:14,383 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-04-01 16:10:14,385 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-04-01 16:10:14,386 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-04-01 16:10:14,387 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-04-01 16:10:14,388 - INFO - allennlp.common.params - metrics.model_performance_measures = Denotation accuracy and consistency\n",
      "2022-04-01 16:10:14,389 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-04-01 16:10:14,389 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-04-01 16:10:14,390 - INFO - allennlp.common.params - evaluation_data.dataset.name = Cornell NLVR\n",
      "2022-04-01 16:10:14,391 - INFO - allennlp.common.params - evaluation_data.dataset.notes = Please download the data from the url provided.\n",
      "2022-04-01 16:10:14,391 - INFO - allennlp.common.params - evaluation_data.dataset.url = http://lil.nlp.cornell.edu/nlvr/\n",
      "2022-04-01 16:10:14,392 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-04-01 16:10:14,393 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-04-01 16:10:14,394 - INFO - allennlp.common.params - training_data.dataset.name = Cornell NLVR\n",
      "2022-04-01 16:10:14,395 - INFO - allennlp.common.params - training_data.dataset.notes = Please download the data from the url provided.\n",
      "2022-04-01 16:10:14,395 - INFO - allennlp.common.params - training_data.dataset.url = http://lil.nlp.cornell.edu/nlvr/\n",
      "2022-04-01 16:10:14,396 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-04-01 16:10:14,396 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-04-01 16:10:14,399 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = None\n",
      "2022-04-01 16:10:14,401 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-04-01 16:10:14,402 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-04-01 16:10:14,403 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-04-01 16:10:14,441 - INFO - allennlp.common.params - id = pair-classification-roberta-mnli\n",
      "2022-04-01 16:10:14,442 - INFO - allennlp.common.params - registered_model_name = basic_classifier\n",
      "2022-04-01 16:10:14,443 - INFO - allennlp.common.params - model_class = None\n",
      "2022-04-01 16:10:14,444 - INFO - allennlp.common.params - registered_predictor_name = textual_entailment\n",
      "2022-04-01 16:10:14,445 - INFO - allennlp.common.params - display_name = RoBERTa MNLI\n",
      "2022-04-01 16:10:14,445 - INFO - allennlp.common.params - task_id = textual_entailment\n",
      "2022-04-01 16:10:14,446 - INFO - allennlp.common.params - model_usage.archive_file = mnli-roberta.2021-03-11.tar.gz\n",
      "2022-04-01 16:10:14,447 - INFO - allennlp.common.params - model_usage.training_config = pair_classification/mnli_roberta.jsonnet\n",
      "2022-04-01 16:10:14,447 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
      "2022-04-01 16:10:14,447 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-04-01 16:10:14,449 - INFO - allennlp.common.params - model_details.description = This `Model` implements a basic text classifier. The text is embedded into a text field using a RoBERTa-large model. The resulting sequence is pooled using a cls_pooler `Seq2VecEncoder` and then passed to a linear classification layer, which projects into the label space.\n",
      "2022-04-01 16:10:14,450 - INFO - allennlp.common.params - model_details.short_description = RoBERTa finetuned on MNLI.\n",
      "2022-04-01 16:10:14,450 - INFO - allennlp.common.params - model_details.developed_by = Liu et al\n",
      "2022-04-01 16:10:14,452 - INFO - allennlp.common.params - model_details.contributed_by = Dirk Groeneveld\n",
      "2022-04-01 16:10:14,452 - INFO - allennlp.common.params - model_details.date = 2020-07-29\n",
      "2022-04-01 16:10:14,453 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-04-01 16:10:14,454 - INFO - allennlp.common.params - model_details.model_type = RoBERTa\n",
      "2022-04-01 16:10:14,455 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@article{Liu2019RoBERTaAR,\n",
      "title={RoBERTa: A Robustly Optimized BERT Pretraining Approach},\n",
      "author={Y. Liu and Myle Ott and Naman Goyal and Jingfei Du and Mandar Joshi and Danqi Chen and Omer Levy and M. Lewis and Luke Zettlemoyer and Veselin Stoyanov},\n",
      "journal={ArXiv},\n",
      "year={2019},\n",
      "volume={abs/1907.11692}}\n",
      "\n",
      "2022-04-01 16:10:14,458 - INFO - allennlp.common.params - model_details.paper.title = RoBERTa: A Robustly Optimized BERT Pretraining Approach (Liu et al)\n",
      "2022-04-01 16:10:14,458 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:198953378\n",
      "2022-04-01 16:10:14,459 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-04-01 16:10:14,459 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-04-01 16:10:14,461 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-04-01 16:10:14,461 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-04-01 16:10:14,462 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-04-01 16:10:14,463 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-04-01 16:10:14,463 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-04-01 16:10:14,464 - INFO - allennlp.common.params - metrics.model_performance_measures = Accuracy\n",
      "2022-04-01 16:10:14,465 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-04-01 16:10:14,466 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-04-01 16:10:14,467 - INFO - allennlp.common.params - evaluation_data.dataset.name = Multi-genre Natural Language Inference (MultiNLI) dev set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-01 16:10:14,467 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = https://allennlp.s3.amazonaws.com/datasets/multinli/multinli_1.0_dev_mismatched.jsonl\n",
      "2022-04-01 16:10:14,468 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://cims.nyu.edu/~sbowman/multinli/\n",
      "2022-04-01 16:10:14,469 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-04-01 16:10:14,469 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-04-01 16:10:14,470 - INFO - allennlp.common.params - training_data.dataset.name = Multi-genre Natural Language Inference (MultiNLI) train set\n",
      "2022-04-01 16:10:14,471 - INFO - allennlp.common.params - training_data.dataset.processed_url = https://allennlp.s3.amazonaws.com/datasets/multinli/multinli_1.0_train.jsonl\n",
      "2022-04-01 16:10:14,471 - INFO - allennlp.common.params - training_data.dataset.url = https://cims.nyu.edu/~sbowman/multinli/\n",
      "2022-04-01 16:10:14,476 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-04-01 16:10:14,477 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-04-01 16:10:14,478 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = None\n",
      "2022-04-01 16:10:14,479 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-04-01 16:10:14,481 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-04-01 16:10:14,483 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-04-01 16:10:14,525 - INFO - allennlp.common.params - id = pair-classification-decomposable-attention-elmo\n",
      "2022-04-01 16:10:14,526 - INFO - allennlp.common.params - registered_model_name = decomposable_attention\n",
      "2022-04-01 16:10:14,527 - INFO - allennlp.common.params - model_class = None\n",
      "2022-04-01 16:10:14,527 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-04-01 16:10:14,528 - INFO - allennlp.common.params - display_name = ELMo-based Decomposable Attention\n",
      "2022-04-01 16:10:14,529 - INFO - allennlp.common.params - task_id = textual_entailment\n",
      "2022-04-01 16:10:14,530 - INFO - allennlp.common.params - model_usage.archive_file = decomposable-attention-elmo-2020.04.09.tar.gz\n",
      "2022-04-01 16:10:14,532 - INFO - allennlp.common.params - model_usage.training_config = decomposable_attention_elmo.jsonnet\n",
      "2022-04-01 16:10:14,533 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
      "2022-04-01 16:10:14,535 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-04-01 16:10:14,537 - INFO - allennlp.common.params - model_details.description = This `Model` implements the Decomposable Attention model described in [A Decomposable Attention Model for Natural Language Inference](https://api.semanticscholar.org/CorpusID:8495258) by Parikh et al., 2016, with some optional enhancements before the decomposable attention actually happens.  Parikh's original model allowed for computing an \"intra-sentence\" attention before doing the decomposable entailment step.  We generalize this to any `Seq2SeqEncoder` that can be applied to the premise and/or the hypothesis before computing entailment.\n",
      "\n",
      "The basic outline of this model is to get an embedded representation of each word in thepremise and hypothesis, align words between the two, compare the aligned phrases, and make a final entailment decision based on this aggregated comparison.  Each step in this process uses a feedforward network to modify the representation.\n",
      "\n",
      "This model uses ELMo embeddings.\n",
      "2022-04-01 16:10:14,538 - INFO - allennlp.common.params - model_details.short_description = The decomposable attention model (Parikh et al, 2017) combined with ELMo embeddings trained on SNLI.\n",
      "2022-04-01 16:10:14,540 - INFO - allennlp.common.params - model_details.developed_by = Parikh et al\n",
      "2022-04-01 16:10:14,542 - INFO - allennlp.common.params - model_details.contributed_by = Dirk Groeneveld\n",
      "2022-04-01 16:10:14,543 - INFO - allennlp.common.params - model_details.date = 2020-04-09\n",
      "2022-04-01 16:10:14,544 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-04-01 16:10:14,545 - INFO - allennlp.common.params - model_details.model_type = Seq2Seq\n",
      "2022-04-01 16:10:14,546 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@article{Parikh2016ADA,\n",
      "title={A Decomposable Attention Model for Natural Language Inference},\n",
      "author={Ankur P. Parikh and Oscar T{\"a}ckstr{\"o}m and Dipanjan Das and Jakob Uszkoreit},\n",
      "journal={ArXiv},\n",
      "year={2016},\n",
      "volume={abs/1606.01933}}\n",
      "\n",
      "2022-04-01 16:10:14,546 - INFO - allennlp.common.params - model_details.paper.title = A Decomposable Attention Model for Natural Language Inference\n",
      "2022-04-01 16:10:14,547 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:8495258\n",
      "2022-04-01 16:10:14,548 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-04-01 16:10:14,549 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-04-01 16:10:14,550 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-04-01 16:10:14,552 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-04-01 16:10:14,553 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-04-01 16:10:14,554 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-04-01 16:10:14,555 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-04-01 16:10:14,557 - INFO - allennlp.common.params - metrics.model_performance_measures = Accuracy\n",
      "2022-04-01 16:10:14,561 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-04-01 16:10:14,562 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-04-01 16:10:14,563 - INFO - allennlp.common.params - evaluation_data.dataset.name = Stanford Natural Language Inference (SNLI) dev set\n",
      "2022-04-01 16:10:14,564 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = https://allennlp.s3.amazonaws.com/datasets/snli/snli_1.0_test.jsonl\n",
      "2022-04-01 16:10:14,565 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://nlp.stanford.edu/projects/snli/\n",
      "2022-04-01 16:10:14,566 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-04-01 16:10:14,567 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-04-01 16:10:14,569 - INFO - allennlp.common.params - training_data.dataset.name = Stanford Natural Language Inference (SNLI) train set\n",
      "2022-04-01 16:10:14,569 - INFO - allennlp.common.params - training_data.dataset.processed_url = https://allennlp.s3.amazonaws.com/datasets/snli/snli_1.0_train.jsonl\n",
      "2022-04-01 16:10:14,570 - INFO - allennlp.common.params - training_data.dataset.url = https://nlp.stanford.edu/projects/snli/\n",
      "2022-04-01 16:10:14,571 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-04-01 16:10:14,571 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-04-01 16:10:14,573 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = None\n",
      "2022-04-01 16:10:14,575 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-04-01 16:10:14,576 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-04-01 16:10:14,579 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-04-01 16:10:14,615 - INFO - allennlp.common.params - id = evaluate_rc-lerc\n",
      "2022-04-01 16:10:14,615 - INFO - allennlp.common.params - registered_model_name = lerc\n",
      "2022-04-01 16:10:14,616 - INFO - allennlp.common.params - model_class = None\n",
      "2022-04-01 16:10:14,616 - INFO - allennlp.common.params - registered_predictor_name = lerc\n",
      "2022-04-01 16:10:14,618 - INFO - allennlp.common.params - display_name = Learned Evaluation for Reading Comprehension (LERC)\n",
      "2022-04-01 16:10:14,618 - INFO - allennlp.common.params - task_id = evaluate_rc\n",
      "2022-04-01 16:10:14,620 - INFO - allennlp.common.params - model_usage.archive_file = lerc-2020-11-18.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-01 16:10:14,621 - INFO - allennlp.common.params - model_usage.training_config = None\n",
      "2022-04-01 16:10:14,622 - INFO - allennlp.common.params - model_usage.install_instructions = The model is available at https://github.com/anthonywchen/MOCHA.\n",
      "2022-04-01 16:10:14,623 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-04-01 16:10:14,625 - INFO - allennlp.common.params - model_details.description = LERC is a BERT model that is trained to mimic human judgement scores on candidate answers in the MOCHA dataset. LERC outputs scores that range from 1 to 5, however, to stay consistent with metrics such as BLEU and ROUGE, we normalize the output of LERC to be between 0 and 1 in this demo.\n",
      "2022-04-01 16:10:14,626 - INFO - allennlp.common.params - model_details.short_description = A BERT model that scores candidate answers from 0 to 1.\n",
      "2022-04-01 16:10:14,627 - INFO - allennlp.common.params - model_details.developed_by = Chen et al\n",
      "2022-04-01 16:10:14,628 - INFO - allennlp.common.params - model_details.contributed_by = Anthony Chen\n",
      "2022-04-01 16:10:14,629 - INFO - allennlp.common.params - model_details.date = 2021-03-10\n",
      "2022-04-01 16:10:14,630 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-04-01 16:10:14,630 - INFO - allennlp.common.params - model_details.model_type = BERT\n",
      "2022-04-01 16:10:14,631 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@inproceedings{Chen2020MOCHAAD,\n",
      "title={MOCHA: A Dataset for Training and Evaluating Generative Reading Comprehension Metrics},\n",
      "author={Anthony Chen and Gabriel Stanovsky and S. Singh and Matt Gardner},\n",
      "booktitle={EMNLP},\n",
      "year={2020}}\n",
      "\n",
      "2022-04-01 16:10:14,633 - INFO - allennlp.common.params - model_details.paper.title = MOCHA: A Dataset for Training and Evaluating Generative Reading Comprehension Metrics\n",
      "2022-04-01 16:10:14,634 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:222208714\n",
      "2022-04-01 16:10:14,639 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-04-01 16:10:14,641 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-04-01 16:10:14,642 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-04-01 16:10:14,644 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-04-01 16:10:14,645 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-04-01 16:10:14,647 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-04-01 16:10:14,648 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-04-01 16:10:14,650 - INFO - allennlp.common.params - metrics.model_performance_measures = Pearson Correlation\n",
      "2022-04-01 16:10:14,651 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-04-01 16:10:14,651 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-04-01 16:10:14,653 - INFO - allennlp.common.params - evaluation_data.dataset.name = MOCHA\n",
      "2022-04-01 16:10:14,654 - INFO - allennlp.common.params - evaluation_data.dataset.notes = To evaluate this model follow the instructions at https://github.com/anthonywchen/MOCHA.\n",
      "2022-04-01 16:10:14,655 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = None\n",
      "2022-04-01 16:10:14,657 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://allennlp.org/mocha\n",
      "2022-04-01 16:10:14,658 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-04-01 16:10:14,661 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-04-01 16:10:14,662 - INFO - allennlp.common.params - training_data.dataset.name = MOCHA\n",
      "2022-04-01 16:10:14,663 - INFO - allennlp.common.params - training_data.dataset.notes = To train this model follow the instructions at https://github.com/anthonywchen/MOCHA.\n",
      "2022-04-01 16:10:14,664 - INFO - allennlp.common.params - training_data.dataset.processed_url = None\n",
      "2022-04-01 16:10:14,665 - INFO - allennlp.common.params - training_data.dataset.url = https://allennlp.org/mocha\n",
      "2022-04-01 16:10:14,665 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-04-01 16:10:14,666 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-04-01 16:10:14,667 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = None\n",
      "2022-04-01 16:10:14,667 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-04-01 16:10:14,668 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-04-01 16:10:14,668 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-04-01 16:10:14,674 - WARNING - allennlp.common.model_card - lerc is not a registered model.\n",
      "2022-04-01 16:10:14,718 - INFO - allennlp.common.params - id = mc-roberta-piqa\n",
      "2022-04-01 16:10:14,719 - INFO - allennlp.common.params - registered_model_name = transformer_mc\n",
      "2022-04-01 16:10:14,719 - INFO - allennlp.common.params - model_class = None\n",
      "2022-04-01 16:10:14,720 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-04-01 16:10:14,722 - INFO - allennlp.common.params - display_name = Physical Interaction Question Answering\n",
      "2022-04-01 16:10:14,723 - INFO - allennlp.common.params - task_id = mc\n",
      "2022-04-01 16:10:14,725 - INFO - allennlp.common.params - model_usage.archive_file = piqa.2020-07-08.tar.gz\n",
      "2022-04-01 16:10:14,726 - INFO - allennlp.common.params - model_usage.training_config = mc/piqa.jsonnet\n",
      "2022-04-01 16:10:14,727 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==1.0.0 allennlp-models==1.0.0\n",
      "2022-04-01 16:10:14,727 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-04-01 16:10:14,728 - INFO - allennlp.common.params - model_details.description = This is a multiple choice model patterned after the BERT architecture. It calculates a score for each sequence on top of the CLS token, and then chooses the alternative with the highest score.\n",
      "2022-04-01 16:10:14,729 - INFO - allennlp.common.params - model_details.short_description = RoBERTa-based multiple choice model for PIQA.\n",
      "2022-04-01 16:10:14,729 - INFO - allennlp.common.params - model_details.developed_by = Devlin et al\n",
      "2022-04-01 16:10:14,730 - INFO - allennlp.common.params - model_details.contributed_by = Dirk Groeneveld\n",
      "2022-04-01 16:10:14,731 - INFO - allennlp.common.params - model_details.date = 2020-07-08\n",
      "2022-04-01 16:10:14,732 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-04-01 16:10:14,732 - INFO - allennlp.common.params - model_details.model_type = RoBERTa large\n",
      "2022-04-01 16:10:14,733 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@article{Liu2019RoBERTaAR,\n",
      "title={RoBERTa: A Robustly Optimized BERT Pretraining Approach},\n",
      "author={Y. Liu and Myle Ott and Naman Goyal and Jingfei Du and Mandar Joshi and Danqi Chen and Omer Levy and M. Lewis and Luke Zettlemoyer and Veselin Stoyanov},\n",
      "journal={ArXiv},\n",
      "year={2019},\n",
      "volume={abs/1907.11692}}\n",
      "\n",
      "2022-04-01 16:10:14,734 - INFO - allennlp.common.params - model_details.paper.title = RoBERTa: A Robustly Optimized BERT Pretraining Approach (Liu et al)\n",
      "2022-04-01 16:10:14,735 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:198953378\n",
      "2022-04-01 16:10:14,735 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-04-01 16:10:14,736 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-04-01 16:10:14,737 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-04-01 16:10:14,738 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-04-01 16:10:14,738 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-04-01 16:10:14,739 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-04-01 16:10:14,740 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-04-01 16:10:14,741 - INFO - allennlp.common.params - metrics.model_performance_measures = The chosen metric is accuracy, since it is a multiple choice model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-01 16:10:14,742 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-04-01 16:10:14,742 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-04-01 16:10:14,743 - INFO - allennlp.common.params - evaluation_data.dataset.name = PIQA (validation set)\n",
      "2022-04-01 16:10:14,744 - INFO - allennlp.common.params - evaluation_data.dataset.notes = Please download the data from the url provided.\n",
      "2022-04-01 16:10:14,744 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://yonatanbisk.com/piqa/\n",
      "2022-04-01 16:10:14,745 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-04-01 16:10:14,746 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-04-01 16:10:14,747 - INFO - allennlp.common.params - training_data.dataset.name = PIQA (train set)\n",
      "2022-04-01 16:10:14,752 - INFO - allennlp.common.params - training_data.dataset.notes = Please download the data from the url provided.\n",
      "2022-04-01 16:10:14,753 - INFO - allennlp.common.params - training_data.dataset.url = https://yonatanbisk.com/piqa/\n",
      "2022-04-01 16:10:14,753 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-04-01 16:10:14,754 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-04-01 16:10:14,755 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = None\n",
      "2022-04-01 16:10:14,757 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-04-01 16:10:14,758 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-04-01 16:10:14,760 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-04-01 16:10:14,797 - INFO - allennlp.common.params - id = lm-next-token-lm-gpt2\n",
      "2022-04-01 16:10:14,798 - INFO - allennlp.common.params - registered_model_name = next_token_lm\n",
      "2022-04-01 16:10:14,799 - INFO - allennlp.common.params - model_class = None\n",
      "2022-04-01 16:10:14,800 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-04-01 16:10:14,801 - INFO - allennlp.common.params - display_name = GPT2-based Next Token Language Model\n",
      "2022-04-01 16:10:14,802 - INFO - allennlp.common.params - task_id = language-modeling\n",
      "2022-04-01 16:10:14,803 - INFO - allennlp.common.params - model_usage.archive_file = gpt2-next-word-lm-2020.06.30.tar.gz\n",
      "2022-04-01 16:10:14,804 - INFO - allennlp.common.params - model_usage.training_config = None\n",
      "2022-04-01 16:10:14,805 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==1.0.0 allennlp-models==1.0.0\n",
      "2022-04-01 16:10:14,806 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-04-01 16:10:14,808 - INFO - allennlp.common.params - model_details.description = This is the public 345M parameter OpenAI GPT-2 language model for generating sentences. The model embeds some input tokens, contextualizes them, then predicts the next word, computing a loss against known target. \n",
      "If `BeamSearch` is given, this model will predict a sequence of next tokens.\n",
      "2022-04-01 16:10:14,809 - INFO - allennlp.common.params - model_details.short_description = OpenAI's GPT-2 language model that generates the next token.\n",
      "2022-04-01 16:10:14,810 - INFO - allennlp.common.params - model_details.developed_by = Radford et al\n",
      "2022-04-01 16:10:14,811 - INFO - allennlp.common.params - model_details.contributed_by = None\n",
      "2022-04-01 16:10:14,812 - INFO - allennlp.common.params - model_details.date = 2020-06-30\n",
      "2022-04-01 16:10:14,814 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-04-01 16:10:14,815 - INFO - allennlp.common.params - model_details.model_type = GPT2\n",
      "2022-04-01 16:10:14,815 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@inproceedings{Radford2019LanguageMA,\n",
      "title={Language Models are Unsupervised Multitask Learners},\n",
      "author={A. Radford and Jeffrey Wu and R. Child and David Luan and Dario Amodei and Ilya Sutskever},\n",
      "year={2019}}\n",
      "\n",
      "2022-04-01 16:10:14,817 - INFO - allennlp.common.params - model_details.paper.title = Language Models are Unsupervised Multitask Learners\n",
      "2022-04-01 16:10:14,817 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:160025533\n",
      "2022-04-01 16:10:14,818 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-04-01 16:10:14,819 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-04-01 16:10:14,819 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-04-01 16:10:14,820 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-04-01 16:10:14,821 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-04-01 16:10:14,822 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-04-01 16:10:14,823 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-04-01 16:10:14,824 - INFO - allennlp.common.params - metrics.model_performance_measures = Perplexity\n",
      "2022-04-01 16:10:14,825 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-04-01 16:10:14,826 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-04-01 16:10:14,827 - INFO - allennlp.common.params - evaluation_data.dataset.name = WebText corpus\n",
      "2022-04-01 16:10:14,828 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://github.com/openai/gpt-2-output-dataset\n",
      "2022-04-01 16:10:14,829 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-04-01 16:10:14,830 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-04-01 16:10:14,831 - INFO - allennlp.common.params - training_data.dataset.name = WebText corpus\n",
      "2022-04-01 16:10:14,832 - INFO - allennlp.common.params - training_data.dataset.url = https://github.com/openai/gpt-2-output-dataset\n",
      "2022-04-01 16:10:14,833 - INFO - allennlp.common.params - training_data.motivation = WebText emphasizes document quality. Only human-curated/filtered documents are scraped. Reddit outbound links which receive at least 3 karma points are taken as a proxy for human filtered webpages that are interesting.\n",
      "2022-04-01 16:10:14,834 - INFO - allennlp.common.params - training_data.preprocessing = Dragnet and [Newspaper](https://github.com/codelucas/newspaper) content extractors are used. Wikipedia articles are removed.\n",
      "2022-04-01 16:10:14,835 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = None\n",
      "2022-04-01 16:10:14,836 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-04-01 16:10:14,837 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-04-01 16:10:14,839 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-04-01 16:10:14,885 - INFO - allennlp.common.params - id = tagging-fine-grained-crf-tagger\n",
      "2022-04-01 16:10:14,886 - INFO - allennlp.common.params - registered_model_name = crf_tagger\n",
      "2022-04-01 16:10:14,887 - INFO - allennlp.common.params - model_class = None\n",
      "2022-04-01 16:10:14,887 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-04-01 16:10:14,888 - INFO - allennlp.common.params - display_name = Fine Grained Named Entity Recognition\n",
      "2022-04-01 16:10:14,890 - INFO - allennlp.common.params - task_id = ner\n",
      "2022-04-01 16:10:14,891 - INFO - allennlp.common.params - model_usage.archive_file = fine-grained-ner.2021-02-11.tar.gz\n",
      "2022-04-01 16:10:14,892 - INFO - allennlp.common.params - model_usage.training_config = tagging/fine-grained-ner.jsonnet\n",
      "2022-04-01 16:10:14,892 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
      "2022-04-01 16:10:14,893 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-04-01 16:10:14,894 - INFO - allennlp.common.params - model_details.description = This model identifies a broad range of 16 semantic types in the input text. It is a reimplementation of Lample (2016) and uses a biLSTM with a CRF layer, character embeddings and ELMo embeddings.\n",
      "2022-04-01 16:10:14,895 - INFO - allennlp.common.params - model_details.short_description = This model identifies a broad range of 16 semantic types in the input text. It is a reimplementation of Lample (2016) and uses a biLSTM with a CRF layer, character embeddings and ELMo embeddings.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-01 16:10:14,896 - INFO - allennlp.common.params - model_details.developed_by = Lample et al\n",
      "2022-04-01 16:10:14,897 - INFO - allennlp.common.params - model_details.contributed_by = None\n",
      "2022-04-01 16:10:14,897 - INFO - allennlp.common.params - model_details.date = 2020-06-24\n",
      "2022-04-01 16:10:14,898 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-04-01 16:10:14,901 - INFO - allennlp.common.params - model_details.model_type = BiLSTM\n",
      "2022-04-01 16:10:14,902 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@article{Lample2016NeuralAF,\n",
      "title={Neural Architectures for Named Entity Recognition},\n",
      "author={Guillaume Lample and Miguel Ballesteros and Sandeep Subramanian and K. Kawakami and Chris Dyer},\n",
      "journal={ArXiv},\n",
      "year={2016},\n",
      "volume={abs/1603.01360}}\n",
      "\n",
      "2022-04-01 16:10:14,903 - INFO - allennlp.common.params - model_details.paper.title = Neural Architectures for Named Entity Recognition\n",
      "2022-04-01 16:10:14,903 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:6042994\n",
      "2022-04-01 16:10:14,904 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-04-01 16:10:14,905 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-04-01 16:10:14,906 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-04-01 16:10:14,907 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-04-01 16:10:14,909 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-04-01 16:10:14,910 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-04-01 16:10:14,911 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-04-01 16:10:14,912 - INFO - allennlp.common.params - metrics.model_performance_measures = Accuracy and Span-based F1 metric\n",
      "2022-04-01 16:10:14,913 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-04-01 16:10:14,914 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-04-01 16:10:14,915 - INFO - allennlp.common.params - evaluation_data.dataset.name = Ontonotes 5.0\n",
      "2022-04-01 16:10:14,915 - INFO - allennlp.common.params - evaluation_data.dataset.notes = Unfortunately we cannot release this data due to licensing restrictions.\n",
      "2022-04-01 16:10:14,916 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = /path/do/dataset\n",
      "2022-04-01 16:10:14,917 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://catalog.ldc.upenn.edu/LDC2013T19\n",
      "2022-04-01 16:10:14,919 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-04-01 16:10:14,920 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-04-01 16:10:14,923 - INFO - allennlp.common.params - training_data.dataset.name = Ontonotes 5.0\n",
      "2022-04-01 16:10:14,924 - INFO - allennlp.common.params - training_data.dataset.notes = Unfortunately we cannot release this data due to licensing restrictions.\n",
      "2022-04-01 16:10:14,925 - INFO - allennlp.common.params - training_data.dataset.processed_url = /path/do/dataset\n",
      "2022-04-01 16:10:14,926 - INFO - allennlp.common.params - training_data.dataset.url = https://catalog.ldc.upenn.edu/LDC2013T19\n",
      "2022-04-01 16:10:14,927 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-04-01 16:10:14,928 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-04-01 16:10:14,929 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = On the validation set:\n",
      "Accuracy: 97%\n",
      "F1: 88%\n",
      "2022-04-01 16:10:14,930 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-04-01 16:10:14,931 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-04-01 16:10:14,932 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-04-01 16:10:14,976 - INFO - allennlp.common.params - id = generation-bart\n",
      "2022-04-01 16:10:14,977 - INFO - allennlp.common.params - registered_model_name = bart\n",
      "2022-04-01 16:10:14,978 - INFO - allennlp.common.params - model_class = None\n",
      "2022-04-01 16:10:14,978 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-04-01 16:10:14,979 - INFO - allennlp.common.params - display_name = BART\n",
      "2022-04-01 16:10:14,980 - INFO - allennlp.common.params - task_id = None\n",
      "2022-04-01 16:10:14,981 - INFO - allennlp.common.params - model_usage.archive_file = bart-2020.07.25.tar.gz\n",
      "2022-04-01 16:10:14,983 - INFO - allennlp.common.params - model_usage.training_config = generation/bart_cnn_dm.jsonnet\n",
      "2022-04-01 16:10:14,985 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==1.0.0 allennlp-models==1.0.0\n",
      "2022-04-01 16:10:14,986 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-04-01 16:10:14,988 - INFO - allennlp.common.params - model_details.description = The BART model here uses a language modeling head, and therefore can be used for generation. The BART encoder, implemented as a `Seq2SeqEncoder`, which assumes it operates on already embedded inputs.  This means that we remove the token and position embeddings from BART in this module.  For the typical use case of using BART to encode inputs to your model (where we include the token and position embeddings from BART), you should use `PretrainedTransformerEmbedder(bart_model_name, sub_module=\"encoder\")` instead of this.\n",
      "2022-04-01 16:10:14,990 - INFO - allennlp.common.params - model_details.short_description = BART with a language model head for generation.\n",
      "2022-04-01 16:10:14,991 - INFO - allennlp.common.params - model_details.developed_by = Lewis et al\n",
      "2022-04-01 16:10:14,992 - INFO - allennlp.common.params - model_details.contributed_by = Dirk Groeneveld\n",
      "2022-04-01 16:10:14,993 - INFO - allennlp.common.params - model_details.date = 2020-07-25\n",
      "2022-04-01 16:10:14,993 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-04-01 16:10:14,994 - INFO - allennlp.common.params - model_details.model_type = BART\n",
      "2022-04-01 16:10:14,995 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@inproceedings{Lewis2020BARTDS,\n",
      "title={BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension},\n",
      "author={M. Lewis and Yinhan Liu and Naman Goyal and Marjan Ghazvininejad and A. Mohamed and Omer Levy and Ves Stoyanov and L. Zettlemoyer},\n",
      "booktitle={ACL},\n",
      "year={2020}}\n",
      "\n",
      "2022-04-01 16:10:14,995 - INFO - allennlp.common.params - model_details.paper.title = BART: Denosing Sequence-to-Sequence Pre-training for Natural Language Generation,Translation, and Comprehension\n",
      "2022-04-01 16:10:14,997 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:204960716\n",
      "2022-04-01 16:10:14,997 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-04-01 16:10:14,998 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-04-01 16:10:14,999 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-04-01 16:10:15,001 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-04-01 16:10:15,001 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-04-01 16:10:15,002 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-04-01 16:10:15,002 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-04-01 16:10:15,003 - INFO - allennlp.common.params - metrics.model_performance_measures = ROUGE and BLEU\n",
      "2022-04-01 16:10:15,004 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-04-01 16:10:15,006 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-04-01 16:10:15,007 - INFO - allennlp.common.params - evaluation_data.dataset.name = CNN/DailyMail\n",
      "2022-04-01 16:10:15,008 - INFO - allennlp.common.params - evaluation_data.dataset.notes = Please download the data from the url provided.\n",
      "2022-04-01 16:10:15,008 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://github.com/abisee/cnn-dailymail\n",
      "2022-04-01 16:10:15,009 - INFO - allennlp.common.params - evaluation_data.motivation = None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-01 16:10:15,009 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-04-01 16:10:15,010 - INFO - allennlp.common.params - training_data.dataset.name = CNN/DailyMail\n",
      "2022-04-01 16:10:15,011 - INFO - allennlp.common.params - training_data.dataset.notes = Please download the data from the url provided.\n",
      "2022-04-01 16:10:15,012 - INFO - allennlp.common.params - training_data.dataset.url = https://github.com/abisee/cnn-dailymail\n",
      "2022-04-01 16:10:15,012 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-04-01 16:10:15,013 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-04-01 16:10:15,014 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = None\n",
      "2022-04-01 16:10:15,015 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-04-01 16:10:15,015 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-04-01 16:10:15,017 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-04-01 16:10:15,234 - INFO - allennlp.common.plugins - Plugin allennlp_models available\n",
      "2022-04-01 16:10:15,268 - INFO - allennlp.common.plugins - Plugin allennlp_semparse available\n",
      "2022-04-01 16:10:15,271 - INFO - allennlp.common.plugins - Plugin allennlp_server available\n",
      "2022-04-01 16:10:15,528 - INFO - cached_path - cache of https://storage.googleapis.com/allennlp-public-models/structured-prediction-srl-bert.2020.12.15.tar.gz is up-to-date\n",
      "2022-04-01 16:10:15,530 - INFO - allennlp.models.archival - loading archive file https://storage.googleapis.com/allennlp-public-models/structured-prediction-srl-bert.2020.12.15.tar.gz from cache at /home/jg/.allennlp/cache/b5f1db011cc85691a5fa2bf29e055a712261a2e5d74a74edd7da2fffc98d4ab8.4c4ac7e06ec3d85631bd26b839f90b5a375d3ceeb43e3c74f1cf4758dcee2bb3\n",
      "2022-04-01 16:10:15,532 - INFO - allennlp.models.archival - extracting archive file /home/jg/.allennlp/cache/b5f1db011cc85691a5fa2bf29e055a712261a2e5d74a74edd7da2fffc98d4ab8.4c4ac7e06ec3d85631bd26b839f90b5a375d3ceeb43e3c74f1cf4758dcee2bb3 to temp dir /tmp/tmp0sk1kzmu\n",
      "2022-04-01 16:10:18,272 - INFO - allennlp.common.params - dataset_reader.type = srl\n",
      "2022-04-01 16:10:18,274 - INFO - allennlp.common.params - dataset_reader.max_instances = None\n",
      "2022-04-01 16:10:18,275 - INFO - allennlp.common.params - dataset_reader.manual_distributed_sharding = False\n",
      "2022-04-01 16:10:18,276 - INFO - allennlp.common.params - dataset_reader.manual_multiprocess_sharding = False\n",
      "2022-04-01 16:10:18,277 - INFO - allennlp.common.params - dataset_reader.token_indexers = None\n",
      "2022-04-01 16:10:18,278 - INFO - allennlp.common.params - dataset_reader.domain_identifier = None\n",
      "2022-04-01 16:10:18,279 - INFO - allennlp.common.params - dataset_reader.bert_model_name = bert-base-uncased\n",
      "2022-04-01 16:10:29,903 - INFO - allennlp.common.params - dataset_reader.type = srl\n",
      "2022-04-01 16:10:29,906 - INFO - allennlp.common.params - dataset_reader.max_instances = None\n",
      "2022-04-01 16:10:29,907 - INFO - allennlp.common.params - dataset_reader.manual_distributed_sharding = False\n",
      "2022-04-01 16:10:29,909 - INFO - allennlp.common.params - dataset_reader.manual_multiprocess_sharding = False\n",
      "2022-04-01 16:10:29,910 - INFO - allennlp.common.params - dataset_reader.token_indexers = None\n",
      "2022-04-01 16:10:29,912 - INFO - allennlp.common.params - dataset_reader.domain_identifier = None\n",
      "2022-04-01 16:10:29,913 - INFO - allennlp.common.params - dataset_reader.bert_model_name = bert-base-uncased\n",
      "2022-04-01 16:10:33,183 - INFO - allennlp.common.params - type = from_instances\n",
      "2022-04-01 16:10:33,185 - INFO - allennlp.data.vocabulary - Loading token dictionary from /tmp/tmp0sk1kzmu/vocabulary.\n",
      "2022-04-01 16:10:33,189 - INFO - allennlp.common.params - model.type = srl_bert\n",
      "2022-04-01 16:10:33,191 - INFO - allennlp.common.params - model.regularizer = None\n",
      "2022-04-01 16:10:33,193 - INFO - allennlp.common.params - model.ddp_accelerator = None\n",
      "2022-04-01 16:10:33,194 - INFO - allennlp.common.params - model.bert_model = bert-base-uncased\n",
      "2022-04-01 16:10:33,196 - INFO - allennlp.common.params - model.embedding_dropout = 0.1\n",
      "2022-04-01 16:10:33,197 - INFO - allennlp.common.params - model.initializer = <allennlp.nn.initializers.InitializerApplicator object at 0x7f3be08fe6d0>\n",
      "2022-04-01 16:10:33,198 - INFO - allennlp.common.params - model.label_smoothing = None\n",
      "2022-04-01 16:10:33,200 - INFO - allennlp.common.params - model.ignore_span_metric = False\n",
      "2022-04-01 16:10:33,201 - INFO - allennlp.common.params - model.srl_eval_path = /home/jg/anaconda3/envs/allennlp37/lib/python3.7/site-packages/allennlp_models/structured_prediction/tools/srl-eval.pl\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "2022-04-01 16:10:35,880 - INFO - allennlp.nn.initializers - Initializing parameters\n",
      "2022-04-01 16:10:35,882 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code\n",
      "2022-04-01 16:10:35,883 - INFO - allennlp.nn.initializers -    bert_model.embeddings.LayerNorm.bias\n",
      "2022-04-01 16:10:35,884 - INFO - allennlp.nn.initializers -    bert_model.embeddings.LayerNorm.weight\n",
      "2022-04-01 16:10:35,885 - INFO - allennlp.nn.initializers -    bert_model.embeddings.position_embeddings.weight\n",
      "2022-04-01 16:10:35,886 - INFO - allennlp.nn.initializers -    bert_model.embeddings.token_type_embeddings.weight\n",
      "2022-04-01 16:10:35,887 - INFO - allennlp.nn.initializers -    bert_model.embeddings.word_embeddings.weight\n",
      "2022-04-01 16:10:35,887 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.output.LayerNorm.bias\n",
      "2022-04-01 16:10:35,888 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.output.LayerNorm.weight\n",
      "2022-04-01 16:10:35,888 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.output.dense.bias\n",
      "2022-04-01 16:10:35,889 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.output.dense.weight\n",
      "2022-04-01 16:10:35,889 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.self.key.bias\n",
      "2022-04-01 16:10:35,890 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.self.key.weight\n",
      "2022-04-01 16:10:35,891 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.self.query.bias\n",
      "2022-04-01 16:10:35,891 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.self.query.weight\n",
      "2022-04-01 16:10:35,892 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.self.value.bias\n",
      "2022-04-01 16:10:35,893 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.self.value.weight\n",
      "2022-04-01 16:10:35,894 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.intermediate.dense.bias\n",
      "2022-04-01 16:10:35,894 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.intermediate.dense.weight\n",
      "2022-04-01 16:10:35,895 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.output.LayerNorm.bias\n",
      "2022-04-01 16:10:35,897 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.output.LayerNorm.weight\n",
      "2022-04-01 16:10:35,898 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.output.dense.bias\n",
      "2022-04-01 16:10:35,899 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.output.dense.weight\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-01 16:10:35,900 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.output.LayerNorm.bias\n",
      "2022-04-01 16:10:35,900 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.output.LayerNorm.weight\n",
      "2022-04-01 16:10:35,901 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.output.dense.bias\n",
      "2022-04-01 16:10:35,902 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.output.dense.weight\n",
      "2022-04-01 16:10:35,903 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.self.key.bias\n",
      "2022-04-01 16:10:35,904 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.self.key.weight\n",
      "2022-04-01 16:10:35,906 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.self.query.bias\n",
      "2022-04-01 16:10:35,908 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.self.query.weight\n",
      "2022-04-01 16:10:35,908 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.self.value.bias\n",
      "2022-04-01 16:10:35,909 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.self.value.weight\n",
      "2022-04-01 16:10:35,910 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.intermediate.dense.bias\n",
      "2022-04-01 16:10:35,911 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.intermediate.dense.weight\n",
      "2022-04-01 16:10:35,912 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.output.LayerNorm.bias\n",
      "2022-04-01 16:10:35,913 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.output.LayerNorm.weight\n",
      "2022-04-01 16:10:35,914 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.output.dense.bias\n",
      "2022-04-01 16:10:35,919 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.output.dense.weight\n",
      "2022-04-01 16:10:35,919 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.output.LayerNorm.bias\n",
      "2022-04-01 16:10:35,921 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.output.LayerNorm.weight\n",
      "2022-04-01 16:10:35,922 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.output.dense.bias\n",
      "2022-04-01 16:10:35,923 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.output.dense.weight\n",
      "2022-04-01 16:10:35,924 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.self.key.bias\n",
      "2022-04-01 16:10:35,925 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.self.key.weight\n",
      "2022-04-01 16:10:35,926 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.self.query.bias\n",
      "2022-04-01 16:10:35,927 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.self.query.weight\n",
      "2022-04-01 16:10:35,928 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.self.value.bias\n",
      "2022-04-01 16:10:35,930 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.self.value.weight\n",
      "2022-04-01 16:10:35,930 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.intermediate.dense.bias\n",
      "2022-04-01 16:10:35,931 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.intermediate.dense.weight\n",
      "2022-04-01 16:10:35,933 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.output.LayerNorm.bias\n",
      "2022-04-01 16:10:35,934 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.output.LayerNorm.weight\n",
      "2022-04-01 16:10:35,935 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.output.dense.bias\n",
      "2022-04-01 16:10:35,936 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.output.dense.weight\n",
      "2022-04-01 16:10:35,937 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.output.LayerNorm.bias\n",
      "2022-04-01 16:10:35,937 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.output.LayerNorm.weight\n",
      "2022-04-01 16:10:35,938 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.output.dense.bias\n",
      "2022-04-01 16:10:35,938 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.output.dense.weight\n",
      "2022-04-01 16:10:35,939 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.self.key.bias\n",
      "2022-04-01 16:10:35,939 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.self.key.weight\n",
      "2022-04-01 16:10:35,940 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.self.query.bias\n",
      "2022-04-01 16:10:35,940 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.self.query.weight\n",
      "2022-04-01 16:10:35,941 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.self.value.bias\n",
      "2022-04-01 16:10:35,942 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.self.value.weight\n",
      "2022-04-01 16:10:35,942 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.intermediate.dense.bias\n",
      "2022-04-01 16:10:35,943 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.intermediate.dense.weight\n",
      "2022-04-01 16:10:35,943 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.output.LayerNorm.bias\n",
      "2022-04-01 16:10:35,944 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.output.LayerNorm.weight\n",
      "2022-04-01 16:10:35,945 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.output.dense.bias\n",
      "2022-04-01 16:10:35,945 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.output.dense.weight\n",
      "2022-04-01 16:10:35,946 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.output.LayerNorm.bias\n",
      "2022-04-01 16:10:35,946 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.output.LayerNorm.weight\n",
      "2022-04-01 16:10:35,950 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.output.dense.bias\n",
      "2022-04-01 16:10:35,951 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.output.dense.weight\n",
      "2022-04-01 16:10:35,952 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.self.key.bias\n",
      "2022-04-01 16:10:35,953 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.self.key.weight\n",
      "2022-04-01 16:10:35,953 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.self.query.bias\n",
      "2022-04-01 16:10:35,954 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.self.query.weight\n",
      "2022-04-01 16:10:35,954 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.self.value.bias\n",
      "2022-04-01 16:10:35,955 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.self.value.weight\n",
      "2022-04-01 16:10:35,955 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.intermediate.dense.bias\n",
      "2022-04-01 16:10:35,956 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.intermediate.dense.weight\n",
      "2022-04-01 16:10:35,957 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.output.LayerNorm.bias\n",
      "2022-04-01 16:10:35,957 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.output.LayerNorm.weight\n",
      "2022-04-01 16:10:35,958 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.output.dense.bias\n",
      "2022-04-01 16:10:35,958 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.output.dense.weight\n",
      "2022-04-01 16:10:35,959 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.output.LayerNorm.bias\n",
      "2022-04-01 16:10:35,959 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.output.LayerNorm.weight\n",
      "2022-04-01 16:10:35,959 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.output.dense.bias\n",
      "2022-04-01 16:10:35,960 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.output.dense.weight\n",
      "2022-04-01 16:10:35,960 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.self.key.bias\n",
      "2022-04-01 16:10:35,961 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.self.key.weight\n",
      "2022-04-01 16:10:35,961 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.self.query.bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-01 16:10:35,962 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.self.query.weight\n",
      "2022-04-01 16:10:35,962 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.self.value.bias\n",
      "2022-04-01 16:10:35,963 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.self.value.weight\n",
      "2022-04-01 16:10:35,963 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.intermediate.dense.bias\n",
      "2022-04-01 16:10:35,964 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.intermediate.dense.weight\n",
      "2022-04-01 16:10:35,964 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.output.LayerNorm.bias\n",
      "2022-04-01 16:10:35,965 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.output.LayerNorm.weight\n",
      "2022-04-01 16:10:35,965 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.output.dense.bias\n",
      "2022-04-01 16:10:35,966 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.output.dense.weight\n",
      "2022-04-01 16:10:35,967 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.output.LayerNorm.bias\n",
      "2022-04-01 16:10:35,969 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.output.LayerNorm.weight\n",
      "2022-04-01 16:10:35,970 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.output.dense.bias\n",
      "2022-04-01 16:10:35,970 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.output.dense.weight\n",
      "2022-04-01 16:10:35,972 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.self.key.bias\n",
      "2022-04-01 16:10:35,974 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.self.key.weight\n",
      "2022-04-01 16:10:35,975 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.self.query.bias\n",
      "2022-04-01 16:10:35,976 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.self.query.weight\n",
      "2022-04-01 16:10:35,976 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.self.value.bias\n",
      "2022-04-01 16:10:35,977 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.self.value.weight\n",
      "2022-04-01 16:10:35,978 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.intermediate.dense.bias\n",
      "2022-04-01 16:10:35,979 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.intermediate.dense.weight\n",
      "2022-04-01 16:10:35,979 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.output.LayerNorm.bias\n",
      "2022-04-01 16:10:35,979 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.output.LayerNorm.weight\n",
      "2022-04-01 16:10:35,980 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.output.dense.bias\n",
      "2022-04-01 16:10:35,981 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.output.dense.weight\n",
      "2022-04-01 16:10:35,982 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.output.LayerNorm.bias\n",
      "2022-04-01 16:10:35,983 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.output.LayerNorm.weight\n",
      "2022-04-01 16:10:35,984 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.output.dense.bias\n",
      "2022-04-01 16:10:35,985 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.output.dense.weight\n",
      "2022-04-01 16:10:35,986 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.self.key.bias\n",
      "2022-04-01 16:10:35,986 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.self.key.weight\n",
      "2022-04-01 16:10:35,987 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.self.query.bias\n",
      "2022-04-01 16:10:35,989 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.self.query.weight\n",
      "2022-04-01 16:10:35,990 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.self.value.bias\n",
      "2022-04-01 16:10:35,991 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.self.value.weight\n",
      "2022-04-01 16:10:35,992 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.intermediate.dense.bias\n",
      "2022-04-01 16:10:35,993 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.intermediate.dense.weight\n",
      "2022-04-01 16:10:35,994 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.output.LayerNorm.bias\n",
      "2022-04-01 16:10:35,997 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.output.LayerNorm.weight\n",
      "2022-04-01 16:10:35,998 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.output.dense.bias\n",
      "2022-04-01 16:10:35,999 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.output.dense.weight\n",
      "2022-04-01 16:10:36,000 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.output.LayerNorm.bias\n",
      "2022-04-01 16:10:36,001 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.output.LayerNorm.weight\n",
      "2022-04-01 16:10:36,002 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.output.dense.bias\n",
      "2022-04-01 16:10:36,003 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.output.dense.weight\n",
      "2022-04-01 16:10:36,004 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.self.key.bias\n",
      "2022-04-01 16:10:36,005 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.self.key.weight\n",
      "2022-04-01 16:10:36,005 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.self.query.bias\n",
      "2022-04-01 16:10:36,006 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.self.query.weight\n",
      "2022-04-01 16:10:36,009 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.self.value.bias\n",
      "2022-04-01 16:10:36,009 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.self.value.weight\n",
      "2022-04-01 16:10:36,010 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.intermediate.dense.bias\n",
      "2022-04-01 16:10:36,011 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.intermediate.dense.weight\n",
      "2022-04-01 16:10:36,011 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.output.LayerNorm.bias\n",
      "2022-04-01 16:10:36,012 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.output.LayerNorm.weight\n",
      "2022-04-01 16:10:36,012 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.output.dense.bias\n",
      "2022-04-01 16:10:36,013 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.output.dense.weight\n",
      "2022-04-01 16:10:36,014 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.output.LayerNorm.bias\n",
      "2022-04-01 16:10:36,014 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.output.LayerNorm.weight\n",
      "2022-04-01 16:10:36,015 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.output.dense.bias\n",
      "2022-04-01 16:10:36,016 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.output.dense.weight\n",
      "2022-04-01 16:10:36,018 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.self.key.bias\n",
      "2022-04-01 16:10:36,019 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.self.key.weight\n",
      "2022-04-01 16:10:36,020 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.self.query.bias\n",
      "2022-04-01 16:10:36,021 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.self.query.weight\n",
      "2022-04-01 16:10:36,024 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.self.value.bias\n",
      "2022-04-01 16:10:36,025 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.self.value.weight\n",
      "2022-04-01 16:10:36,026 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.intermediate.dense.bias\n",
      "2022-04-01 16:10:36,026 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.intermediate.dense.weight\n",
      "2022-04-01 16:10:36,027 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.output.LayerNorm.bias\n",
      "2022-04-01 16:10:36,028 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.output.LayerNorm.weight\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-01 16:10:36,029 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.output.dense.bias\n",
      "2022-04-01 16:10:36,029 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.output.dense.weight\n",
      "2022-04-01 16:10:36,031 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.output.LayerNorm.bias\n",
      "2022-04-01 16:10:36,032 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.output.LayerNorm.weight\n",
      "2022-04-01 16:10:36,033 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.output.dense.bias\n",
      "2022-04-01 16:10:36,034 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.output.dense.weight\n",
      "2022-04-01 16:10:36,035 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.self.key.bias\n",
      "2022-04-01 16:10:36,035 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.self.key.weight\n",
      "2022-04-01 16:10:36,037 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.self.query.bias\n",
      "2022-04-01 16:10:36,038 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.self.query.weight\n",
      "2022-04-01 16:10:36,039 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.self.value.bias\n",
      "2022-04-01 16:10:36,039 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.self.value.weight\n",
      "2022-04-01 16:10:36,040 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.intermediate.dense.bias\n",
      "2022-04-01 16:10:36,040 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.intermediate.dense.weight\n",
      "2022-04-01 16:10:36,041 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.output.LayerNorm.bias\n",
      "2022-04-01 16:10:36,043 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.output.LayerNorm.weight\n",
      "2022-04-01 16:10:36,043 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.output.dense.bias\n",
      "2022-04-01 16:10:36,044 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.output.dense.weight\n",
      "2022-04-01 16:10:36,044 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.output.LayerNorm.bias\n",
      "2022-04-01 16:10:36,045 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.output.LayerNorm.weight\n",
      "2022-04-01 16:10:36,045 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.output.dense.bias\n",
      "2022-04-01 16:10:36,046 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.output.dense.weight\n",
      "2022-04-01 16:10:36,046 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.self.key.bias\n",
      "2022-04-01 16:10:36,047 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.self.key.weight\n",
      "2022-04-01 16:10:36,047 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.self.query.bias\n",
      "2022-04-01 16:10:36,048 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.self.query.weight\n",
      "2022-04-01 16:10:36,049 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.self.value.bias\n",
      "2022-04-01 16:10:36,050 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.self.value.weight\n",
      "2022-04-01 16:10:36,051 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.intermediate.dense.bias\n",
      "2022-04-01 16:10:36,052 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.intermediate.dense.weight\n",
      "2022-04-01 16:10:36,054 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.output.LayerNorm.bias\n",
      "2022-04-01 16:10:36,055 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.output.LayerNorm.weight\n",
      "2022-04-01 16:10:36,056 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.output.dense.bias\n",
      "2022-04-01 16:10:36,057 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.output.dense.weight\n",
      "2022-04-01 16:10:36,057 - INFO - allennlp.nn.initializers -    bert_model.pooler.dense.bias\n",
      "2022-04-01 16:10:36,058 - INFO - allennlp.nn.initializers -    bert_model.pooler.dense.weight\n",
      "2022-04-01 16:10:36,058 - INFO - allennlp.nn.initializers -    tag_projection_layer.bias\n",
      "2022-04-01 16:10:36,059 - INFO - allennlp.nn.initializers -    tag_projection_layer.weight\n",
      "2022-04-01 16:10:36,373 - INFO - allennlp.models.archival - removing temporary unarchived model dir at /tmp/tmp0sk1kzmu\n"
     ]
    }
   ],
   "source": [
    "# load the regular SRL model\n",
    "srl_predictor = load_predictor('structured-prediction-srl')\n",
    "# load the SRL BERT model\n",
    "srlbert_predictor = load_predictor('structured-prediction-srl-bert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions to create model predictions for a list containing sentences\n",
    "### added by pia, edited by Goya ###\n",
    "\n",
    "def predict_srl(data):\n",
    "    pred = []\n",
    "    for d in data:\n",
    "        pred.append(srl_predictor.predict(d))\n",
    "    return pred\n",
    "\n",
    "\n",
    "def predict_srlbert(data):\n",
    "    pred = []\n",
    "    for d in data:\n",
    "        pred.append(srlbert_predictor.predict(d))\n",
    "    return pred\n",
    "\n",
    "predict_srl = PredictorWrapper.wrap_predict(predict_srl)\n",
    "predict_srlbert = PredictorWrapper.wrap_predict(predict_srlbert)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define output file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create lists to store test sentences and model predictions in \n",
    "test_data = []\n",
    "SRLBERT_predictions = []\n",
    "SRL_predictions = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define paths to output files\n",
    "test_sents_path = './JSON_test_and_predict_files/test_data_patient.json'\n",
    "bert_pred_path = './JSON_test_and_predict_files/BERT_predictions_patient.json'\n",
    "srl_pred_path = './JSON_test_and_predict_files/SRL_predictions_patient.json'\n",
    "\n",
    "#set name of current capability\n",
    "capability = 'patient_recognition'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Checklist tests (Load functions defined in utils)\n",
    "Load functions to test whether names are recognized as patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load functions that check whether the argument of interest is correctly predicted\n",
    "expect_arg1_verb0 = Expect.single(found_arg1_people_verb0)\n",
    "expect_arg1_verb1 = Expect.single(found_arg1_people_verb1)\n",
    "expect_arg1_verb2 = Expect.single(found_arg1_people_verb2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load functions to recognize the title 'doctor' + a name as patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load functions that check whether the argument of interest is correctly predicted\n",
    "expect_arg1_doctor_verb0 = Expect.single(found_arg1_doctor_verb0)\n",
    "expect_arg1_doctor_verb1 = Expect.single(found_arg1_doctor_verb1)\n",
    "expect_arg1_doctor_verb2 = Expect.single(found_arg1_doctor_verb2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load wordlists to use in sample sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize editor object\n",
    "editor = Editor()\n",
    "#import alphabet detector to ensure we only use latin characters\n",
    "from alphabet_detector import AlphabetDetector\n",
    "ad = AlphabetDetector()\n",
    "\n",
    "#get lists of names from the different countries\n",
    "english_firstname = editor.lexicons.female_from.United_Kingdom + editor.lexicons.male_from.United_Kingdom\n",
    "english_male = editor.lexicons.male_from.United_Kingdom \n",
    "english_female = editor.lexicons.female_from.United_Kingdom\n",
    "\n",
    "#get iranian names, only those in latin characters\n",
    "iran_lastnames = [name for name in editor.lexicons.last_from.Iran if ad.only_alphabet_chars(name, \"LATIN\")]\n",
    "iran_female = [name for name in editor.lexicons.female_from.Iran if ad.only_alphabet_chars(name, \"LATIN\")]\n",
    "iran_male = [name for name in editor.lexicons.male_from.Iran if ad.only_alphabet_chars(name, \"LATIN\")]\n",
    "iran_names = iran_female + iran_male\n",
    "\n",
    "#get Dutch names\n",
    "dutch_male = editor.lexicons.male_from.the_Netherlands\n",
    "dutch_female = editor.lexicons.female_from.the_Netherlands\n",
    "dutch_names = dutch_female +  dutch_male\n",
    "dutch_lastnames = editor.lexicons.last_from.the_Netherlands\n",
    "\n",
    "# a list of verbs to use in the test cases\n",
    "passive_verbs = ['kissed', 'killed', 'hurt', 'touched', 'ignored', 'silenced', 'hit', 'greeted']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Names only : English names\n",
    "Tests in the name only setting, for English names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRL\n",
      "Predicting 100 examples\n",
      "Test cases:      100\n",
      "Fails (rate):    2 (2.0%)\n",
      "\n",
      "Example fails:\n",
      "[ARG1: Eric] Reed [V: hurt] [ARGM-LOC: Ernest Miller] [ARGM-TMP: yesterday] .\n",
      "----\n",
      "[ARG1: Adam] [ARGM-ADV: Walker] [V: hurt] [ARG2: Sara Miller] [ARGM-TMP: yesterday] .\n",
      "----\n",
      "SRL BERT\n",
      "Predicting 100 examples\n",
      "Test cases:      100\n",
      "Fails (rate):    0 (0.0%)\n"
     ]
    }
   ],
   "source": [
    "#create samples\n",
    "testcase_name = 'English_names_active'\n",
    "t = editor.template(\"{first_name} {last_name} {verb} {first} {last} yesterday.\", first=english_firstname, last=editor.lexicons.last_from.United_Kingdom, verb=passive_verbs, meta=True, nsamples=100)\n",
    "\n",
    "#make and store predictions for the two models\n",
    "test_data, SRL_predictions, SRLBERT_predictions = predict_and_store(t, capability, testcase_name, \\\n",
    "                                                                    expect_arg1_verb0, format_srl_verb0, \\\n",
    "                                                                    predict_srl, predict_srlbert, test_data, \\\n",
    "                                                                    SRL_predictions, SRLBERT_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRL\n",
      "Predicting 100 examples\n",
      "Test cases:      100\n",
      "Fails (rate):    1 (1.0%)\n",
      "\n",
      "Example fails:\n",
      "[ARGM-MNR: David] [ARG1: Griffiths] was [V: greeted] [ARG0: by Carl Ford] [ARGM-TMP: yesterday]\n",
      "----\n",
      "SRL BERT\n",
      "Predicting 100 examples\n",
      "Test cases:      100\n",
      "Fails (rate):    0 (0.0%)\n"
     ]
    }
   ],
   "source": [
    "#create samples\n",
    "testcase_name = 'English_names_passive'\n",
    "t = editor.template(\"{first} {last} was {verb} by {first_name} {last_name} yesterday\", first=english_firstname, last=editor.lexicons.last_from.United_Kingdom, verb=passive_verbs, meta=True, nsamples=100)\n",
    "\n",
    "#make and store predictions for the two models\n",
    "test_data, SRL_predictions, SRLBERT_predictions = predict_and_store(t, capability, testcase_name, \\\n",
    "                                                                    expect_arg1_verb1, format_srl_verb1, \\\n",
    "                                                                    predict_srl, predict_srlbert, test_data, \\\n",
    "                                                                    SRL_predictions, SRLBERT_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRL\n",
      "Predicting 100 examples\n",
      "Test cases:      100\n",
      "Fails (rate):    2 (2.0%)\n",
      "\n",
      "Example fails:\n",
      "It was Amanda Griffiths [R-ARG1: who] was [V: killed] [ARG0: by Emma Cooper] [ARGM-TMP: yesterday] '\n",
      "----\n",
      "It was [ARG1: Nicola] Richards [R-ARG1: who] was [V: silenced] [ARG0: by Emily Allen yesterday] '\n",
      "----\n",
      "SRL BERT\n",
      "Predicting 100 examples\n",
      "Test cases:      100\n",
      "Fails (rate):    0 (0.0%)\n"
     ]
    }
   ],
   "source": [
    "#create samples\n",
    "testcase_name = 'English_names_itwas_passive'\n",
    "t = editor.template(\"It was {first} {last} who was {verb} by {first_name} {last_name} yesterday'\", first=english_firstname, last=editor.lexicons.last_from.United_Kingdom, verb=passive_verbs, meta=True, nsamples=100)\n",
    "\n",
    "#make and store predictions for the two models\n",
    "test_data, SRL_predictions, SRLBERT_predictions = predict_and_store(t, capability, testcase_name, \\\n",
    "                                                                    expect_arg1_verb2, format_srl_verb2, \\\n",
    "                                                                    predict_srl, predict_srlbert, test_data, \\\n",
    "                                                                    SRL_predictions, SRLBERT_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Names only : Iranian names\n",
    "Tests in the name only setting, for Iranian names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRL\n",
      "Predicting 100 examples\n",
      "Test cases:      100\n",
      "Fails (rate):    11 (11.0%)\n",
      "\n",
      "Example fails:\n",
      "[ARG0: William Brown] [V: touched] [ARG1: Nassim] [ARG2: Moradi] [ARGM-TMP: yesterday] .\n",
      "----\n",
      "[ARG0: Andrew Watson] [V: hurt] [ARG1: Rahman] [ARGM-MNR: Ghazi] [ARGM-TMP: yesterday] .\n",
      "----\n",
      "[ARG0: Alexander Johnson] [V: hit] [ARG1: Amir] [ARG2: Jamali] [ARGM-TMP: yesterday] .\n",
      "----\n",
      "SRL BERT\n",
      "Predicting 100 examples\n",
      "Test cases:      100\n",
      "Fails (rate):    0 (0.0%)\n"
     ]
    }
   ],
   "source": [
    "#create samples\n",
    "testcase_name = 'Iranian_names_active'\n",
    "t = editor.template(\"{first_name} {last_name} {verb} {first} {last} yesterday.\", first=iran_names, last=iran_lastnames, verb=passive_verbs, meta=True, nsamples=100)\n",
    "\n",
    "\n",
    "test_data, SRL_predictions, SRLBERT_predictions = predict_and_store(t, capability, testcase_name, \\\n",
    "                                                                    expect_arg1_verb0, format_srl_verb0, \\\n",
    "                                                                    predict_srl, predict_srlbert, test_data, \\\n",
    "                                                                    SRL_predictions, SRLBERT_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRL\n",
      "Predicting 100 examples\n",
      "Test cases:      100\n",
      "Fails (rate):    5 (5.0%)\n",
      "\n",
      "Example fails:\n",
      "Niki [ARG1: Rahimi] was [V: hit] [ARG0: by Sally Miller] [ARGM-TMP: yesterday]\n",
      "----\n",
      "[ARGM-TMP: Cleopatra] [ARG1: Shariati] was [V: killed] [ARG0: by Jay Allen] [ARGM-TMP: yesterday]\n",
      "----\n",
      "Helen [ARG1: Rezaei] was [V: kissed] [ARG0: by Judith Nelson] [ARGM-TMP: yesterday]\n",
      "----\n",
      "SRL BERT\n",
      "Predicting 100 examples\n",
      "Test cases:      100\n",
      "Fails (rate):    0 (0.0%)\n"
     ]
    }
   ],
   "source": [
    "#create samples\n",
    "testcase_name = 'Iranian_names_passive'\n",
    "t = editor.template(\"{first} {last} was {verb} by {first_name} {last_name} yesterday\", first=iran_names, last=iran_lastnames, verb=passive_verbs, meta=True, nsamples=100)\n",
    "\n",
    "#make and store predictions for the two models\n",
    "test_data, SRL_predictions, SRLBERT_predictions = predict_and_store(t, capability, testcase_name, \\\n",
    "                                                                    expect_arg1_verb1, format_srl_verb1, \\\n",
    "                                                                    predict_srl, predict_srlbert, test_data, \\\n",
    "                                                                    SRL_predictions, SRLBERT_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRL\n",
      "Predicting 100 examples\n",
      "Test cases:      100\n",
      "Fails (rate):    43 (43.0%)\n",
      "\n",
      "Example fails:\n",
      "It was Camelia Jabbari [R-ARG1: who] was [V: greeted] [ARG0: by Ben Brooks yesterday] '\n",
      "----\n",
      "It was Carina [ARG1: Mansourian] [R-ARG1: who] was [V: hurt] [ARG0: by Gary Stewart] [ARGM-TMP: yesterday] '\n",
      "----\n",
      "It was Mani Behbahani [R-ARG1: who] was [V: ignored] [ARG0: by Carolyn Hart] yesterday '\n",
      "----\n",
      "SRL BERT\n",
      "Predicting 100 examples\n",
      "Test cases:      100\n",
      "Fails (rate):    0 (0.0%)\n"
     ]
    }
   ],
   "source": [
    "#create samples\n",
    "testcase_name = 'Iranian_names_itwas_passive'\n",
    "t = editor.template(\"It was {first} {last} who was {verb} by {first_name} {last_name} yesterday'\", first=iran_names, last=iran_lastnames, verb=passive_verbs, meta=True, nsamples=100)\n",
    "\n",
    "#make and store predictions for the two models\n",
    "test_data, SRL_predictions, SRLBERT_predictions = predict_and_store(t, capability, testcase_name, \\\n",
    "                                                                    expect_arg1_verb2, format_srl_verb2, \\\n",
    "                                                                    predict_srl, predict_srlbert, test_data, \\\n",
    "                                                                    SRL_predictions, SRLBERT_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Names only: Dutch names\n",
    "Tests in the name only setting, for Dutch names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRL\n",
      "Predicting 100 examples\n",
      "Test cases:      100\n",
      "Fails (rate):    4 (4.0%)\n",
      "\n",
      "Example fails:\n",
      "[ARG1: Sue Nelson] [V: greeted] [ARG2: Wim Staal] [ARGM-TMP: yesterday] .\n",
      "----\n",
      "[ARG1: Pamela Mason] [V: touched] [ARG2: Maria Vos] [ARGM-TMP: yesterday] .\n",
      "----\n",
      "[ARG1: Betty Green] [V: greeted] [ARG2: Johannes Boersma] [ARGM-TMP: yesterday] .\n",
      "----\n",
      "SRL BERT\n",
      "Predicting 100 examples\n",
      "Test cases:      100\n",
      "Fails (rate):    0 (0.0%)\n"
     ]
    }
   ],
   "source": [
    "#create samples\n",
    "testcase_name = 'Dutch_names_active'\n",
    "t = editor.template(\"{first_name} {last_name} {verb} {first} {last} yesterday.\", first=dutch_names, last=dutch_lastnames, verb=passive_verbs, meta=True, nsamples=100)\n",
    "\n",
    "#make and store predictions for the two models\n",
    "test_data, SRL_predictions, SRLBERT_predictions = predict_and_store(t, capability, testcase_name, \\\n",
    "                                                                    expect_arg1_verb0, format_srl_verb0, \\\n",
    "                                                                    predict_srl, predict_srlbert, test_data, \\\n",
    "                                                                    SRL_predictions, SRLBERT_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRL\n",
      "Predicting 100 examples\n",
      "Test cases:      100\n",
      "Fails (rate):    8 (8.0%)\n",
      "\n",
      "Example fails:\n",
      "[ARGM-ADV: Cor] [ARG1: Pronk] was [V: kissed] [ARG0: by David Carter] [ARGM-TMP: yesterday]\n",
      "----\n",
      "Dirk [ARG1: Roos] was [V: hurt] [ARG0: by Alexander Walker] [ARGM-TMP: yesterday]\n",
      "----\n",
      "[ARGM-DIS: David] [ARG1: Roos] was [V: greeted] [ARG0: by Alexandra Robinson] [ARGM-TMP: yesterday]\n",
      "----\n",
      "SRL BERT\n",
      "Predicting 100 examples\n",
      "Test cases:      100\n",
      "Fails (rate):    1 (1.0%)\n",
      "\n",
      "Example fails:\n",
      "Henriëtte [ARG1: Vos] was [V: greeted] [ARG0: by Rose Cooper] [ARGM-TMP: yesterday]\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "#create samples\n",
    "testcase_name = 'Dutch_names_passive'\n",
    "t = editor.template(\"{first} {last} was {verb} by {first_name} {last_name} yesterday\", first=dutch_names, last=dutch_lastnames, verb=passive_verbs, meta=True, nsamples=100)\n",
    "\n",
    "#make and store predictions for the two models\n",
    "test_data, SRL_predictions, SRLBERT_predictions = predict_and_store(t, capability, testcase_name, \\\n",
    "                                                                    expect_arg1_verb1, format_srl_verb1, \\\n",
    "                                                                    predict_srl, predict_srlbert, test_data, \\\n",
    "                                                                    SRL_predictions, SRLBERT_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRL\n",
      "Predicting 100 examples\n",
      "Test cases:      100\n",
      "Fails (rate):    36 (36.0%)\n",
      "\n",
      "Example fails:\n",
      "It was Marlies [ARG1: Muller] [R-ARG1: who] was [V: killed] [ARG0: by Matt Butler yesterday] '\n",
      "----\n",
      "It was Liesbeth Polak [R-ARG1: who] was [V: killed] [ARG0: by Don James] [ARGM-TMP: yesterday] '\n",
      "----\n",
      "It was [ARG1: Henk] Rutten [R-ARG1: who] was [V: kissed] [ARG0: by Lawrence Thompson] [ARGM-TMP: yesterday] '\n",
      "----\n",
      "SRL BERT\n",
      "Predicting 100 examples\n",
      "Test cases:      100\n",
      "Fails (rate):    0 (0.0%)\n"
     ]
    }
   ],
   "source": [
    "#create samples\n",
    "testcase_name = 'English_names_itwas_passive'\n",
    "t = editor.template(\"It was {first} {last} who was {verb} by {first_name} {last_name} yesterday'\", first=dutch_names, last=dutch_lastnames, verb=passive_verbs, meta=True, nsamples=100)\n",
    "\n",
    "#make and store predictions for the two models\n",
    "test_data, SRL_predictions, SRLBERT_predictions = predict_and_store(t, capability, testcase_name, \\\n",
    "                                                                    expect_arg1_verb2, format_srl_verb2, \\\n",
    "                                                                    predict_srl, predict_srlbert, test_data, \\\n",
    "                                                                    SRL_predictions, SRLBERT_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Titles + names: English names\n",
    "In the stereotypical version: 'Doctor' + male name ; 'Nurse' + female name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRL\n",
      "Predicting 100 examples\n",
      "Test cases:      100\n",
      "Fails (rate):    0 (0.0%)\n",
      "SRL BERT\n",
      "Predicting 100 examples\n",
      "Test cases:      100\n",
      "Fails (rate):    0 (0.0%)\n"
     ]
    }
   ],
   "source": [
    "#create samples\n",
    "testcase_name = 'English_title_stereotype_active'\n",
    "t = editor.template(\"Nurse {female} {last_name} {verb} Doctor {first} {last} yesterday.\", first=english_male, last=editor.lexicons.last_from.United_Kingdom, verb=passive_verbs, meta=True, nsamples=100)\n",
    "\n",
    "#make and store predictions for the two models\n",
    "test_data, SRL_predictions, SRLBERT_predictions = predict_and_store(t, capability, testcase_name, \\\n",
    "                                                                    expect_arg1_doctor_verb0, format_srl_verb0, \\\n",
    "                                                                    predict_srl, predict_srlbert, test_data, \\\n",
    "                                                                    SRL_predictions, SRLBERT_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRL\n",
      "Predicting 100 examples\n",
      "Test cases:      100\n",
      "Fails (rate):    0 (0.0%)\n",
      "SRL BERT\n",
      "Predicting 100 examples\n",
      "Test cases:      100\n",
      "Fails (rate):    0 (0.0%)\n"
     ]
    }
   ],
   "source": [
    "#create samples\n",
    "testcase_name = 'English_title_stereotype_passive'\n",
    "t = editor.template(\"Doctor {first} {last} was {verb} by nurse {female} {last_name} yesterday.\", first=english_male, last=editor.lexicons.last_from.United_Kingdom, verb=passive_verbs, meta=True, nsamples=100)\n",
    "\n",
    "#make and store predictions for the two models\n",
    "test_data, SRL_predictions, SRLBERT_predictions = predict_and_store(t, capability, testcase_name, \\\n",
    "                                                                    expect_arg1_doctor_verb1, format_srl_verb1, \\\n",
    "                                                                    predict_srl, predict_srlbert, test_data, \\\n",
    "                                                                    SRL_predictions, SRLBERT_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRL\n",
      "Predicting 100 examples\n",
      "Test cases:      100\n",
      "Fails (rate):    0 (0.0%)\n",
      "SRL BERT\n",
      "Predicting 100 examples\n",
      "Test cases:      100\n",
      "Fails (rate):    0 (0.0%)\n"
     ]
    }
   ],
   "source": [
    "#create samples\n",
    "testcase_name = 'English_title_stereotype_itwas_passive'\n",
    "t = editor.template(\"It was Doctor {first} {last} who was {verb} by nurse {female} {last_name} yesterday.\", first=english_male, last=editor.lexicons.last_from.United_Kingdom, verb=passive_verbs, meta=True, nsamples=100)\n",
    "\n",
    "#make and store predictions for the two models\n",
    "test_data, SRL_predictions, SRLBERT_predictions = predict_and_store(t, capability, testcase_name, \\\n",
    "                                                                    expect_arg1_doctor_verb2, format_srl_verb2, \\\n",
    "                                                                    predict_srl, predict_srlbert, test_data, \\\n",
    "                                                                    SRL_predictions, SRLBERT_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the non-stereotypical version: 'Doctor' + female name ; 'Nurse' + male name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRL\n",
      "Predicting 100 examples\n",
      "Test cases:      100\n",
      "Fails (rate):    0 (0.0%)\n",
      "SRL BERT\n",
      "Predicting 100 examples\n",
      "Test cases:      100\n",
      "Fails (rate):    0 (0.0%)\n"
     ]
    }
   ],
   "source": [
    "#create samples\n",
    "testcase_name = 'English_title_nonstereotype_active'\n",
    "t = editor.template(\"Nurse {male} {last_name} {verb} Doctor {first} {last} yesterday.\", first=english_female, last=editor.lexicons.last_from.United_Kingdom, verb=passive_verbs, meta=True, nsamples=100)\n",
    "\n",
    "#make and store predictions for the two models\n",
    "test_data, SRL_predictions, SRLBERT_predictions = predict_and_store(t, capability, testcase_name, \\\n",
    "                                                                    expect_arg1_doctor_verb0, format_srl_verb0, \\\n",
    "                                                                    predict_srl, predict_srlbert, test_data, \\\n",
    "                                                                    SRL_predictions, SRLBERT_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRL\n",
      "Predicting 100 examples\n",
      "Test cases:      100\n",
      "Fails (rate):    2 (2.0%)\n",
      "\n",
      "Example fails:\n",
      "[ARGM-DIS: Doctor Ethel] [ARG1: Clark] was [V: hit] [ARG0: by nurse Kevin Sullivan] [ARGM-TMP: yesterday] .\n",
      "----\n",
      "[ARGM-DIS: Doctor Ethel] [ARG1: Davies] was [V: hit] [ARG0: by nurse Chris Martin] [ARGM-TMP: yesterday] .\n",
      "----\n",
      "SRL BERT\n",
      "Predicting 100 examples\n",
      "Test cases:      100\n",
      "Fails (rate):    0 (0.0%)\n"
     ]
    }
   ],
   "source": [
    "#create samples\n",
    "testcase_name = 'English_title_nonstereotype_passive'\n",
    "t = editor.template(\"Doctor {first} {last} was {verb} by nurse {male} {last_name} yesterday.\", first=english_female, last=editor.lexicons.last_from.United_Kingdom, verb=passive_verbs, meta=True, nsamples=100)\n",
    "\n",
    "#make and store predictions for the two models\n",
    "test_data, SRL_predictions, SRLBERT_predictions = predict_and_store(t, capability, testcase_name, \\\n",
    "                                                                    expect_arg1_doctor_verb1, format_srl_verb1, \\\n",
    "                                                                    predict_srl, predict_srlbert, test_data, \\\n",
    "                                                                    SRL_predictions, SRLBERT_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRL\n",
      "Predicting 100 examples\n",
      "Test cases:      100\n",
      "Fails (rate):    0 (0.0%)\n",
      "SRL BERT\n",
      "Predicting 100 examples\n",
      "Test cases:      100\n",
      "Fails (rate):    0 (0.0%)\n"
     ]
    }
   ],
   "source": [
    "#create samples\n",
    "testcase_name = 'English_title_nonstereotype_itwas_passive'\n",
    "t = editor.template(\"It was Doctor {first} {last} who was {verb} by nurse {male} {last_name} yesterday.\", first=english_female, last=editor.lexicons.last_from.United_Kingdom, verb=passive_verbs, meta=True, nsamples=100)\n",
    "\n",
    "#make and store predictions for the two models\n",
    "test_data, SRL_predictions, SRLBERT_predictions = predict_and_store(t, capability, testcase_name, \\\n",
    "                                                                    expect_arg1_doctor_verb2, format_srl_verb2, \\\n",
    "                                                                    predict_srl, predict_srlbert, test_data, \\\n",
    "                                                                    SRL_predictions, SRLBERT_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Titles + names: Iranian names\n",
    "In the stereotypical version: 'Doctor' + male name ; 'Nurse' + female name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRL\n",
      "Predicting 100 examples\n",
      "Test cases:      100\n",
      "Fails (rate):    4 (4.0%)\n",
      "\n",
      "Example fails:\n",
      "[ARGM-TMP: Nurse] [ARG0: Deborah Robertson] [V: touched] [ARG1: Doctor Saeed] [ARGM-PRD: Razi] [ARGM-TMP: yesterday] .\n",
      "----\n",
      "Nurse [ARG0: Judith Sullivan] [V: kissed] [ARG1: Doctor Robert Khan yesterday] .\n",
      "----\n",
      "Nurse [ARG0: Louise Hamilton] [V: kissed] [ARG1: Doctor Daniel] [ARG2: Panahi] [ARGM-TMP: yesterday] .\n",
      "----\n",
      "SRL BERT\n",
      "Predicting 100 examples\n",
      "Test cases:      100\n",
      "Fails (rate):    0 (0.0%)\n"
     ]
    }
   ],
   "source": [
    "#create samples\n",
    "testcase_name = 'Iranian_title_stereotype_active'\n",
    "t = editor.template(\"Nurse {female} {last_name} {verb} Doctor {first} {last} yesterday.\", first=iran_male, last=iran_lastnames, verb=passive_verbs, meta=True, nsamples=100)\n",
    "\n",
    "#make and store predictions for the two models\n",
    "test_data, SRL_predictions, SRLBERT_predictions = predict_and_store(t, capability, testcase_name, \\\n",
    "                                                                    expect_arg1_doctor_verb0, format_srl_verb0, \\\n",
    "                                                                    predict_srl, predict_srlbert, test_data, \\\n",
    "                                                                    SRL_predictions, SRLBERT_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRL\n",
      "Predicting 100 examples\n",
      "Test cases:      100\n",
      "Fails (rate):    15 (15.0%)\n",
      "\n",
      "Example fails:\n",
      "[ARG2: Doctor Navid Zandi] was [V: touched] [ARG0: by nurse Laura Hamilton] [ARGM-TMP: yesterday] .\n",
      "----\n",
      "[ARG2: Doctor Jalil Fatemi] was [V: touched] [ARG0: by nurse Barbara Clark] [ARGM-TMP: yesterday] .\n",
      "----\n",
      "[ARG2: Doctor Mani] [ARG1: Peyrovani] was [V: kissed] [ARG0: by nurse Rebecca Coleman] [ARGM-TMP: yesterday] .\n",
      "----\n",
      "SRL BERT\n",
      "Predicting 100 examples\n",
      "Test cases:      100\n",
      "Fails (rate):    0 (0.0%)\n"
     ]
    }
   ],
   "source": [
    "#create samples\n",
    "testcase_name = 'Iranian_title_stereotype_passive'\n",
    "t = editor.template(\"Doctor {first} {last} was {verb} by nurse {female} {last_name} yesterday.\", first=iran_male, last=iran_lastnames, verb=passive_verbs, meta=True, nsamples=100)\n",
    "\n",
    "#make and store predictions for the two models\n",
    "test_data, SRL_predictions, SRLBERT_predictions = predict_and_store(t, capability, testcase_name, \\\n",
    "                                                                    expect_arg1_doctor_verb1, format_srl_verb1, \\\n",
    "                                                                    predict_srl, predict_srlbert, test_data, \\\n",
    "                                                                    SRL_predictions, SRLBERT_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRL\n",
      "Predicting 100 examples\n",
      "Test cases:      100\n",
      "Fails (rate):    0 (0.0%)\n",
      "SRL BERT\n",
      "Predicting 100 examples\n",
      "Test cases:      100\n",
      "Fails (rate):    0 (0.0%)\n"
     ]
    }
   ],
   "source": [
    "#create samples\n",
    "testcase_name = 'Iranian_title_stereotype_itwas_passive'\n",
    "t = editor.template(\"It was Doctor {first} {last} who was {verb} by nurse {female} {last_name} yesterday.\", first=iran_male, last=iran_lastnames, verb=passive_verbs, meta=True, nsamples=100)\n",
    "\n",
    "#make and store predictions for the two models\n",
    "test_data, SRL_predictions, SRLBERT_predictions = predict_and_store(t, capability, testcase_name, \\\n",
    "                                                                    expect_arg1_doctor_verb2, format_srl_verb2, \\\n",
    "                                                                    predict_srl, predict_srlbert, test_data, \\\n",
    "                                                                    SRL_predictions, SRLBERT_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the non-stereotypical version: 'Doctor' + female name ; 'Nurse' + male name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRL\n",
      "Predicting 100 examples\n",
      "Test cases:      100\n",
      "Fails (rate):    1 (1.0%)\n",
      "\n",
      "Example fails:\n",
      "[ARGM-CAU: Nurse] [ARG0: Donald Cohen] [V: touched] [ARG1: Doctor Niki] [ARG2: Hassani] [ARGM-TMP: yesterday] .\n",
      "----\n",
      "SRL BERT\n",
      "Predicting 100 examples\n",
      "Test cases:      100\n",
      "Fails (rate):    0 (0.0%)\n"
     ]
    }
   ],
   "source": [
    "#create samples\n",
    "testcase_name = 'Iranian_title_nonstereotype_active'\n",
    "t = editor.template(\"Nurse {male} {last_name} {verb} Doctor {first} {last} yesterday.\", first=iran_female, last=iran_lastnames, verb=passive_verbs, meta=True, nsamples=100)\n",
    "\n",
    "#make and store predictions for the two models\n",
    "test_data, SRL_predictions, SRLBERT_predictions = predict_and_store(t, capability, testcase_name, \\\n",
    "                                                                    expect_arg1_doctor_verb0, format_srl_verb0, \\\n",
    "                                                                    predict_srl, predict_srlbert, test_data, \\\n",
    "                                                                    SRL_predictions, SRLBERT_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRL\n",
      "Predicting 100 examples\n",
      "Test cases:      100\n",
      "Fails (rate):    16 (16.0%)\n",
      "\n",
      "Example fails:\n",
      "[ARG2: Doctor Fatemeh Afshar] was [V: touched] [ARG0: by nurse Steve Gordon] [ARGM-TMP: yesterday] .\n",
      "----\n",
      "[ARG2: Doctor Negar Tabatabaei] was [V: touched] [ARG0: by nurse Richard White] [ARGM-TMP: yesterday] .\n",
      "----\n",
      "[ARG2: Doctor Fatemeh Rajabi] was [V: kissed] [ARG0: by nurse Ralph Bell] [ARGM-TMP: yesterday] .\n",
      "----\n",
      "SRL BERT\n",
      "Predicting 100 examples\n",
      "Test cases:      100\n",
      "Fails (rate):    0 (0.0%)\n"
     ]
    }
   ],
   "source": [
    "#create samples\n",
    "testcase_name = 'Iranian_title_nonstereotype_passive'\n",
    "t = editor.template(\"Doctor {first} {last} was {verb} by nurse {male} {last_name} yesterday.\", first=iran_female, last=iran_lastnames, verb=passive_verbs, meta=True, nsamples=100)\n",
    "\n",
    "#make and store predictions for the two models\n",
    "test_data, SRL_predictions, SRLBERT_predictions = predict_and_store(t, capability, testcase_name, \\\n",
    "                                                                    expect_arg1_doctor_verb1, format_srl_verb1, \\\n",
    "                                                                    predict_srl, predict_srlbert, test_data, \\\n",
    "                                                                    SRL_predictions, SRLBERT_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRL\n",
      "Predicting 100 examples\n",
      "Test cases:      100\n",
      "Fails (rate):    0 (0.0%)\n",
      "SRL BERT\n",
      "Predicting 100 examples\n",
      "Test cases:      100\n",
      "Fails (rate):    0 (0.0%)\n"
     ]
    }
   ],
   "source": [
    "#create samples\n",
    "testcase_name = 'Iranian_title_nonstereotype_itwas_passive'\n",
    "t = editor.template(\"It was Doctor {first} {last} who was {verb} by nurse {male} {last_name} yesterday.\", first=iran_female, last=iran_lastnames, verb=passive_verbs, meta=True, nsamples=100)\n",
    "\n",
    "#make and store predictions for the two models\n",
    "test_data, SRL_predictions, SRLBERT_predictions = predict_and_store(t, capability, testcase_name, \\\n",
    "                                                                    expect_arg1_doctor_verb2, format_srl_verb2, \\\n",
    "                                                                    predict_srl, predict_srlbert, test_data, \\\n",
    "                                                                    SRL_predictions, SRLBERT_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Titles + names: Dutch names\n",
    "In the stereotypical version: 'Doctor' + male name ; 'Nurse' + female name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRL\n",
      "Predicting 100 examples\n",
      "Test cases:      100\n",
      "Fails (rate):    6 (6.0%)\n",
      "\n",
      "Example fails:\n",
      "Nurse [ARG0: Rose Wright] [V: touched] [ARG1: Doctor Bas] [ARG2: Wiersma] [ARGM-TMP: yesterday] .\n",
      "----\n",
      "[ARGM-MOD: Nurse] [ARG0: Diane Price] [V: hurt] [ARG1: Doctor Eduard] [ARG2: Smulders] [ARGM-TMP: yesterday] .\n",
      "----\n",
      "Nurse [ARG0: Catherine Cohen] [V: hurt] [ARG1: Doctor Rob] [ARG2: Simons] [ARGM-TMP: yesterday] .\n",
      "----\n",
      "SRL BERT\n",
      "Predicting 100 examples\n",
      "Test cases:      100\n",
      "Fails (rate):    0 (0.0%)\n"
     ]
    }
   ],
   "source": [
    "#create samples\n",
    "testcase_name = 'Dutch_title_stereotype_active'\n",
    "t = editor.template(\"Nurse {female} {last_name} {verb} Doctor {first} {last} yesterday.\", first=dutch_male, last=dutch_lastnames, verb=passive_verbs, meta=True, nsamples=100)\n",
    "\n",
    "#make and store predictions for the two models\n",
    "test_data, SRL_predictions, SRLBERT_predictions = predict_and_store(t, capability, testcase_name, \\\n",
    "                                                                    expect_arg1_doctor_verb0, format_srl_verb0, \\\n",
    "                                                                    predict_srl, predict_srlbert, test_data, \\\n",
    "                                                                    SRL_predictions, SRLBERT_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRL\n",
      "Predicting 100 examples\n",
      "Test cases:      100\n",
      "Fails (rate):    6 (6.0%)\n",
      "\n",
      "Example fails:\n",
      "[ARG1: Doctor Jacques] Kuiper was [V: hit] [ARG0: by nurse Kathleen King] [ARGM-TMP: yesterday] .\n",
      "----\n",
      "[ARG2: Doctor Geert Molenaar] was [V: touched] [ARG0: by nurse Charlotte Foster] [ARGM-TMP: yesterday] .\n",
      "----\n",
      "[ARG2: Doctor Joop Dijkstra] was [V: kissed] [ARG0: by nurse Anne Kennedy] [ARGM-TMP: yesterday] .\n",
      "----\n",
      "SRL BERT\n",
      "Predicting 100 examples\n",
      "Test cases:      100\n",
      "Fails (rate):    0 (0.0%)\n"
     ]
    }
   ],
   "source": [
    "#create samples\n",
    "testcase_name = 'Dutch_title_stereotype_passive'\n",
    "t = editor.template(\"Doctor {first} {last} was {verb} by nurse {female} {last_name} yesterday.\", first=dutch_male, last=dutch_lastnames, verb=passive_verbs, meta=True, nsamples=100)\n",
    "\n",
    "#make and store predictions for the two models\n",
    "test_data, SRL_predictions, SRLBERT_predictions = predict_and_store(t, capability, testcase_name, \\\n",
    "                                                                    expect_arg1_doctor_verb1, format_srl_verb1, \\\n",
    "                                                                    predict_srl, predict_srlbert, test_data, \\\n",
    "                                                                    SRL_predictions, SRLBERT_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRL\n",
      "Predicting 100 examples\n",
      "Test cases:      100\n",
      "Fails (rate):    1 (1.0%)\n",
      "\n",
      "Example fails:\n",
      "It was Doctor Erik [ARG1: Martens] [R-ARG1: who] was [V: greeted] [ARG0: by nurse Melissa Evans] [ARGM-TMP: yesterday] .\n",
      "----\n",
      "SRL BERT\n",
      "Predicting 100 examples\n",
      "Test cases:      100\n",
      "Fails (rate):    0 (0.0%)\n"
     ]
    }
   ],
   "source": [
    "#create samples\n",
    "testcase_name = 'Dutch_title_stereotype_itwas_passive'\n",
    "t = editor.template(\"It was Doctor {first} {last} who was {verb} by nurse {female} {last_name} yesterday.\", first=dutch_male, last=dutch_lastnames, verb=passive_verbs, meta=True, nsamples=100)\n",
    "\n",
    "#make and store predictions for the two models\n",
    "test_data, SRL_predictions, SRLBERT_predictions = predict_and_store(t, capability, testcase_name, \\\n",
    "                                                                    expect_arg1_doctor_verb2, format_srl_verb2, \\\n",
    "                                                                    predict_srl, predict_srlbert, test_data, \\\n",
    "                                                                    SRL_predictions, SRLBERT_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the non-stereotypical version: 'Doctor' + female name ; 'Nurse' + male name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRL\n",
      "Predicting 100 examples\n",
      "Test cases:      100\n",
      "Fails (rate):    2 (2.0%)\n",
      "\n",
      "Example fails:\n",
      "Nurse [ARG0: Ken Alexander] [V: hurt] [ARG1: Doctor] Helena Vonk yesterday .\n",
      "----\n",
      "Nurse [ARG0: Tom Gordon] [V: greeted] [ARG1: Doctor Nina] [ARG2: Wagenaar] [ARGM-TMP: yesterday] .\n",
      "----\n",
      "SRL BERT\n",
      "Predicting 100 examples\n",
      "Test cases:      100\n",
      "Fails (rate):    0 (0.0%)\n"
     ]
    }
   ],
   "source": [
    "#create samples\n",
    "testcase_name = 'Dutch_title_nonstereotype_active'\n",
    "t = editor.template(\"Nurse {male} {last_name} {verb} Doctor {first} {last} yesterday.\", first=dutch_female, last=dutch_lastnames, verb=passive_verbs, meta=True, nsamples=100)\n",
    "\n",
    "#make and store predictions for the two models\n",
    "test_data, SRL_predictions, SRLBERT_predictions = predict_and_store(t, capability, testcase_name, \\\n",
    "                                                                    expect_arg1_doctor_verb0, format_srl_verb0, \\\n",
    "                                                                    predict_srl, predict_srlbert, test_data, \\\n",
    "                                                                    SRL_predictions, SRLBERT_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRL\n",
      "Predicting 100 examples\n",
      "Test cases:      100\n",
      "Fails (rate):    7 (7.0%)\n",
      "\n",
      "Example fails:\n",
      "[ARG2: Doctor Ilse] [ARG1: Dijkstra] was [V: kissed] [ARG0: by nurse Colin Brooks] [ARGM-TMP: yesterday] .\n",
      "----\n",
      "[ARG2: Doctor Ineke] [ARG1: Rutten] was [V: kissed] [ARG0: by nurse Dick Perry] [ARGM-TMP: yesterday] .\n",
      "----\n",
      "[ARG2: Doctor Gerda] [ARG1: Vonk] was [V: kissed] [ARG0: by nurse Matthew Rose] [ARGM-TMP: yesterday] .\n",
      "----\n",
      "SRL BERT\n",
      "Predicting 100 examples\n",
      "Test cases:      100\n",
      "Fails (rate):    0 (0.0%)\n"
     ]
    }
   ],
   "source": [
    "#create samples\n",
    "testcase_name = 'Dutch_title_nonstereotype_passive'\n",
    "t = editor.template(\"Doctor {first} {last} was {verb} by nurse {male} {last_name} yesterday.\", first=dutch_female, last=dutch_lastnames, verb=passive_verbs, meta=True, nsamples=100)\n",
    "\n",
    "#make and store predictions for the two models\n",
    "test_data, SRL_predictions, SRLBERT_predictions = predict_and_store(t, capability, testcase_name, \\\n",
    "                                                                    expect_arg1_doctor_verb1, format_srl_verb1, \\\n",
    "                                                                    predict_srl, predict_srlbert, test_data, \\\n",
    "                                                                    SRL_predictions, SRLBERT_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRL\n",
      "Predicting 100 examples\n",
      "Test cases:      100\n",
      "Fails (rate):    0 (0.0%)\n",
      "SRL BERT\n",
      "Predicting 100 examples\n",
      "Test cases:      100\n",
      "Fails (rate):    0 (0.0%)\n"
     ]
    }
   ],
   "source": [
    "#create samples\n",
    "testcase_name = 'Dutch_title_nonstereotype_itwas_passive'\n",
    "t = editor.template(\"It was Doctor {first} {last} who was {verb} by nurse {male} {last_name} yesterday.\", first=dutch_female, last=dutch_lastnames, verb=passive_verbs, meta=True, nsamples=100)\n",
    "\n",
    "#make and store predictions for the two models\n",
    "test_data, SRL_predictions, SRLBERT_predictions = predict_and_store(t, capability, testcase_name, \\\n",
    "                                                                    expect_arg1_doctor_verb2, format_srl_verb2, \\\n",
    "                                                                    predict_srl, predict_srlbert, test_data, \\\n",
    "                                                                    SRL_predictions, SRLBERT_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store all data to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store the test sentences\n",
    "store_data(test_sents_path, test_data, new_file=True)\n",
    "#store the model predictions\n",
    "store_data(bert_pred_path, SRLBERT_predictions, new_file=True)\n",
    "store_data(srl_pred_path, SRL_predictions, new_file=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:allennlp37]",
   "language": "python",
   "name": "conda-env-allennlp37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
