{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SRL Patient recognition experiments\n",
    "\n",
    "In this notebook I carry out experiments to test whether two Semantic Role Labelling (SRL) systems can correctly identify patients in sentences with varying structures. This code was based on code provided by Pia Sommerauer.\n",
    "\n",
    "In this code I load two models, namely the AllenNLP SRL model and the AllenNLP SRL BERT model. I create a variety of tets cases, for wich I evaluate the performance of the two models. All the test sentences are stored in a json file specified through the `test_sents_path` variable. The SRL predictions are stored in the json file specified through `srl_pred_path`, and similarly the SRL BERT predictions are stored at the path `bert_pred_path`.\n",
    "\n",
    "### Distance  Agent recognition\n",
    "In this notebook, I evaluate whether the two models can identify agents equally well if the agent is close to or further away from the predicate. I try both an active and a passive formulation. \n",
    "*  Active, small distance: \"John smashed the ball\", \n",
    "*  Active, large distance: \"Frederick, after nearly falling down, finally missed the ball\", \n",
    "*  Passive, small distance: \"The bal was kicked by Jennifer\", \n",
    "*  Passive, large distance: \"The ball was kicked after a boring match by Evelyn\" \n",
    "\n",
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp_models.pretrained import load_predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import checklist\n",
    "from checklist.editor import Editor\n",
    "from checklist.perturb import Perturb\n",
    "from checklist.test_types import MFT, INV, DIR\n",
    "from checklist.expect import Expect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from checklist.pred_wrapper import PredictorWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the AllenNLP models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the regular SRL model\n",
    "srl_predictor = load_predictor('structured-prediction-srl')\n",
    "# load the SRL BERT model\n",
    "srlbert_predictor = load_predictor('structured-prediction-srl-bert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions to create model predictions for a list containing sentences\n",
    "### added by pia, edited by Goya ###\n",
    "\n",
    "def predict_srl(data):\n",
    "    pred = []\n",
    "    for d in data:\n",
    "        pred.append(srl_predictor.predict(d))\n",
    "    return pred\n",
    "\n",
    "\n",
    "def predict_srlbert(data):\n",
    "    pred = []\n",
    "    for d in data:\n",
    "        pred.append(srlbert_predictor.predict(d))\n",
    "    return pred\n",
    "\n",
    "predict_srl = PredictorWrapper.wrap_predict(predict_srl)\n",
    "predict_srlbert = PredictorWrapper.wrap_predict(predict_srlbert)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define output file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create lists to store test sentences and model predictions in \n",
    "test_data = []\n",
    "SRLBERT_predictions = []\n",
    "SRL_predictions = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define paths to output files\n",
    "test_sents_path = './JSON_test_and_predict_files/test_data_agent.json'\n",
    "bert_pred_path = './JSON_test_and_predict_files/BERT_predictions_agent.json'\n",
    "srl_pred_path = './JSON_test_and_predict_files/SRL_predictions_agent.json'\n",
    "\n",
    "#set name of current capability\n",
    "capability = 'agent_small_long_recognition'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Checklist tests (Load functions defined in utils)\n",
    "Load functions to test whether names are recognized as agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "expect_arg0_verb0 = Expect.single(found_arg0_verb0)\n",
    "expect_arg0_verb1 = Expect.single(found_arg0_verb1)\n",
    "expect_byarg0_verb1 = Expect.single(found_byarg0_verb1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load wordlists to use in sample sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize editor object\n",
    "editor = Editor()\n",
    "# verbs\n",
    "verbs = ['hit', 'kicked', 'stopped', 'touched', 'missed', 'smashed']\n",
    "# lists of sentence fillers to increase the distance between the agent and the predicate\n",
    "# for active sentences\n",
    "precedents = ['nearly falling down', 'missing the past three games', 'celebrating a perfect streak', 'suffering from a knee injury', 'appearing so fit']\n",
    "# for passive sentences\n",
    "ball_precedents = ['lying there for a while', 'a boring match', 'three nerve-wrecking minutes', 'some time']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests: Agent recognition - small and large predicate distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Active\n",
    "small distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRL\n",
      "Predicting 100 examples\n",
      "Test cases:      100\n",
      "Fails (rate):    8 (8.0%)\n",
      "\n",
      "Example fails:\n",
      "[ARG2: Jack] [V: hit] [ARG1: the ball]\n",
      "----\n",
      "Diane [V: hit] [ARG1: the ball]\n",
      "----\n",
      "[ARGM-DIS: Andrea] [V: hit] [ARG1: the ball]\n",
      "----\n",
      "SRL BERT\n",
      "Predicting 100 examples\n",
      "Test cases:      100\n",
      "Fails (rate):    0 (0.0%)\n"
     ]
    }
   ],
   "source": [
    "#create samples\n",
    "testcase_name = 'active_small_distance'\n",
    "t = editor.template(\"{first_name} {verb} the ball\", verb=verbs, meta=True, nsamples=100)\n",
    "\n",
    "#make and store predictions for the two models\n",
    "test_data, SRL_predictions, SRLBERT_predictions = predict_and_store(t, capability, testcase_name, \\\n",
    "                                                                    expect_arg0_verb0, format_srl_verb0, \\\n",
    "                                                                    predict_srl, predict_srlbert, test_data, \\\n",
    "                                                                    SRL_predictions, SRLBERT_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Large distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRL\n",
      "Predicting 100 examples\n",
      "Test cases:      100\n",
      "Fails (rate):    100 (100.0%)\n",
      "\n",
      "Example fails:\n",
      "[ARGM-TMP: Dave] , [ARGM-TMP: after missing the past three games] , [ARG0: finnaly] [V: kicked] [ARG1: the ball]\n",
      "----\n",
      "[ARG0: Joan] , [ARGM-TMP: after nearly falling down] , [ARG0: finnaly] [V: kicked] [ARG1: the ball]\n",
      "----\n",
      "[ARGM-DIS: Patricia] , [ARGM-TMP: after nearly falling down] , [ARG0: finnaly] [V: kicked] [ARG1: the ball]\n",
      "----\n",
      "SRL BERT\n",
      "Predicting 100 examples\n",
      "Test cases:      100\n",
      "Fails (rate):    100 (100.0%)\n",
      "\n",
      "Example fails:\n",
      "[ARGM-DIS: Nancy] , [ARGM-TMP: after celebrating a perfect streak] , [ARG0: finnaly] [V: hit] [ARG1: the ball]\n",
      "----\n",
      "[ARGM-DIS: Emily] , [ARGM-TMP: after suffering from a knee injury] , [ARGM-MNR: finnaly] [V: smashed] [ARG1: the ball]\n",
      "----\n",
      "[ARGM-DIS: Chris] , [ARGM-TMP: after celebrating a perfect streak] , [ARG0: finnaly] [V: hit] [ARG1: the ball]\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "#create samples\n",
    "testcase_name = 'active_large_distance'\n",
    "t = editor.template(\"{first_name}, after {filler}, finnaly {verb} the ball\", verb=verbs, filler=precedents, meta=True, nsamples=100)\n",
    "\n",
    "#make and store predictions for the two models\n",
    "test_data, SRL_predictions, SRLBERT_predictions = predict_and_store(t, capability, testcase_name, \\\n",
    "                                                                    expect_arg0_verb1, format_srl_verb1, \\\n",
    "                                                                    predict_srl, predict_srlbert, test_data, \\\n",
    "                                                                    SRL_predictions, SRLBERT_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passive\n",
    "Small distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRL\n",
      "Predicting 100 examples\n",
      "Test cases:      100\n",
      "Fails (rate):    0 (0.0%)\n",
      "SRL BERT\n",
      "Predicting 100 examples\n",
      "Test cases:      100\n",
      "Fails (rate):    0 (0.0%)\n"
     ]
    }
   ],
   "source": [
    "#create samples\n",
    "testcase_name = 'passive_small_distance'\n",
    "t = editor.template(\"The ball was {verb} by {first_name}\", verb=verbs, meta=True, nsamples=100)\n",
    "\n",
    "#make and store predictions for the two models\n",
    "test_data, SRL_predictions, SRLBERT_predictions = predict_and_store(t, capability, testcase_name, \\\n",
    "                                                                    expect_byarg0_verb1, format_srl_verb1, \\\n",
    "                                                                    predict_srl, predict_srlbert, test_data, \\\n",
    "                                                                    SRL_predictions, SRLBERT_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Large distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRL\n",
      "Predicting 100 examples\n",
      "Test cases:      100\n",
      "Fails (rate):    96 (96.0%)\n",
      "\n",
      "Example fails:\n",
      "[ARG1: The ball] was [V: hit] [ARGM-TMP: after some time] [ARG2: by Amanda]\n",
      "----\n",
      "[ARG1: The ball] was [V: missed] [ARGM-TMP: after three nerve - wrecking minutes by Alice]\n",
      "----\n",
      "[ARG1: The ball] was [V: stopped] [ARGM-TMP: after three nerve - wrecking minutes by Howard]\n",
      "----\n",
      "SRL BERT\n",
      "Predicting 100 examples\n",
      "Test cases:      100\n",
      "Fails (rate):    29 (29.0%)\n",
      "\n",
      "Example fails:\n",
      "[ARG1: The ball] was [V: smashed] [ARGM-TMP: after a boring match by Katie]\n",
      "----\n",
      "[ARG1: The ball] was [V: smashed] [ARGM-TMP: after lying there for a while by Katherine]\n",
      "----\n",
      "[ARG1: The ball] was [V: stopped] [ARGM-TMP: after a boring match by Sally]\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "#create samples\n",
    "testcase_name = 'passive_large_distance'\n",
    "t = editor.template(\"The ball was {verb} after {precedent} by {first_name}\", verb=verbs, precedent=ball_precedents, meta=True, nsamples=100)\n",
    "\n",
    "#make and store predictions for the two models\n",
    "test_data, SRL_predictions, SRLBERT_predictions = predict_and_store(t, capability, testcase_name, \\\n",
    "                                                                    expect_byarg0_verb1, format_srl_verb1, \\\n",
    "                                                                    predict_srl, predict_srlbert, test_data, \\\n",
    "                                                                    SRL_predictions, SRLBERT_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store all data to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store the test sentences\n",
    "store_data(test_sents_path, test_data, new_file=True)\n",
    "#store the model predictions\n",
    "store_data(bert_pred_path, SRLBERT_predictions, new_file=True)\n",
    "store_data(srl_pred_path, SRL_predictions, new_file=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:allennlp37]",
   "language": "python",
   "name": "conda-env-allennlp37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
